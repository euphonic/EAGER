{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract-pages-from-mongo\n",
    "SanjayKAroraPhD@gmail.com <br>\n",
    "November 2018\n",
    "\n",
    "## Description\n",
    "This notebook extracts groups of pages from mongodb by firm_name to create firm-centric page output files that can later be topic modeled.  In doing so, it removes repetitive content (e.g., repeated menu items) and garbage content (e.g., improperly parsed HTML code). \n",
    "\n",
    "## Change log\n",
    "v3 adds the python boilerplate  api for web page cleaning.\n",
    "\n",
    "## TODO:\n",
    "* Need to make better use of all pages in the site, e.g., to improve data quality and use additional paragraph data found on non-homepages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data processing and other libraries\n",
    "import csv\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import pprint\n",
    "import pymongo\n",
    "import traceback\n",
    "from time import sleep\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "from IPython.display import display\n",
    "import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boilerpipe.extract import Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGODB_DB = \"FirmDB\"\n",
    "MONGODB_COLLECTION = \"pages_co_urls\"\n",
    "CONNECTION_STRING = \"mongodb://localhost\"\n",
    "username = \"scrapy\"\n",
    "password = \"eager\"\n",
    "authSource = \"FirmDB\"\n",
    "authMechanism='SCRAM-SHA-1'\n",
    "\n",
    "client = pymongo.MongoClient(CONNECTION_STRING, username=username, password=password, authSource=authSource, authMechanism=authMechanism)\n",
    "db = client[MONGODB_DB]\n",
    "col = db[MONGODB_COLLECTION]\n",
    "\n",
    "DATA_DIR = '/home/eager/EAGER/data/orgs/workshop/depth0_boilerpipe/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "dict_keys(['Ticona LLC', 'Plant Sensory Systems', 'CyboEnergy', 'EMD Technologies Inc.', 'Ferro Corporation', 'NanoOncology', 'Genesco Inc.', 'Immunolight', 'Iogen Corporation', 'NA', 'ACACIA RESEARCH GROUP LLC', 'Kinetech Power Company LLC', 'Lux Bio Group', 'Pharmatrophix', 'Alliance for Sustainable Energy', 'Nanoquantum Sciences', 'Glucan Biorenewables LLC', 'Magnolia Solar', 'Ablexis', 'FULL CIRCLE BIOCHAR', 'GOAL ZERO LLC', 'Matrix Genetics', 'Gilead Connecticut', 'Mattson Technology'])\n"
     ]
    }
   ],
   "source": [
    "# gather unique firm_names from mongodb\n",
    "\n",
    "def get_firm_aggregates ():\n",
    "    query = [ { \"$group\": {\"_id\":\"$firm_name\" , \"number\":{\"$sum\":1}} } ]\n",
    "    results = col.aggregate(query)\n",
    "\n",
    "    mongo_dict = {}\n",
    "    for result in results:\n",
    "        key = (result['_id'])\n",
    "        if key:\n",
    "            mongo_dict[key[0]] = result['number']\n",
    "        else:\n",
    "            mongo_dict['NA'] = result['number']\n",
    "    \n",
    "    return mongo_dict\n",
    "\n",
    "results_dict = get_firm_aggregates()\n",
    "firm_names = results_dict.keys()\n",
    "print (len(firm_names))\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(firm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html content\n",
    "def is_javascript (x):\n",
    "    match_string = r\"(CDATA|return\\s+true|return\\s+false|getelementbyid|function|\\w+\\(.*?\\);|\\w{2,}[\\\\.|:]+\\w{2,}|'\\w+':\\s+'\\w+|\\\\|{|}|\\r|\\n|\\/\\/')\"\n",
    "    # capture CDATA; function declarations; function calls; word sequences separated by a period (e.g., denoting paths)\n",
    "    regex = re.findall(match_string, x) \n",
    "    # check to see if the regex finds some percentage of the words look like javascript patterns\n",
    "    if (len(regex) / float(len(x.split())) > .10):\n",
    "        return True \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def clean_page_content (text_list):\n",
    "    # remove whatever we think is html\n",
    "    removed_html = filter(lambda x: not( bool(BeautifulSoup(x, \"html.parser\").find()) ), text_list)\n",
    "    # remove content that looks like javascript \n",
    "    removed_js = filter(lambda x: not (is_javascript(x)), removed_html)\n",
    "    # add other checks here as needed\n",
    "\n",
    "    return removed_js\n",
    "    \n",
    "\n",
    "# iterate through each firm, get all pages associated with a firm, and produce data structure\n",
    "# url --> depth\n",
    "#     --> content (list)\n",
    "# return data structure\n",
    "def process_firm (firm_name): \n",
    "    regex = '^' + re.escape(firm_name) + '$'\n",
    "    results = col.find( {\"firm_name\": re.compile(firm_name, re.IGNORECASE) } )\n",
    "    firm_pages_dict = {}\n",
    "    depth0_page_text = [] # home page\n",
    "    for result in results:\n",
    "        key = result['url'][0]\n",
    "        if key:\n",
    "            page_dict = {}\n",
    "            depth = result['depth'][0]\n",
    "            page_dict['depth'] = depth\n",
    "            page_dict['domain'] = result['domain'][0]\n",
    "            result['domain'][0]\n",
    "            page_dict['firm_name'] = firm_name\n",
    "            clnd_text = clean_page_content(result['full_text'])\n",
    "            page_dict['clnd_text'] = clnd_text\n",
    "            extractor = Extractor(extractor='DefaultExtractor', html = result['body'][0])\n",
    "            page_dict['boilerpipe'] = extractor.getText()\n",
    "            firm_pages_dict[key] = page_dict\n",
    "            \n",
    "            if depth == -1:\n",
    "                # depth0_page_text = clnd_text\n",
    "                depth0_page_text = page_dict['boilerpipe']\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return firm_pages_dict, depth0_page_text\n",
    "# TODO: identify which pieces of content are common across all sites, and remove those\n",
    "# def clean_content(firm_dict): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CDATA', 'function', 'getelementbyid', 'javascript.function', 'linker:autoLink', 'www.littlekidsinc', 'fxnCall(param.param);', 'dextr.us', \"'type': 'image\", 'return true', 'return false', 'rev7bynlh\\\\u00252bvcgrjg', '\\\\', '{', '}']\n"
     ]
    }
   ],
   "source": [
    "# regex test \n",
    "regex = re.findall(r\"(CDATA|return\\s+true|return\\s+false|getelementbyid|function|\\w+\\(.*?\\);|\\w{2,}[\\\\.|:]+\\w{2,}|'\\w+':\\s+'\\w+|\\\\|{|}|\\r|\\n|\\/\\/')\", \n",
    "                   \"CDATA function contact-us getelementbyid javascript.function linker:autoLink www.littlekidsinc.com fxnCall(param.param); email@dextr.us 'type': 'image' return true return false rev7bynlh\\\\u00252bvcgrjg\\\\ {height}\") # last part is words sequences separated by punct\n",
    "print (regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What We Do\n",
      "Kinetech Power Systems (KPS) has developed a low-cost, flexible duration  - long or short - flywheel energy storage system (FESS), also known as a mechanical battery, that provides non-toxic, environmentally friendly power for up to 30 years with little maintenance required.\n",
      "How We Do It\n",
      "Constant innovation and hard work are behind our FESS. We've managed to create our own technology and designs for our high speed hybrid composite flywheel system, which allows us to drive our costs down without sacrificing efficiency. \n",
      "Why We Do It\n",
      "We strongly believe energy storage to be essential for more widespread renewable energy adoption. We are committed to the development of technology that can put us all one step closer to a clean future for all generations to come.\n",
      "Our Core Technology and Key Advantages\n",
      "Innovative FESS Design\n",
      "Our patented FESS design has been tested and proven to provide long duration energy delivery in several prototype systems. KPS is constantly developing new innovations to further our technology and its applications.\n",
      "High Speed / Small Volume\n",
      "KPS's high speed hybrid composite carbon fibre flywheel is much smaller than other similar steel flywheels, decreasing instalation costs and making it suitable for commercial and residential applications.\n",
      "Unique Bearing Technology\n",
      "The RingLube™ bearing technology is an efficient alternative to magnetic bearing systems without suffering from standby power losses.\n",
      "Efficient\n",
      "Clean\n",
      "Secure\n",
      "Telecom\n",
      "Telecom flywheel energy storage backup systems that can operate outdoors at low and high temperatures with minimal O&M.\n",
      "Utilities + Renewables\n",
      "Flexible and fast responsive energy storage for frequency regulation, peak management, T&D deferral and renewables intregration. \n",
      "Microgrids\n",
      "Modular flywheel energy storage arrays that can adjust for the needs of residential, commercial and/or industrial applications. \n",
      "150 Wh prototype test run\n",
      "WINNERS OF CLEANTECH CHALLENGE MEXICO 2017\n",
      "In November, we were recognized by GreenMomentum as one of the most promising clean technology companies in Mexico.\n",
      "Send\n",
      "Feeling energetic? Please share your energy storage project ideas with us.\n",
      "Kinetech Power Systems is a multi-national company with offices in both Mexico and the United States.\n",
      "Kinetech Power Systems\n",
      "info@kinetechpower.com\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firm_pages_dict, depth0_page_text = process_firm (\"Kinetech Power Company LLC\")\n",
    "print (depth0_page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eager/EAGER/data/orgs/workshop/depth0_boilerpipe/\n"
     ]
    }
   ],
   "source": [
    "print (DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Ticona LLC\n",
      "Working on Plant Sensory Systems\n",
      "Working on CyboEnergy\n",
      "Working on EMD Technologies Inc.\n",
      "Working on Ferro Corporation\n",
      "Working on NanoOncology\n",
      "Working on Genesco Inc.\n",
      "Working on Immunolight\n",
      "Working on Iogen Corporation\n",
      "Working on NA\n",
      "Working on ACACIA RESEARCH GROUP LLC\n",
      "Working on Kinetech Power Company LLC\n",
      "Working on Lux Bio Group\n",
      "Working on Pharmatrophix\n",
      "Working on Alliance for Sustainable Energy\n",
      "Working on Nanoquantum Sciences\n",
      "Working on Glucan Biorenewables LLC\n",
      "Working on Magnolia Solar\n",
      "Working on Ablexis\n",
      "Working on FULL CIRCLE BIOCHAR\n",
      "Working on GOAL ZERO LLC\n",
      "Working on Matrix Genetics\n",
      "Working on Gilead Connecticut\n",
      "Working on Mattson Technology\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "pp = pprint.PrettyPrinter()\n",
    "for firm_name in firm_names: \n",
    "    print (\"Working on \" + firm_name)\n",
    "    firm_pages_dict, depth0_page_text = process_firm (firm_name)\n",
    "    # pp.pprint(depth0_page_text)\n",
    "    if depth0_page_text: \n",
    "        file = re.sub('\\.|\\/', '_', firm_name) + '.txt'\n",
    "        with io.open(DATA_DIR + file,'w',encoding='utf8') as f:\n",
    "            f.write (depth0_page_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
