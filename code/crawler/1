nohup: ignoring input
2018-11-07 05:05:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: FirmDB)
2018-11-07 05:05:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.6 (default, Sep 12 2018, 18:26:19) - [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Linux-4.15.0-1023-aws-x86_64-with-Ubuntu-18.04-bionic
2018-11-07 05:05:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'FirmDB', 'CONCURRENT_REQUESTS_PER_DOMAIN': 4, 'DEPTH_LIMIT': '1', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'FirmDB.spiders', 'ROBOTSTXT_OBEY': 'False', 'SPIDER_MODULES': ['FirmDB.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36'}
2018-11-07 05:05:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-07 05:05:18 [py.warnings] WARNING: /home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2018-11-07 05:05:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'random_useragent.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-07 05:05:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-07 05:05:18 [scrapy.middleware] INFO: Enabled item pipelines:
['FirmDB.pipelines.FirmDBPipeline']
2018-11-07 05:05:18 [scrapy.core.engine] INFO: Spider opened
2018-11-07 05:05:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-07 05:06:25 [scrapy.extensions.logstats] INFO: Crawled 37 pages (at 37 pages/min), scraped 18 items (at 18 items/min)
2018-11-07 05:07:27 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 8 pages/min), scraped 26 items (at 8 items/min)
2018-11-07 05:07:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://new.abb.com>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 05:08:39 [scrapy.extensions.logstats] INFO: Crawled 62 pages (at 17 pages/min), scraped 39 items (at 13 items/min)
2018-11-07 05:09:44 [scrapy.extensions.logstats] INFO: Crawled 71 pages (at 9 pages/min), scraped 50 items (at 11 items/min)
2018-11-07 05:09:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.accu-chek.com/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 05:10:36 [scrapy.extensions.logstats] INFO: Crawled 80 pages (at 9 pages/min), scraped 59 items (at 9 items/min)
2018-11-07 05:11:42 [scrapy.extensions.logstats] INFO: Crawled 88 pages (at 8 pages/min), scraped 68 items (at 9 items/min)
2018-11-07 05:12:41 [scrapy.extensions.logstats] INFO: Crawled 96 pages (at 8 pages/min), scraped 76 items (at 8 items/min)
2018-11-07 05:13:32 [scrapy.extensions.logstats] INFO: Crawled 105 pages (at 9 pages/min), scraped 84 items (at 8 items/min)
2018-11-07 05:14:30 [scrapy.extensions.logstats] INFO: Crawled 113 pages (at 8 pages/min), scraped 92 items (at 8 items/min)
2018-11-07 05:15:23 [scrapy.extensions.logstats] INFO: Crawled 122 pages (at 9 pages/min), scraped 100 items (at 8 items/min)
2018-11-07 05:16:32 [scrapy.extensions.logstats] INFO: Crawled 130 pages (at 8 pages/min), scraped 109 items (at 9 items/min)
2018-11-07 05:17:24 [scrapy.extensions.logstats] INFO: Crawled 139 pages (at 9 pages/min), scraped 117 items (at 8 items/min)
2018-11-07 05:18:26 [scrapy.extensions.logstats] INFO: Crawled 144 pages (at 5 pages/min), scraped 126 items (at 9 items/min)
2018-11-07 05:19:23 [scrapy.extensions.logstats] INFO: Crawled 154 pages (at 10 pages/min), scraped 133 items (at 7 items/min)
2018-11-07 05:20:24 [scrapy.extensions.logstats] INFO: Crawled 159 pages (at 5 pages/min), scraped 140 items (at 7 items/min)
2018-11-07 05:21:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/power-management-ic/lithium-ion-battery-protection-ic/s-8245bd/%0D/>: HTTP status code is not handled or not allowed
2018-11-07 05:21:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/power-management-ic/lithium-ion-battery-protection-ic/s-8255b/%0D/>: HTTP status code is not handled or not allowed
2018-11-07 05:21:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/power-management-ic/lithium-ion-battery-protection-ic/s-8255a/%0D/>: HTTP status code is not handled or not allowed
2018-11-07 05:21:52 [scrapy.extensions.logstats] INFO: Crawled 176 pages (at 17 pages/min), scraped 152 items (at 12 items/min)
2018-11-07 05:22:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/power-management-ic/voltage-regulator-ldo/s-1313xxxh/%0D/>: HTTP status code is not handled or not allowed
2018-11-07 05:22:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/automotive/automotive-voltage-regulator-ldo/s-19252/%0D/>: HTTP status code is not handled or not allowed
2018-11-07 05:22:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.acer.com/nextatacer/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 05:22:28 [scrapy.extensions.logstats] INFO: Crawled 185 pages (at 9 pages/min), scraped 158 items (at 6 items/min)
2018-11-07 05:23:47 [scrapy.extensions.logstats] INFO: Crawled 195 pages (at 10 pages/min), scraped 167 items (at 9 items/min)
2018-11-07 05:24:35 [scrapy.extensions.logstats] INFO: Crawled 199 pages (at 4 pages/min), scraped 174 items (at 7 items/min)
2018-11-07 05:25:30 [scrapy.extensions.logstats] INFO: Crawled 206 pages (at 7 pages/min), scraped 180 items (at 6 items/min)
2018-11-07 05:26:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://hub.ablic.com/en/ceatec2018%0D>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 05:26:26 [scrapy.extensions.logstats] INFO: Crawled 215 pages (at 9 pages/min), scraped 187 items (at 7 items/min)
2018-11-07 05:27:27 [scrapy.extensions.logstats] INFO: Crawled 223 pages (at 8 pages/min), scraped 195 items (at 8 items/min)
2018-11-07 05:28:32 [scrapy.extensions.logstats] INFO: Crawled 230 pages (at 7 pages/min), scraped 203 items (at 8 items/min)
2018-11-07 05:29:27 [scrapy.extensions.logstats] INFO: Crawled 237 pages (at 7 pages/min), scraped 211 items (at 8 items/min)
2018-11-07 05:30:34 [scrapy.extensions.logstats] INFO: Crawled 247 pages (at 10 pages/min), scraped 219 items (at 8 items/min)
2018-11-07 05:31:53 [scrapy.extensions.logstats] INFO: Crawled 255 pages (at 8 pages/min), scraped 229 items (at 10 items/min)
2018-11-07 05:32:29 [scrapy.extensions.logstats] INFO: Crawled 259 pages (at 4 pages/min), scraped 233 items (at 4 items/min)
2018-11-07 05:33:34 [scrapy.extensions.logstats] INFO: Crawled 266 pages (at 7 pages/min), scraped 240 items (at 7 items/min)
2018-11-07 05:34:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://customercare.acer.com/customercare/Default.aspx> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 05:34:25 [scrapy.extensions.logstats] INFO: Crawled 274 pages (at 8 pages/min), scraped 246 items (at 6 items/min)
2018-11-07 05:35:27 [scrapy.extensions.logstats] INFO: Crawled 284 pages (at 10 pages/min), scraped 253 items (at 7 items/min)
2018-11-07 05:35:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://home.cloud.acer.com/airmonitor/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 05:35:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://home.cloud.acer.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 05:35:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://home.cloud.acer.com/beingware/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 05:36:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://home.cloud.acer.com/abeing-cloud/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 05:36:28 [scrapy.extensions.logstats] INFO: Crawled 291 pages (at 7 pages/min), scraped 259 items (at 6 items/min)
2018-11-07 05:37:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.acer.com/ac/>: HTTP status code is not handled or not allowed
2018-11-07 05:37:49 [scrapy.extensions.logstats] INFO: Crawled 299 pages (at 8 pages/min), scraped 270 items (at 11 items/min)
2018-11-07 05:38:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://news.3m.com/press_releases> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 05:38:26 [scrapy.extensions.logstats] INFO: Crawled 309 pages (at 10 pages/min), scraped 276 items (at 6 items/min)
2018-11-07 05:39:32 [scrapy.extensions.logstats] INFO: Crawled 322 pages (at 13 pages/min), scraped 288 items (at 12 items/min)
2018-11-07 05:40:26 [scrapy.extensions.logstats] INFO: Crawled 329 pages (at 7 pages/min), scraped 300 items (at 12 items/min)
2018-11-07 05:40:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.accessbusinessgroup.com/manufacturing-capabilities/home-care-liquids/>: HTTP status code is not handled or not allowed
2018-11-07 05:41:45 [scrapy.extensions.logstats] INFO: Crawled 353 pages (at 24 pages/min), scraped 319 items (at 19 items/min)
2018-11-07 05:42:43 [scrapy.extensions.logstats] INFO: Crawled 361 pages (at 8 pages/min), scraped 327 items (at 8 items/min)
2018-11-07 05:43:24 [scrapy.extensions.logstats] INFO: Crawled 371 pages (at 10 pages/min), scraped 335 items (at 8 items/min)
2018-11-07 05:43:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://investors.3m.com/overview/default.aspx> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 05:44:23 [scrapy.extensions.logstats] INFO: Crawled 379 pages (at 8 pages/min), scraped 344 items (at 9 items/min)
2018-11-07 05:44:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://news.3m.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 05:45:24 [scrapy.extensions.logstats] INFO: Crawled 390 pages (at 11 pages/min), scraped 355 items (at 11 items/min)
2018-11-07 05:46:35 [scrapy.extensions.logstats] INFO: Crawled 402 pages (at 12 pages/min), scraped 366 items (at 11 items/min)
2018-11-07 05:47:42 [scrapy.extensions.logstats] INFO: Crawled 414 pages (at 12 pages/min), scraped 378 items (at 12 items/min)
2018-11-07 05:48:39 [scrapy.extensions.logstats] INFO: Crawled 420 pages (at 6 pages/min), scraped 385 items (at 7 items/min)
2018-11-07 05:49:19 [scrapy.extensions.logstats] INFO: Crawled 428 pages (at 8 pages/min), scraped 392 items (at 7 items/min)
2018-11-07 05:50:30 [scrapy.extensions.logstats] INFO: Crawled 440 pages (at 12 pages/min), scraped 404 items (at 12 items/min)
2018-11-07 05:51:28 [scrapy.extensions.logstats] INFO: Crawled 451 pages (at 11 pages/min), scraped 415 items (at 11 items/min)
2018-11-07 05:52:22 [scrapy.extensions.logstats] INFO: Crawled 460 pages (at 9 pages/min), scraped 425 items (at 10 items/min)
2018-11-07 05:53:26 [scrapy.extensions.logstats] INFO: Crawled 473 pages (at 13 pages/min), scraped 439 items (at 14 items/min)
2018-11-07 05:54:19 [scrapy.extensions.logstats] INFO: Crawled 483 pages (at 10 pages/min), scraped 449 items (at 10 items/min)
2018-11-07 05:55:23 [scrapy.extensions.logstats] INFO: Crawled 494 pages (at 11 pages/min), scraped 462 items (at 13 items/min)
2018-11-07 05:56:30 [scrapy.extensions.logstats] INFO: Crawled 511 pages (at 17 pages/min), scraped 471 items (at 9 items/min)
2018-11-07 05:58:40 [scrapy.extensions.logstats] INFO: Crawled 515 pages (at 4 pages/min), scraped 483 items (at 12 items/min)
2018-11-07 06:00:57 [scrapy.extensions.logstats] INFO: Crawled 536 pages (at 21 pages/min), scraped 496 items (at 13 items/min)
2018-11-07 06:01:20 [scrapy.extensions.logstats] INFO: Crawled 536 pages (at 0 pages/min), scraped 504 items (at 8 items/min)
2018-11-07 06:02:25 [scrapy.extensions.logstats] INFO: Crawled 560 pages (at 24 pages/min), scraped 524 items (at 20 items/min)
2018-11-07 06:02:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://investors.accuray.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 06:03:36 [scrapy.extensions.logstats] INFO: Crawled 580 pages (at 20 pages/min), scraped 539 items (at 15 items/min)
2018-11-07 06:04:22 [scrapy.extensions.logstats] INFO: Crawled 584 pages (at 4 pages/min), scraped 547 items (at 8 items/min)
2018-11-07 06:05:34 [scrapy.extensions.logstats] INFO: Crawled 597 pages (at 13 pages/min), scraped 560 items (at 13 items/min)
2018-11-07 06:06:31 [scrapy.extensions.logstats] INFO: Crawled 612 pages (at 15 pages/min), scraped 572 items (at 12 items/min)
2018-11-07 06:07:51 [scrapy.extensions.logstats] INFO: Crawled 615 pages (at 3 pages/min), scraped 579 items (at 7 items/min)
2018-11-07 06:08:37 [scrapy.extensions.logstats] INFO: Crawled 621 pages (at 6 pages/min), scraped 583 items (at 4 items/min)
2018-11-07 06:09:48 [scrapy.extensions.logstats] INFO: Crawled 623 pages (at 2 pages/min), scraped 586 items (at 3 items/min)
2018-11-07 06:10:21 [scrapy.extensions.logstats] INFO: Crawled 636 pages (at 13 pages/min), scraped 590 items (at 4 items/min)
2018-11-07 06:11:33 [scrapy.extensions.logstats] INFO: Crawled 642 pages (at 6 pages/min), scraped 595 items (at 5 items/min)
2018-11-07 06:12:50 [scrapy.extensions.logstats] INFO: Crawled 646 pages (at 4 pages/min), scraped 603 items (at 8 items/min)
2018-11-07 06:13:42 [scrapy.extensions.logstats] INFO: Crawled 648 pages (at 2 pages/min), scraped 609 items (at 6 items/min)
2018-11-07 06:15:56 [scrapy.extensions.logstats] INFO: Crawled 651 pages (at 3 pages/min), scraped 613 items (at 4 items/min)
2018-11-07 06:16:50 [scrapy.extensions.logstats] INFO: Crawled 652 pages (at 1 pages/min), scraped 616 items (at 3 items/min)
2018-11-07 06:17:35 [scrapy.extensions.logstats] INFO: Crawled 660 pages (at 8 pages/min), scraped 623 items (at 7 items/min)
2018-11-07 06:18:27 [scrapy.extensions.logstats] INFO: Crawled 668 pages (at 8 pages/min), scraped 631 items (at 8 items/min)
2018-11-07 06:19:43 [scrapy.extensions.logstats] INFO: Crawled 676 pages (at 8 pages/min), scraped 639 items (at 8 items/min)
2018-11-07 06:20:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://aadvancedaqua.com/client_area/index.html>: HTTP status code is not handled or not allowed
2018-11-07 06:20:20 [scrapy.extensions.logstats] INFO: Crawled 690 pages (at 14 pages/min), scraped 650 items (at 11 items/min)
2018-11-07 06:21:21 [scrapy.extensions.logstats] INFO: Crawled 715 pages (at 25 pages/min), scraped 670 items (at 20 items/min)
2018-11-07 06:22:25 [scrapy.extensions.logstats] INFO: Crawled 732 pages (at 17 pages/min), scraped 691 items (at 21 items/min)
2018-11-07 06:23:19 [scrapy.extensions.logstats] INFO: Crawled 748 pages (at 16 pages/min), scraped 706 items (at 15 items/min)
2018-11-07 06:24:38 [scrapy.extensions.logstats] INFO: Crawled 763 pages (at 15 pages/min), scraped 725 items (at 19 items/min)
2018-11-07 06:25:20 [scrapy.extensions.logstats] INFO: Crawled 779 pages (at 16 pages/min), scraped 733 items (at 8 items/min)
2018-11-07 06:26:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://hub.ablic.com/en/electronica2018?rf=slide>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 06:26:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/corp/quality-environment/%0D/>: HTTP status code is not handled or not allowed
2018-11-07 06:26:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.accessbusinessgroup.com/manufacturing-capabilities/overview/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.accessbusinessgroup.com/about-abg/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.accessbusinessgroup.com/manufacturing-capabilities/nutrilite-farms/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:39 [scrapy.extensions.logstats] INFO: Crawled 782 pages (at 3 pages/min), scraped 745 items (at 12 items/min)
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://acell.com/clinician-corner/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://acell.com/wound-matrix/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://acell.com/reimbursement/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://community.acer.com/en/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.accuray.com/training/cyberknife-training/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.accuray.com/services/technology-upgrades/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.accuray.com/software/precision-treatment-planning/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.accessbusinessgroup.com/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.accuray.com/cyberknife/cyberknife-treatment-delivery/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://abc.xyz/investor/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:26:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://adeka.co.jp/en/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 975, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: adeka.co.jp.
2018-11-07 06:27:34 [scrapy.extensions.logstats] INFO: Crawled 811 pages (at 29 pages/min), scraped 755 items (at 10 items/min)
2018-11-07 06:33:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.admaproducts.com> (referer: https://www.admaproducts.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-07 06:33:16 [scrapy.extensions.logstats] INFO: Crawled 813 pages (at 2 pages/min), scraped 760 items (at 5 items/min)
2018-11-07 06:33:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cloud.acer.com/ops/login>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 110: Connection timed out.
2018-11-07 06:33:20 [scrapy.extensions.logstats] INFO: Crawled 818 pages (at 5 pages/min), scraped 761 items (at 1 items/min)
2018-11-07 06:33:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://afmodels.com/jobs/>: HTTP status code is not handled or not allowed
2018-11-07 06:34:18 [scrapy.extensions.logstats] INFO: Crawled 824 pages (at 6 pages/min), scraped 770 items (at 9 items/min)
2018-11-07 06:35:21 [scrapy.extensions.logstats] INFO: Crawled 833 pages (at 9 pages/min), scraped 777 items (at 7 items/min)
2018-11-07 06:36:26 [scrapy.extensions.logstats] INFO: Crawled 840 pages (at 7 pages/min), scraped 784 items (at 7 items/min)
2018-11-07 06:37:20 [scrapy.extensions.logstats] INFO: Crawled 845 pages (at 5 pages/min), scraped 790 items (at 6 items/min)
2018-11-07 06:38:54 [scrapy.extensions.logstats] INFO: Crawled 863 pages (at 18 pages/min), scraped 807 items (at 17 items/min)
2018-11-07 06:39:31 [scrapy.extensions.logstats] INFO: Crawled 879 pages (at 16 pages/min), scraped 813 items (at 6 items/min)
2018-11-07 06:40:05 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adidas.com/us/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.adidas.com/us/ took longer than 180.0 seconds..
2018-11-07 06:40:31 [scrapy.extensions.logstats] INFO: Crawled 888 pages (at 9 pages/min), scraped 825 items (at 12 items/min)
2018-11-07 06:41:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.agcbio.com/resources/casestudies>: HTTP status code is not handled or not allowed
2018-11-07 06:41:20 [scrapy.extensions.logstats] INFO: Crawled 893 pages (at 5 pages/min), scraped 834 items (at 9 items/min)
2018-11-07 06:41:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.agcbio.com/about/our_history>: HTTP status code is not handled or not allowed
2018-11-07 06:42:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.agcbio.com/capabilities/process_development>: HTTP status code is not handled or not allowed
2018-11-07 06:42:24 [scrapy.extensions.logstats] INFO: Crawled 906 pages (at 13 pages/min), scraped 845 items (at 11 items/min)
2018-11-07 06:43:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.adm.com/news/media-relation-contacts>: HTTP status code is not handled or not allowed
2018-11-07 06:43:45 [scrapy.extensions.logstats] INFO: Crawled 921 pages (at 15 pages/min), scraped 856 items (at 11 items/min)
2018-11-07 06:44:48 [scrapy.extensions.logstats] INFO: Crawled 929 pages (at 8 pages/min), scraped 863 items (at 7 items/min)
2018-11-07 06:45:49 [scrapy.extensions.logstats] INFO: Crawled 937 pages (at 8 pages/min), scraped 871 items (at 8 items/min)
2018-11-07 06:46:28 [scrapy.extensions.logstats] INFO: Crawled 941 pages (at 4 pages/min), scraped 875 items (at 4 items/min)
2018-11-07 06:47:43 [scrapy.extensions.logstats] INFO: Crawled 945 pages (at 4 pages/min), scraped 883 items (at 8 items/min)
2018-11-07 06:48:27 [scrapy.extensions.logstats] INFO: Crawled 945 pages (at 0 pages/min), scraped 887 items (at 4 items/min)
2018-11-07 06:49:41 [scrapy.extensions.logstats] INFO: Crawled 962 pages (at 17 pages/min), scraped 897 items (at 10 items/min)
2018-11-07 06:50:31 [scrapy.extensions.logstats] INFO: Crawled 965 pages (at 3 pages/min), scraped 904 items (at 7 items/min)
2018-11-07 06:51:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://supportforums.adtran.com/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-07 06:51:19 [scrapy.extensions.logstats] INFO: Crawled 979 pages (at 14 pages/min), scraped 917 items (at 13 items/min)
2018-11-07 06:52:36 [scrapy.extensions.logstats] INFO: Crawled 1002 pages (at 23 pages/min), scraped 941 items (at 24 items/min)
2018-11-07 06:53:19 [scrapy.extensions.logstats] INFO: Crawled 1016 pages (at 14 pages/min), scraped 954 items (at 13 items/min)
2018-11-07 06:54:18 [scrapy.extensions.logstats] INFO: Crawled 1032 pages (at 16 pages/min), scraped 972 items (at 18 items/min)
2018-11-07 06:55:19 [scrapy.extensions.logstats] INFO: Crawled 1051 pages (at 19 pages/min), scraped 989 items (at 17 items/min)
2018-11-07 06:56:26 [scrapy.extensions.logstats] INFO: Crawled 1067 pages (at 16 pages/min), scraped 1006 items (at 17 items/min)
2018-11-07 06:56:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://ag.energy/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 06:57:30 [scrapy.extensions.logstats] INFO: Crawled 1084 pages (at 17 pages/min), scraped 1024 items (at 18 items/min)
2018-11-07 06:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.kubotaholdings.co.jp/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 06:58:21 [scrapy.extensions.logstats] INFO: Crawled 1097 pages (at 13 pages/min), scraped 1038 items (at 14 items/min)
2018-11-07 06:59:20 [scrapy.extensions.logstats] INFO: Crawled 1114 pages (at 17 pages/min), scraped 1054 items (at 16 items/min)
2018-11-07 07:00:37 [scrapy.extensions.logstats] INFO: Crawled 1143 pages (at 29 pages/min), scraped 1073 items (at 19 items/min)
2018-11-07 07:01:18 [scrapy.extensions.logstats] INFO: Crawled 1144 pages (at 1 pages/min), scraped 1084 items (at 11 items/min)
2018-11-07 07:02:21 [scrapy.extensions.logstats] INFO: Crawled 1167 pages (at 23 pages/min), scraped 1101 items (at 17 items/min)
2018-11-07 07:03:20 [scrapy.extensions.logstats] INFO: Crawled 1185 pages (at 18 pages/min), scraped 1118 items (at 17 items/min)
2018-11-07 07:04:18 [scrapy.extensions.logstats] INFO: Crawled 1194 pages (at 9 pages/min), scraped 1135 items (at 17 items/min)
2018-11-07 07:05:41 [scrapy.extensions.logstats] INFO: Crawled 1212 pages (at 18 pages/min), scraped 1153 items (at 18 items/min)
2018-11-07 07:06:23 [scrapy.extensions.logstats] INFO: Crawled 1226 pages (at 14 pages/min), scraped 1162 items (at 9 items/min)
2018-11-07 07:07:28 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 9 pages/min), scraped 1176 items (at 14 items/min)
2018-11-07 07:08:20 [scrapy.extensions.logstats] INFO: Crawled 1249 pages (at 14 pages/min), scraped 1186 items (at 10 items/min)
2018-11-07 07:09:43 [scrapy.extensions.logstats] INFO: Crawled 1259 pages (at 10 pages/min), scraped 1200 items (at 14 items/min)
2018-11-07 07:10:28 [scrapy.extensions.logstats] INFO: Crawled 1268 pages (at 9 pages/min), scraped 1209 items (at 9 items/min)
2018-11-07 07:11:18 [scrapy.extensions.logstats] INFO: Crawled 1278 pages (at 10 pages/min), scraped 1215 items (at 6 items/min)
2018-11-07 07:12:29 [scrapy.extensions.logstats] INFO: Crawled 1291 pages (at 13 pages/min), scraped 1228 items (at 13 items/min)
2018-11-07 07:13:27 [scrapy.extensions.logstats] INFO: Crawled 1297 pages (at 6 pages/min), scraped 1238 items (at 10 items/min)
2018-11-07 07:14:24 [scrapy.extensions.logstats] INFO: Crawled 1313 pages (at 16 pages/min), scraped 1250 items (at 12 items/min)
2018-11-07 07:15:23 [scrapy.extensions.logstats] INFO: Crawled 1325 pages (at 12 pages/min), scraped 1262 items (at 12 items/min)
2018-11-07 07:16:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ww2.adaptivebiotech.com/Analyzer3.0> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 07:16:19 [scrapy.extensions.logstats] INFO: Crawled 1335 pages (at 10 pages/min), scraped 1274 items (at 12 items/min)
2018-11-07 07:16:23 [root] ERROR: Unable to find match for url: https://WWW.ADAPTIVEBIOTECH.COM/INSIGHTS
2018-11-07 07:16:28 [root] ERROR: Unable to find match for url: https://WWW.ADAPTIVEBIOTECH.COM/CLONOSEQ/CLONOSEQ-REPORT
2018-11-07 07:16:32 [root] ERROR: Unable to find match for url: https://WWW.ADAPTIVEBIOTECH.COM/IMMUNOSEQ/ANALYZER
2018-11-07 07:16:38 [root] ERROR: Unable to find match for url: https://WWW.ADAPTIVEBIOTECH.COM/CLONOSEQ/CLONOSEQ-ASSAY
2018-11-07 07:16:46 [root] ERROR: Unable to find match for url: https://WWW.ADAPTIVEBIOTECH.COM/TCR-ANTIGEN-MAP
2018-11-07 07:17:24 [scrapy.extensions.logstats] INFO: Crawled 1353 pages (at 18 pages/min), scraped 1288 items (at 14 items/min)
2018-11-07 07:18:24 [scrapy.extensions.logstats] INFO: Crawled 1365 pages (at 12 pages/min), scraped 1300 items (at 12 items/min)
2018-11-07 07:19:20 [scrapy.extensions.logstats] INFO: Crawled 1377 pages (at 12 pages/min), scraped 1313 items (at 13 items/min)
2018-11-07 07:20:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://adaptivebiotech.com/WWnjZ/news/press-releases>: HTTP status code is not handled or not allowed
2018-11-07 07:20:48 [scrapy.extensions.logstats] INFO: Crawled 1400 pages (at 23 pages/min), scraped 1327 items (at 14 items/min)
2018-11-07 07:21:40 [scrapy.extensions.logstats] INFO: Crawled 1402 pages (at 2 pages/min), scraped 1334 items (at 7 items/min)
2018-11-07 07:22:35 [scrapy.extensions.logstats] INFO: Crawled 1402 pages (at 0 pages/min), scraped 1339 items (at 5 items/min)
2018-11-07 07:23:39 [scrapy.extensions.logstats] INFO: Crawled 1414 pages (at 12 pages/min), scraped 1346 items (at 7 items/min)
2018-11-07 07:24:40 [scrapy.extensions.logstats] INFO: Crawled 1422 pages (at 8 pages/min), scraped 1357 items (at 11 items/min)
2018-11-07 07:25:18 [scrapy.extensions.logstats] INFO: Crawled 1430 pages (at 8 pages/min), scraped 1364 items (at 7 items/min)
2018-11-07 07:26:27 [scrapy.extensions.logstats] INFO: Crawled 1442 pages (at 12 pages/min), scraped 1376 items (at 12 items/min)
2018-11-07 07:27:34 [scrapy.extensions.logstats] INFO: Crawled 1454 pages (at 12 pages/min), scraped 1388 items (at 12 items/min)
2018-11-07 07:28:24 [scrapy.extensions.logstats] INFO: Crawled 1465 pages (at 11 pages/min), scraped 1395 items (at 7 items/min)
2018-11-07 07:29:24 [scrapy.extensions.logstats] INFO: Crawled 1469 pages (at 4 pages/min), scraped 1404 items (at 9 items/min)
2018-11-07 07:30:27 [scrapy.extensions.logstats] INFO: Crawled 1477 pages (at 8 pages/min), scraped 1412 items (at 8 items/min)
2018-11-07 07:31:30 [scrapy.extensions.logstats] INFO: Crawled 1485 pages (at 8 pages/min), scraped 1420 items (at 8 items/min)
2018-11-07 07:32:30 [scrapy.extensions.logstats] INFO: Crawled 1493 pages (at 8 pages/min), scraped 1428 items (at 8 items/min)
2018-11-07 07:33:30 [scrapy.extensions.logstats] INFO: Crawled 1501 pages (at 8 pages/min), scraped 1436 items (at 8 items/min)
2018-11-07 07:34:22 [scrapy.extensions.logstats] INFO: Crawled 1512 pages (at 11 pages/min), scraped 1444 items (at 8 items/min)
2018-11-07 07:35:20 [scrapy.extensions.logstats] INFO: Crawled 1520 pages (at 8 pages/min), scraped 1452 items (at 8 items/min)
2018-11-07 07:36:41 [scrapy.extensions.logstats] INFO: Crawled 1528 pages (at 8 pages/min), scraped 1460 items (at 8 items/min)
2018-11-07 07:37:50 [scrapy.extensions.logstats] INFO: Crawled 1532 pages (at 4 pages/min), scraped 1464 items (at 4 items/min)
2018-11-07 07:41:10 [scrapy.extensions.logstats] INFO: Crawled 1533 pages (at 1 pages/min), scraped 1471 items (at 7 items/min)
2018-11-07 07:41:22 [scrapy.extensions.logstats] INFO: Crawled 1543 pages (at 10 pages/min), scraped 1473 items (at 2 items/min)
2018-11-07 07:44:50 [scrapy.extensions.logstats] INFO: Crawled 1552 pages (at 9 pages/min), scraped 1487 items (at 14 items/min)
2018-11-07 07:46:56 [scrapy.extensions.logstats] INFO: Crawled 1552 pages (at 0 pages/min), scraped 1491 items (at 4 items/min)
2018-11-07 07:47:44 [scrapy.extensions.logstats] INFO: Crawled 1565 pages (at 13 pages/min), scraped 1495 items (at 4 items/min)
2018-11-07 07:49:08 [scrapy.extensions.logstats] INFO: Crawled 1565 pages (at 0 pages/min), scraped 1504 items (at 9 items/min)
2018-11-07 07:49:23 [scrapy.extensions.logstats] INFO: Crawled 1572 pages (at 7 pages/min), scraped 1507 items (at 3 items/min)
2018-11-07 07:50:18 [scrapy.extensions.logstats] INFO: Crawled 1579 pages (at 7 pages/min), scraped 1517 items (at 10 items/min)
2018-11-07 07:51:20 [scrapy.extensions.logstats] INFO: Crawled 1592 pages (at 13 pages/min), scraped 1528 items (at 11 items/min)
2018-11-07 07:51:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.agcbio.com/privacy-policy>: HTTP status code is not handled or not allowed
2018-11-07 07:52:24 [scrapy.extensions.logstats] INFO: Crawled 1611 pages (at 19 pages/min), scraped 1539 items (at 11 items/min)
2018-11-07 07:53:19 [scrapy.extensions.logstats] INFO: Crawled 1620 pages (at 9 pages/min), scraped 1552 items (at 13 items/min)
2018-11-07 07:53:51 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/brands/novelio/easyfix>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:53:51 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/brands/novelio/mold-x>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:53:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://supportforums.adtran.com/welcome>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 07:54:27 [scrapy.extensions.logstats] INFO: Crawled 1627 pages (at 7 pages/min), scraped 1565 items (at 13 items/min)
2018-11-07 07:54:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/building-products/wall-finishing-accessories/sanding-screens>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:54:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/building-products/window-door-manufacturers/pollen-guard-screen>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:54:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/building-products/wall-finishing-tapes/fibatape-cement-board-tape>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:54:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/road-reinforcement/reinforcement-grids/roads-highways>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:54:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://adlens.com/pages/delivery-returns>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:55:30 [scrapy.extensions.logstats] INFO: Crawled 1641 pages (at 14 pages/min), scraped 1574 items (at 9 items/min)
2018-11-07 07:55:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://adlens.com/pages/90-day-hassle-free-trial>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 07:55:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/building-products>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:55:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/industrial-fabrics/specialty/esf-technology>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:55:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/building-products/exterior-reinforcement>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:55:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/building-products/insect-screens>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:56:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.adobe.com/au/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 07:56:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.adobe.com/il_he/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 07:56:05 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/industrial-fabrics/interiorexterior-reinforcement/cement-board>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:56:05 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/product-installation-instructions>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:56:05 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/industrial-fabrics/composite-reinforcement/fiberglass-tank>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:56:05 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.adfors.com/us/industrial-fabrics/composite-reinforcement/fg-reinforced-pipe>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 07:56:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <406 http://akronpolysys.com/>: HTTP status code is not handled or not allowed
2018-11-07 07:56:27 [scrapy.extensions.logstats] INFO: Crawled 1664 pages (at 23 pages/min), scraped 1586 items (at 12 items/min)
2018-11-07 07:57:26 [scrapy.extensions.logstats] INFO: Crawled 1683 pages (at 19 pages/min), scraped 1599 items (at 13 items/min)
2018-11-07 07:58:19 [scrapy.extensions.logstats] INFO: Crawled 1689 pages (at 6 pages/min), scraped 1606 items (at 7 items/min)
2018-11-07 07:59:26 [scrapy.extensions.logstats] INFO: Crawled 1696 pages (at 7 pages/min), scraped 1615 items (at 9 items/min)
2018-11-07 08:00:50 [scrapy.extensions.logstats] INFO: Crawled 1711 pages (at 15 pages/min), scraped 1625 items (at 10 items/min)
2018-11-07 08:00:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/about/features/crosslab-clean.html> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:01:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/about/features/biopharma-fight-cancer.html> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:01:33 [scrapy.extensions.logstats] INFO: Crawled 1715 pages (at 4 pages/min), scraped 1631 items (at 6 items/min)
2018-11-07 08:02:19 [scrapy.extensions.logstats] INFO: Crawled 1723 pages (at 8 pages/min), scraped 1638 items (at 7 items/min)
2018-11-07 08:04:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en-us/training-events> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:04:03 [scrapy.extensions.logstats] INFO: Crawled 1731 pages (at 8 pages/min), scraped 1649 items (at 11 items/min)
2018-11-07 08:04:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://blog.agilent.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:04:39 [scrapy.extensions.logstats] INFO: Crawled 1739 pages (at 8 pages/min), scraped 1653 items (at 4 items/min)
2018-11-07 08:05:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://eprocurement.agilent.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:05:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/about/features/research-cell-metabolism.html> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:05:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/about/features/raman-spectroscopy.html> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:05:36 [scrapy.extensions.logstats] INFO: Crawled 1746 pages (at 7 pages/min), scraped 1659 items (at 6 items/min)
2018-11-07 08:06:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://blog.agilent.com/social-hub/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:06:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/about/features/diagnostics-fight-cancer.html> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:06:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/about/features/food-contamination.html> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:06:23 [scrapy.extensions.logstats] INFO: Crawled 1752 pages (at 6 pages/min), scraped 1663 items (at 4 items/min)
2018-11-07 08:06:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/product/amplicon-based-next-generation-sequencing-(ngs)/amplicon-amplification-assay> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:06:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en-us/newsletters/data-integrity-insights-newsletter> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:06:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/newsletters/agilentinsights> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:07:22 [scrapy.extensions.logstats] INFO: Crawled 1760 pages (at 8 pages/min), scraped 1668 items (at 5 items/min)
2018-11-07 08:07:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/cell-reference-database/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:08:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/search/gn/syringe-selector> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:08:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/search/gn/vial-selector> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:08:53 [scrapy.extensions.logstats] INFO: Crawled 1778 pages (at 18 pages/min), scraped 1677 items (at 9 items/min)
2018-11-07 08:08:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/products/cell-analysis/seahorse-stress-test-dilution-calculator-app> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:09:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/publications-database/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:09:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/quality/index.shtml> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:09:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/promotions/applicationfinder> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:09:37 [scrapy.extensions.logstats] INFO: Crawled 1781 pages (at 3 pages/min), scraped 1680 items (at 3 items/min)
2018-11-07 08:10:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/services/instrument-service-agreements-for-dako-products> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:10:51 [scrapy.extensions.logstats] INFO: Crawled 1787 pages (at 6 pages/min), scraped 1685 items (at 5 items/min)
2018-11-07 08:11:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/services/instrument-services-dako-products> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:11:20 [scrapy.extensions.logstats] INFO: Crawled 1790 pages (at 3 pages/min), scraped 1687 items (at 2 items/min)
2018-11-07 08:11:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/services/deployment-services-for-dako-products> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:11:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/services/application-technical-support-for-dako-products> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:11:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://expwcsa4.cos.agilent.com:7003/cs/agilent/en/prozyme>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 110: Connection timed out.
2018-11-07 08:13:04 [scrapy.extensions.logstats] INFO: Crawled 1802 pages (at 12 pages/min), scraped 1696 items (at 9 items/min)
2018-11-07 08:13:36 [scrapy.extensions.logstats] INFO: Crawled 1806 pages (at 4 pages/min), scraped 1700 items (at 4 items/min)
2018-11-07 08:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/services/nucleic-acid-therapeutics/oligonucleotide-api-manufacturing> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:14:33 [scrapy.extensions.logstats] INFO: Crawled 1810 pages (at 4 pages/min), scraped 1705 items (at 5 items/min)
2018-11-07 08:15:56 [scrapy.extensions.logstats] INFO: Crawled 1818 pages (at 8 pages/min), scraped 1711 items (at 6 items/min)
2018-11-07 08:16:40 [scrapy.extensions.logstats] INFO: Crawled 1822 pages (at 4 pages/min), scraped 1715 items (at 4 items/min)
2018-11-07 08:17:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/cs/agilent/en-us/solutions/proteomics-sample-preparation-columns-supplies> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:17:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/cs/agilent/en-us/solutions/targeted-proteomics> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:17:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/cs/agilent/en-us/solutions/proteomics-data-analysis> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:17:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/cs/agilent/en-us/solutions/intact-protein-profiling> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:17:47 [scrapy.extensions.logstats] INFO: Crawled 1830 pages (at 8 pages/min), scraped 1719 items (at 4 items/min)
2018-11-07 08:18:25 [scrapy.extensions.logstats] INFO: Crawled 1833 pages (at 3 pages/min), scraped 1723 items (at 4 items/min)
2018-11-07 08:19:20 [scrapy.extensions.logstats] INFO: Crawled 1840 pages (at 7 pages/min), scraped 1729 items (at 6 items/min)
2018-11-07 08:20:41 [scrapy.extensions.logstats] INFO: Crawled 1846 pages (at 6 pages/min), scraped 1737 items (at 8 items/min)
2018-11-07 08:20:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en-us/solutions/clinical-grade-variant-assessment> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:20:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.agilent.com/en-us/solutions//refining/refinery-fuel-gas-analyzers>: HTTP status code is not handled or not allowed
2018-11-07 08:22:00 [scrapy.extensions.logstats] INFO: Crawled 1856 pages (at 10 pages/min), scraped 1744 items (at 7 items/min)
2018-11-07 08:22:26 [scrapy.extensions.logstats] INFO: Crawled 1859 pages (at 3 pages/min), scraped 1747 items (at 3 items/min)
2018-11-07 08:22:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/promotions/cancer-genetics> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:22:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en-us/solutions/environmental/soils-sludges-sediments> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:22:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en-us/solutions/environmental/environmental-exposure> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:23:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en-us/solutions/clinical-diagnostics> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:23:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/ngs-solutions-for-pathology> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:23:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/translational-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:23:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/pharma-biopharma/small-molecules> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:23:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/pharma-biopharma/biologics> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:23:33 [scrapy.extensions.logstats] INFO: Crawled 1870 pages (at 11 pages/min), scraped 1748 items (at 1 items/min)
2018-11-07 08:23:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/obesity-diabetes-metabolic-disorders> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:23:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/neurobiology-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:24:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/stem-cell-biology> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/model-organisms> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:24:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/mitochondrial-disease-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:24:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/cell-physiology-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:24:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/immunology-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:24:29 [scrapy.extensions.logstats] INFO: Crawled 1876 pages (at 6 pages/min), scraped 1748 items (at 0 items/min)
2018-11-07 08:24:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/cardiovascular-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:24:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/toxicology-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:25:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/drug-discovery> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:25:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en-us/academia> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:25:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/pathology-solutions-overview> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:25:21 [scrapy.extensions.logstats] INFO: Crawled 1881 pages (at 5 pages/min), scraped 1750 items (at 2 items/min)
2018-11-07 08:25:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/cancer-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:25:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/assays-under-hypoxic-conditions> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:26:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/dakolink-staining-management-software> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:26:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/solutions/cell-metabolism/aging-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:26:24 [scrapy.extensions.logstats] INFO: Crawled 1891 pages (at 10 pages/min), scraped 1754 items (at 4 items/min)
2018-11-07 08:27:24 [scrapy.extensions.logstats] INFO: Crawled 1899 pages (at 8 pages/min), scraped 1762 items (at 8 items/min)
2018-11-07 08:28:22 [scrapy.extensions.logstats] INFO: Crawled 1907 pages (at 8 pages/min), scraped 1770 items (at 8 items/min)
2018-11-07 08:29:24 [scrapy.extensions.logstats] INFO: Crawled 1914 pages (at 7 pages/min), scraped 1779 items (at 9 items/min)
2018-11-07 08:30:23 [scrapy.extensions.logstats] INFO: Crawled 1922 pages (at 8 pages/min), scraped 1785 items (at 6 items/min)
2018-11-07 08:31:25 [scrapy.extensions.logstats] INFO: Crawled 1928 pages (at 6 pages/min), scraped 1792 items (at 7 items/min)
2018-11-07 08:32:29 [scrapy.extensions.logstats] INFO: Crawled 1937 pages (at 9 pages/min), scraped 1800 items (at 8 items/min)
2018-11-07 08:33:26 [scrapy.extensions.logstats] INFO: Crawled 1943 pages (at 6 pages/min), scraped 1807 items (at 7 items/min)
2018-11-07 08:34:19 [scrapy.extensions.logstats] INFO: Crawled 1951 pages (at 8 pages/min), scraped 1814 items (at 7 items/min)
2018-11-07 08:35:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://careers.agilent.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 08:35:40 [scrapy.extensions.logstats] INFO: Crawled 1960 pages (at 9 pages/min), scraped 1823 items (at 9 items/min)
2018-11-07 08:36:29 [scrapy.extensions.logstats] INFO: Crawled 1976 pages (at 16 pages/min), scraped 1830 items (at 7 items/min)
2018-11-07 08:37:43 [scrapy.extensions.logstats] INFO: Crawled 1985 pages (at 9 pages/min), scraped 1842 items (at 12 items/min)
2018-11-07 08:40:14 [scrapy.extensions.logstats] INFO: Crawled 1985 pages (at 0 pages/min), scraped 1847 items (at 5 items/min)
2018-11-07 08:41:03 [scrapy.extensions.logstats] INFO: Crawled 1985 pages (at 0 pages/min), scraped 1851 items (at 4 items/min)
2018-11-07 08:41:27 [scrapy.extensions.logstats] INFO: Crawled 1995 pages (at 10 pages/min), scraped 1853 items (at 2 items/min)
2018-11-07 08:43:01 [scrapy.extensions.logstats] INFO: Crawled 2003 pages (at 8 pages/min), scraped 1861 items (at 8 items/min)
2018-11-07 08:43:44 [scrapy.extensions.logstats] INFO: Crawled 2003 pages (at 0 pages/min), scraped 1865 items (at 4 items/min)
2018-11-07 08:44:43 [scrapy.extensions.logstats] INFO: Crawled 2003 pages (at 0 pages/min), scraped 1869 items (at 4 items/min)
2018-11-07 08:45:41 [scrapy.extensions.logstats] INFO: Crawled 2016 pages (at 13 pages/min), scraped 1874 items (at 5 items/min)
2018-11-07 08:46:29 [scrapy.extensions.logstats] INFO: Crawled 2020 pages (at 4 pages/min), scraped 1878 items (at 4 items/min)
2018-11-07 08:47:21 [scrapy.extensions.logstats] INFO: Crawled 2020 pages (at 0 pages/min), scraped 1882 items (at 4 items/min)
2018-11-07 08:48:22 [scrapy.extensions.logstats] INFO: Crawled 2026 pages (at 6 pages/min), scraped 1887 items (at 5 items/min)
2018-11-07 08:50:07 [scrapy.extensions.logstats] INFO: Crawled 2038 pages (at 12 pages/min), scraped 1896 items (at 9 items/min)
2018-11-07 08:50:49 [scrapy.extensions.logstats] INFO: Crawled 2038 pages (at 0 pages/min), scraped 1900 items (at 4 items/min)
2018-11-07 08:51:40 [scrapy.extensions.logstats] INFO: Crawled 2038 pages (at 0 pages/min), scraped 1904 items (at 4 items/min)
2018-11-07 08:52:34 [scrapy.extensions.logstats] INFO: Crawled 2051 pages (at 13 pages/min), scraped 1909 items (at 5 items/min)
2018-11-07 08:53:23 [scrapy.extensions.logstats] INFO: Crawled 2055 pages (at 4 pages/min), scraped 1913 items (at 4 items/min)
2018-11-07 08:54:52 [scrapy.extensions.logstats] INFO: Crawled 2055 pages (at 0 pages/min), scraped 1921 items (at 8 items/min)
2018-11-07 08:55:20 [scrapy.extensions.logstats] INFO: Crawled 2064 pages (at 9 pages/min), scraped 1923 items (at 2 items/min)
2018-11-07 08:56:57 [scrapy.extensions.logstats] INFO: Crawled 2072 pages (at 8 pages/min), scraped 1930 items (at 7 items/min)
2018-11-07 08:57:42 [scrapy.extensions.logstats] INFO: Crawled 2072 pages (at 0 pages/min), scraped 1934 items (at 4 items/min)
2018-11-07 08:58:40 [scrapy.extensions.logstats] INFO: Crawled 2072 pages (at 0 pages/min), scraped 1938 items (at 4 items/min)
2018-11-07 08:59:39 [scrapy.extensions.logstats] INFO: Crawled 2084 pages (at 12 pages/min), scraped 1943 items (at 5 items/min)
2018-11-07 09:01:03 [scrapy.extensions.logstats] INFO: Crawled 2088 pages (at 4 pages/min), scraped 1950 items (at 7 items/min)
2018-11-07 09:01:50 [scrapy.extensions.logstats] INFO: Crawled 2088 pages (at 0 pages/min), scraped 1954 items (at 4 items/min)
2018-11-07 09:02:31 [scrapy.extensions.logstats] INFO: Crawled 2098 pages (at 10 pages/min), scraped 1958 items (at 4 items/min)
2018-11-07 09:03:42 [scrapy.extensions.logstats] INFO: Crawled 2107 pages (at 9 pages/min), scraped 1965 items (at 7 items/min)
2018-11-07 09:04:23 [scrapy.extensions.logstats] INFO: Crawled 2107 pages (at 0 pages/min), scraped 1969 items (at 4 items/min)
2018-11-07 09:05:20 [scrapy.extensions.logstats] INFO: Crawled 2114 pages (at 7 pages/min), scraped 1976 items (at 7 items/min)
2018-11-07 09:06:19 [scrapy.extensions.logstats] INFO: Crawled 2119 pages (at 5 pages/min), scraped 1984 items (at 8 items/min)
2018-11-07 09:07:23 [scrapy.extensions.logstats] INFO: Crawled 2128 pages (at 9 pages/min), scraped 1993 items (at 9 items/min)
2018-11-07 09:08:27 [scrapy.extensions.logstats] INFO: Crawled 2137 pages (at 9 pages/min), scraped 2002 items (at 9 items/min)
2018-11-07 09:09:23 [scrapy.extensions.logstats] INFO: Crawled 2145 pages (at 8 pages/min), scraped 2010 items (at 8 items/min)
2018-11-07 09:10:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://wpwwwp1.agfa.be/corporate>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 975, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: wpwwwp1.agfa.be.
2018-11-07 09:10:23 [scrapy.extensions.logstats] INFO: Crawled 2152 pages (at 7 pages/min), scraped 2018 items (at 8 items/min)
2018-11-07 09:11:25 [scrapy.extensions.logstats] INFO: Crawled 2164 pages (at 12 pages/min), scraped 2027 items (at 9 items/min)
2018-11-07 09:12:50 [scrapy.extensions.logstats] INFO: Crawled 2182 pages (at 18 pages/min), scraped 2044 items (at 17 items/min)
2018-11-07 09:13:20 [scrapy.extensions.logstats] INFO: Crawled 2192 pages (at 10 pages/min), scraped 2052 items (at 8 items/min)
2018-11-07 09:14:20 [scrapy.extensions.logstats] INFO: Crawled 2208 pages (at 16 pages/min), scraped 2064 items (at 12 items/min)
2018-11-07 09:15:21 [scrapy.extensions.logstats] INFO: Crawled 2223 pages (at 15 pages/min), scraped 2079 items (at 15 items/min)
2018-11-07 09:15:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.agtc.com/financial-information> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:15:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.agtc.com/investor-faqs> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:15:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.agtc.com/stock-information> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:16:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.agtc.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:16:21 [scrapy.extensions.logstats] INFO: Crawled 2230 pages (at 7 pages/min), scraped 2088 items (at 9 items/min)
2018-11-07 09:17:43 [scrapy.extensions.logstats] INFO: Crawled 2238 pages (at 8 pages/min), scraped 2100 items (at 12 items/min)
2018-11-07 09:19:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agcglass.com/projects> (referer: https://www.agcglass.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: Browsing context has been discarded

2018-11-07 09:19:12 [scrapy.extensions.logstats] INFO: Crawled 2251 pages (at 13 pages/min), scraped 2110 items (at 10 items/min)
2018-11-07 09:19:26 [scrapy.extensions.logstats] INFO: Crawled 2251 pages (at 0 pages/min), scraped 2112 items (at 2 items/min)
2018-11-07 09:20:24 [scrapy.extensions.logstats] INFO: Crawled 2259 pages (at 8 pages/min), scraped 2120 items (at 8 items/min)
2018-11-07 09:21:25 [scrapy.extensions.logstats] INFO: Crawled 2267 pages (at 8 pages/min), scraped 2128 items (at 8 items/min)
2018-11-07 09:22:34 [scrapy.extensions.logstats] INFO: Crawled 2275 pages (at 8 pages/min), scraped 2136 items (at 8 items/min)
2018-11-07 09:23:43 [scrapy.extensions.logstats] INFO: Crawled 2282 pages (at 7 pages/min), scraped 2143 items (at 7 items/min)
2018-11-07 09:25:52 [scrapy.extensions.logstats] INFO: Crawled 2302 pages (at 20 pages/min), scraped 2148 items (at 5 items/min)
2018-11-07 09:26:36 [scrapy.extensions.logstats] INFO: Crawled 2306 pages (at 4 pages/min), scraped 2155 items (at 7 items/min)
2018-11-07 09:27:30 [scrapy.extensions.logstats] INFO: Crawled 2306 pages (at 0 pages/min), scraped 2163 items (at 8 items/min)
2018-11-07 09:28:20 [scrapy.extensions.logstats] INFO: Crawled 2322 pages (at 16 pages/min), scraped 2176 items (at 13 items/min)
2018-11-07 09:29:23 [scrapy.extensions.logstats] INFO: Crawled 2330 pages (at 8 pages/min), scraped 2189 items (at 13 items/min)
2018-11-07 09:30:24 [scrapy.extensions.logstats] INFO: Crawled 2348 pages (at 18 pages/min), scraped 2204 items (at 15 items/min)
2018-11-07 09:31:23 [scrapy.extensions.logstats] INFO: Crawled 2368 pages (at 20 pages/min), scraped 2219 items (at 15 items/min)
2018-11-07 09:31:43 [root] ERROR: Unable to find match for url: https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25091&siteid=5105
2018-11-07 09:32:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://agriculture.basf.com/content/bws/north-america/us/en/we-create-chemistry.html>: HTTP status code is not handled or not allowed
2018-11-07 09:32:35 [scrapy.extensions.logstats] INFO: Crawled 2396 pages (at 28 pages/min), scraped 2238 items (at 19 items/min)
2018-11-07 09:33:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://agriculture.basf.com/content/bws/north-america/us/en/company.html>: HTTP status code is not handled or not allowed
2018-11-07 09:33:20 [scrapy.extensions.logstats] INFO: Crawled 2400 pages (at 4 pages/min), scraped 2247 items (at 9 items/min)
2018-11-07 09:34:19 [scrapy.extensions.logstats] INFO: Crawled 2408 pages (at 8 pages/min), scraped 2263 items (at 16 items/min)
2018-11-07 09:35:21 [scrapy.extensions.logstats] INFO: Crawled 2425 pages (at 17 pages/min), scraped 2280 items (at 17 items/min)
2018-11-07 09:36:29 [scrapy.extensions.logstats] INFO: Crawled 2445 pages (at 20 pages/min), scraped 2297 items (at 17 items/min)
2018-11-07 09:37:30 [scrapy.extensions.logstats] INFO: Crawled 2454 pages (at 9 pages/min), scraped 2312 items (at 15 items/min)
2018-11-07 09:38:18 [scrapy.extensions.logstats] INFO: Crawled 2465 pages (at 11 pages/min), scraped 2319 items (at 7 items/min)
2018-11-07 09:39:24 [scrapy.extensions.logstats] INFO: Crawled 2474 pages (at 9 pages/min), scraped 2330 items (at 11 items/min)
2018-11-07 09:40:18 [scrapy.extensions.logstats] INFO: Crawled 2494 pages (at 20 pages/min), scraped 2343 items (at 13 items/min)
2018-11-07 09:41:26 [scrapy.extensions.logstats] INFO: Crawled 2499 pages (at 5 pages/min), scraped 2356 items (at 13 items/min)
2018-11-07 09:43:19 [scrapy.extensions.logstats] INFO: Crawled 2504 pages (at 5 pages/min), scraped 2358 items (at 2 items/min)
2018-11-07 09:44:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.investor.agilent.com/phoenix.zhtml?c=103274&p=irol-irhome> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:44:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/promotions/human-reproductive-genetics> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:44:56 [scrapy.extensions.logstats] INFO: Crawled 2524 pages (at 20 pages/min), scraped 2369 items (at 11 items/min)
2018-11-07 09:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/promotions/analyzing-substances-through-opaque-barriers> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:45:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/promotions/life-science> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:45:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/products/genomics-agilent> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:45:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/products/genomics-agilent> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:46:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.agilent.com/en/products/genomics-agilent> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:46:15 [scrapy.extensions.logstats] INFO: Crawled 2524 pages (at 0 pages/min), scraped 2372 items (at 3 items/min)
2018-11-07 09:46:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://metabolomics.chem.agilent.com/Data-Analysis/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 975, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: metabolomics.chem.agilent.com.
2018-11-07 09:46:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://alcotek.com>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:46:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://alcotek.com/contact-us/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:46:36 [scrapy.extensions.logstats] INFO: Crawled 2525 pages (at 1 pages/min), scraped 2376 items (at 4 items/min)
2018-11-07 09:46:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://alcotek.com/what-we-do/science>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:46:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://metabolomics.chem.agilent.com/Frontiers/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 975, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: metabolomics.chem.agilent.com.
2018-11-07 09:46:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://metabolomics.chem.agilent.com/Knowledge-Center/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 975, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: metabolomics.chem.agilent.com.
2018-11-07 09:46:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://alcotek.com/employment/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:46:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://metabolomics.chem.agilent.com/Practical-Guide-to-Metabolomics/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 975, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: metabolomics.chem.agilent.com.
2018-11-07 09:47:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://alcotek.com/what-we-do/manufacturing>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 09:47:25 [scrapy.extensions.logstats] INFO: Crawled 2535 pages (at 10 pages/min), scraped 2382 items (at 6 items/min)
2018-11-07 09:47:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://alcotek.com/about-us/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:47:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://alcotek.com/who-we-serve/law-enforcement/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:47:32 [scrapy.core.scraper] ERROR: Error downloading <GET http://agienic.com/?start=5>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 09:47:32 [scrapy.core.scraper] ERROR: Error downloading <GET http://agienic.com/?start=10>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 09:47:32 [scrapy.core.scraper] ERROR: Error downloading <GET http://agienic.com/29-fruit-shop-site>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 09:49:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.agrofresh.com/technologies/freshcloud/predictive-screening/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:49:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.agrofresh.com/markets/growers/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:49:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.agrofresh.com/resources/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:49:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.agrofresh.com/about-us/r-and-d-centers/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:49:15 [scrapy.extensions.logstats] INFO: Crawled 2542 pages (at 7 pages/min), scraped 2393 items (at 11 items/min)
2018-11-07 09:49:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.agrofresh.com/technologies/freshcloud/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 09:49:23 [scrapy.extensions.logstats] INFO: Crawled 2552 pages (at 10 pages/min), scraped 2394 items (at 1 items/min)
2018-11-07 09:49:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://alenconsystems.com/tel:8884107915>: HTTP status code is not handled or not allowed
2018-11-07 09:50:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://allergytherapeutics.com/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 09:50:27 [scrapy.extensions.logstats] INFO: Crawled 2574 pages (at 22 pages/min), scraped 2413 items (at 19 items/min)
2018-11-07 09:51:42 [scrapy.extensions.logstats] INFO: Crawled 2585 pages (at 11 pages/min), scraped 2430 items (at 17 items/min)
2018-11-07 09:52:27 [scrapy.extensions.logstats] INFO: Crawled 2593 pages (at 8 pages/min), scraped 2435 items (at 5 items/min)
2018-11-07 09:52:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://allisontransmission.com/cookies?utm_source=WebFooter&utm_content=Cookies_EN> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:53:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-infoReq> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:53:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.allisontransmission.com/parts-service/remanufactured-transmissions> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:53:41 [scrapy.extensions.logstats] INFO: Crawled 2608 pages (at 15 pages/min), scraped 2441 items (at 6 items/min)
2018-11-07 09:53:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-govBoard> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:53:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-faq> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:53:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-stockQuote> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:54:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.allisontransmission.com/home/fuelsense> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:54:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.allisontransmission.com/company/news-article/!details/2016/03/02/allison-transmission-launches-redesigned-mobile-app> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:54:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-analysts> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:54:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-sec> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:54:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-presentations> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:54:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-govHighlights> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:54:55 [scrapy.extensions.logstats] INFO: Crawled 2615 pages (at 7 pages/min), scraped 2445 items (at 4 items/min)
2018-11-07 09:54:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-calendar> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:55:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=proxy> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:55:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-news&nyo=0> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:55:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.allisontransmission.com/phoenix.zhtml?c=227924&p=irol-irhome> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 09:55:35 [scrapy.extensions.logstats] INFO: Crawled 2619 pages (at 4 pages/min), scraped 2448 items (at 3 items/min)
2018-11-07 09:56:42 [scrapy.extensions.logstats] INFO: Crawled 2626 pages (at 7 pages/min), scraped 2456 items (at 8 items/min)
2018-11-07 09:57:36 [scrapy.extensions.logstats] INFO: Crawled 2633 pages (at 7 pages/min), scraped 2463 items (at 7 items/min)
2018-11-07 09:58:37 [scrapy.extensions.logstats] INFO: Crawled 2641 pages (at 8 pages/min), scraped 2470 items (at 7 items/min)
2018-11-07 09:59:19 [scrapy.extensions.logstats] INFO: Crawled 2645 pages (at 4 pages/min), scraped 2475 items (at 5 items/min)
2018-11-07 10:00:43 [scrapy.extensions.logstats] INFO: Crawled 2660 pages (at 15 pages/min), scraped 2486 items (at 11 items/min)
2018-11-07 10:01:20 [scrapy.extensions.logstats] INFO: Crawled 2664 pages (at 4 pages/min), scraped 2491 items (at 5 items/min)
2018-11-07 10:02:41 [scrapy.extensions.logstats] INFO: Crawled 2672 pages (at 8 pages/min), scraped 2501 items (at 10 items/min)
2018-11-07 10:03:22 [scrapy.extensions.logstats] INFO: Crawled 2676 pages (at 4 pages/min), scraped 2506 items (at 5 items/min)
2018-11-07 10:04:37 [scrapy.extensions.logstats] INFO: Crawled 2695 pages (at 19 pages/min), scraped 2518 items (at 12 items/min)
2018-11-07 10:05:15 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "www.algeternal.com"; VerificationError(errors=[DNSMismatch(mismatched_id=DNS_ID(hostname=b'www.algeternal.com'))])
2018-11-07 10:05:19 [scrapy.extensions.logstats] INFO: Crawled 2696 pages (at 1 pages/min), scraped 2526 items (at 8 items/min)
2018-11-07 10:06:24 [scrapy.extensions.logstats] INFO: Crawled 2723 pages (at 27 pages/min), scraped 2547 items (at 21 items/min)
2018-11-07 10:07:24 [scrapy.extensions.logstats] INFO: Crawled 2736 pages (at 13 pages/min), scraped 2565 items (at 18 items/min)
2018-11-07 10:08:21 [scrapy.extensions.logstats] INFO: Crawled 2752 pages (at 16 pages/min), scraped 2582 items (at 17 items/min)
2018-11-07 10:09:26 [scrapy.extensions.logstats] INFO: Crawled 2779 pages (at 27 pages/min), scraped 2602 items (at 20 items/min)
2018-11-07 10:10:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://algenol.com/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 10:10:23 [scrapy.extensions.logstats] INFO: Crawled 2791 pages (at 12 pages/min), scraped 2620 items (at 18 items/min)
2018-11-07 10:11:24 [scrapy.extensions.logstats] INFO: Crawled 2821 pages (at 30 pages/min), scraped 2636 items (at 16 items/min)
2018-11-07 10:12:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ampiopharma.com/privacy-policy/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:12:19 [scrapy.extensions.logstats] INFO: Crawled 2842 pages (at 21 pages/min), scraped 2648 items (at 12 items/min)
2018-11-07 10:12:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ampiopharma.com/pipeline/optina/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:12:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/news-releases/news-release-details/amicus-therapeutics-host-analyst-day-2018-today-new-york-city> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:12:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/news-releases/news-release-details/amicus-therapeutics-enters-research-and-development> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:12:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/news-releases/news-release-details/amicus-therapeutics-announces-positive-18-month-data-pompe> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:12:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/news-releases/news-release-details/amicus-therapeutics-announce-third-quarter-2018-financial> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:12:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/news-releases/news-release-details/amicus-therapeutics-announces-third-quarter-2018-financial> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:13:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ampiopharma.com/pipeline/ampion/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:13:31 [scrapy.extensions.logstats] INFO: Crawled 2855 pages (at 13 pages/min), scraped 2658 items (at 10 items/min)
2018-11-07 10:13:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.biotechnology.amgen.com> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:13:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://services.transport.alstom.com/s/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:14:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://careers.amgen.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:14:26 [scrapy.extensions.logstats] INFO: Crawled 2875 pages (at 20 pages/min), scraped 2668 items (at 10 items/min)
2018-11-07 10:15:36 [scrapy.extensions.logstats] INFO: Crawled 2884 pages (at 9 pages/min), scraped 2684 items (at 16 items/min)
2018-11-07 10:16:22 [scrapy.extensions.logstats] INFO: Crawled 2901 pages (at 17 pages/min), scraped 2697 items (at 13 items/min)
2018-11-07 10:17:23 [scrapy.extensions.logstats] INFO: Crawled 2913 pages (at 12 pages/min), scraped 2713 items (at 16 items/min)
2018-11-07 10:18:22 [scrapy.extensions.logstats] INFO: Crawled 2932 pages (at 19 pages/min), scraped 2728 items (at 15 items/min)
2018-11-07 10:19:30 [scrapy.extensions.logstats] INFO: Crawled 2944 pages (at 12 pages/min), scraped 2744 items (at 16 items/min)
2018-11-07 10:20:25 [scrapy.extensions.logstats] INFO: Crawled 2956 pages (at 12 pages/min), scraped 2756 items (at 12 items/min)
2018-11-07 10:21:34 [scrapy.extensions.logstats] INFO: Crawled 2975 pages (at 19 pages/min), scraped 2772 items (at 16 items/min)
2018-11-07 10:21:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/investor-faqs> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:21:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/stock-information> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:21:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/contact-us> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:21:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/email-alerts> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:22:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/events-and-presentations> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:22:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/press-releases> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:22:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/financial-information/sec-filings> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:22:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/annual-reports-and-proxies> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:22:28 [scrapy.extensions.logstats] INFO: Crawled 2984 pages (at 9 pages/min), scraped 2778 items (at 6 items/min)
2018-11-07 10:22:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amicusrx.com/corporate-governance> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:23:26 [scrapy.extensions.logstats] INFO: Crawled 3002 pages (at 18 pages/min), scraped 2789 items (at 11 items/min)
2018-11-07 10:24:29 [scrapy.extensions.logstats] INFO: Crawled 3013 pages (at 11 pages/min), scraped 2801 items (at 12 items/min)
2018-11-07 10:25:28 [scrapy.extensions.logstats] INFO: Crawled 3015 pages (at 2 pages/min), scraped 2807 items (at 6 items/min)
2018-11-07 10:26:20 [scrapy.extensions.logstats] INFO: Crawled 3028 pages (at 13 pages/min), scraped 2814 items (at 7 items/min)
2018-11-07 10:27:23 [scrapy.extensions.logstats] INFO: Crawled 3032 pages (at 4 pages/min), scraped 2822 items (at 8 items/min)
2018-11-07 10:29:16 [scrapy.extensions.logstats] INFO: Crawled 3049 pages (at 17 pages/min), scraped 2839 items (at 17 items/min)
2018-11-07 10:29:34 [scrapy.extensions.logstats] INFO: Crawled 3049 pages (at 0 pages/min), scraped 2843 items (at 4 items/min)
2018-11-07 10:30:20 [scrapy.extensions.logstats] INFO: Crawled 3069 pages (at 20 pages/min), scraped 2856 items (at 13 items/min)
2018-11-07 10:31:40 [scrapy.extensions.logstats] INFO: Crawled 3087 pages (at 18 pages/min), scraped 2877 items (at 21 items/min)
2018-11-07 10:32:58 [scrapy.extensions.logstats] INFO: Crawled 3104 pages (at 17 pages/min), scraped 2895 items (at 18 items/min)
2018-11-07 10:34:07 [scrapy.extensions.logstats] INFO: Crawled 3123 pages (at 19 pages/min), scraped 2913 items (at 18 items/min)
2018-11-07 10:34:23 [scrapy.extensions.logstats] INFO: Crawled 3123 pages (at 0 pages/min), scraped 2917 items (at 4 items/min)
2018-11-07 10:35:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amkor.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:35:29 [scrapy.extensions.logstats] INFO: Crawled 3143 pages (at 20 pages/min), scraped 2932 items (at 15 items/min)
2018-11-07 10:35:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://ambature.com/what-we-could-do/>: HTTP status code is not handled or not allowed
2018-11-07 10:36:27 [scrapy.extensions.logstats] INFO: Crawled 3157 pages (at 14 pages/min), scraped 2944 items (at 12 items/min)
2018-11-07 10:37:41 [scrapy.extensions.logstats] INFO: Crawled 3171 pages (at 14 pages/min), scraped 2962 items (at 18 items/min)
2018-11-07 10:38:33 [scrapy.extensions.logstats] INFO: Crawled 3192 pages (at 21 pages/min), scraped 2975 items (at 13 items/min)
2018-11-07 10:39:27 [scrapy.extensions.logstats] INFO: Crawled 3206 pages (at 14 pages/min), scraped 2989 items (at 14 items/min)
2018-11-07 10:40:25 [scrapy.extensions.logstats] INFO: Crawled 3214 pages (at 8 pages/min), scraped 3000 items (at 11 items/min)
2018-11-07 10:41:49 [scrapy.extensions.logstats] INFO: Crawled 3227 pages (at 13 pages/min), scraped 3015 items (at 15 items/min)
2018-11-07 10:42:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.allpowerlabs.com/Sneak%20Peeks:%20Local%20Carbon%20Network-%20Italy%20Launch.%20X-Prize%20Watertainer%20at%20Verge%20Conference%20in%20Oakland>: HTTP status code is not handled or not allowed
2018-11-07 10:42:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.allpowerlabs.com/Sneak%20Peeks:%20Local%20Carbon%20Network-%20Italy%20Launch.%20X-Prize%20Watertainer%20at%20Verge%20Conference%20in%20Oakland%3EAPL%20NEWS%20BLOG%20INDEX%3C/strong%3E%3C/a%3E%3C/div%3E%0A%09%09%3C/div%3E%09%09%3Cdiv%20id=>: HTTP status code is not handled or not allowed
2018-11-07 10:42:23 [scrapy.extensions.logstats] INFO: Crawled 3236 pages (at 9 pages/min), scraped 3021 items (at 6 items/min)
2018-11-07 10:42:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <418 http://www.allpowerlabs.com/people/gek-users/industry-forestry-ranching-and-farming>: HTTP status code is not handled or not allowed
2018-11-07 10:43:20 [scrapy.extensions.logstats] INFO: Crawled 3250 pages (at 14 pages/min), scraped 3034 items (at 13 items/min)
2018-11-07 10:43:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <418 http://www.allpowerlabs.com/about-apl>: HTTP status code is not handled or not allowed
2018-11-07 10:44:26 [scrapy.extensions.logstats] INFO: Crawled 3265 pages (at 15 pages/min), scraped 3049 items (at 15 items/min)
2018-11-07 10:45:24 [scrapy.extensions.logstats] INFO: Crawled 3281 pages (at 16 pages/min), scraped 3061 items (at 12 items/min)
2018-11-07 10:46:42 [scrapy.extensions.logstats] INFO: Crawled 3298 pages (at 17 pages/min), scraped 3080 items (at 19 items/min)
2018-11-07 10:47:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.amkor.com/press-releases> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:47:46 [scrapy.extensions.logstats] INFO: Crawled 3315 pages (at 17 pages/min), scraped 3098 items (at 18 items/min)
2018-11-07 10:48:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://investors.amgen.com/phoenix.zhtml?c=61656&p=irol-IRHome> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 10:49:39 [scrapy.extensions.logstats] INFO: Crawled 3335 pages (at 20 pages/min), scraped 3113 items (at 15 items/min)
2018-11-07 10:50:22 [scrapy.extensions.logstats] INFO: Crawled 3335 pages (at 0 pages/min), scraped 3119 items (at 6 items/min)
2018-11-07 10:51:48 [scrapy.extensions.logstats] INFO: Crawled 3343 pages (at 8 pages/min), scraped 3128 items (at 9 items/min)
2018-11-07 10:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.amicusrx.com/advocacy/disease-resources/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 10:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.amicusrx.com/advocacy/community-support/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 10:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.amicusrx.com/advocacy/advisory-boards/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 10:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://altabira.com/altabira-gift-certificates/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 10:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://altabira.com/draft-beer-list/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 10:52:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://allurausa.com/remodelers>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 10:52:55 [scrapy.extensions.logstats] INFO: Crawled 3359 pages (at 16 pages/min), scraped 3137 items (at 9 items/min)
2018-11-07 10:53:41 [scrapy.extensions.logstats] INFO: Crawled 3359 pages (at 0 pages/min), scraped 3143 items (at 6 items/min)
2018-11-07 10:53:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://altabira.com/altabira-newsletter/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-07 10:54:20 [scrapy.extensions.logstats] INFO: Crawled 3389 pages (at 30 pages/min), scraped 3149 items (at 6 items/min)
2018-11-07 10:55:37 [scrapy.extensions.logstats] INFO: Crawled 3395 pages (at 6 pages/min), scraped 3164 items (at 15 items/min)
2018-11-07 10:56:22 [scrapy.extensions.logstats] INFO: Crawled 3408 pages (at 13 pages/min), scraped 3174 items (at 10 items/min)
2018-11-07 10:57:20 [scrapy.extensions.logstats] INFO: Crawled 3422 pages (at 14 pages/min), scraped 3185 items (at 11 items/min)
2018-11-07 10:58:27 [scrapy.extensions.logstats] INFO: Crawled 3430 pages (at 8 pages/min), scraped 3198 items (at 13 items/min)
2018-11-07 10:59:23 [scrapy.extensions.logstats] INFO: Crawled 3450 pages (at 20 pages/min), scraped 3211 items (at 13 items/min)
2018-11-07 11:00:20 [scrapy.extensions.logstats] INFO: Crawled 3462 pages (at 12 pages/min), scraped 3224 items (at 13 items/min)
2018-11-07 11:01:22 [scrapy.extensions.logstats] INFO: Crawled 3476 pages (at 14 pages/min), scraped 3239 items (at 15 items/min)
2018-11-07 11:02:25 [scrapy.extensions.logstats] INFO: Crawled 3493 pages (at 17 pages/min), scraped 3253 items (at 14 items/min)
2018-11-07 11:03:21 [scrapy.extensions.logstats] INFO: Crawled 3505 pages (at 12 pages/min), scraped 3267 items (at 14 items/min)
2018-11-07 11:04:19 [scrapy.extensions.logstats] INFO: Crawled 3521 pages (at 16 pages/min), scraped 3282 items (at 15 items/min)
2018-11-07 11:05:26 [scrapy.extensions.logstats] INFO: Crawled 3534 pages (at 13 pages/min), scraped 3301 items (at 19 items/min)
2018-11-07 11:05:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <418 http://www.ansunbiopharma.com/publications/>: HTTP status code is not handled or not allowed
2018-11-07 11:06:36 [scrapy.extensions.logstats] INFO: Crawled 3560 pages (at 26 pages/min), scraped 3323 items (at 22 items/min)
2018-11-07 11:07:22 [scrapy.extensions.logstats] INFO: Crawled 3576 pages (at 16 pages/min), scraped 3340 items (at 17 items/min)
2018-11-07 11:08:22 [scrapy.extensions.logstats] INFO: Crawled 3598 pages (at 22 pages/min), scraped 3362 items (at 22 items/min)
2018-11-07 11:09:37 [scrapy.extensions.logstats] INFO: Crawled 3615 pages (at 17 pages/min), scraped 3379 items (at 17 items/min)
2018-11-07 11:10:21 [scrapy.extensions.logstats] INFO: Crawled 3631 pages (at 16 pages/min), scraped 3391 items (at 12 items/min)
2018-11-07 11:10:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://investor.analog.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:11:23 [scrapy.extensions.logstats] INFO: Crawled 3645 pages (at 14 pages/min), scraped 3408 items (at 17 items/min)
2018-11-07 11:12:22 [scrapy.extensions.logstats] INFO: Crawled 3660 pages (at 15 pages/min), scraped 3425 items (at 17 items/min)
2018-11-07 11:12:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://registration.analog.com/login/login.aspx?target=aHR0cHM6Ly9lYml6LnNzby5hbmFsb2cuY29tL2ludGVybmV0L3dzdHJ1c3QvP3dhPXdzaWduaW4xLjAmd3RyZWFsbT1odHRwczovL215LmFuYWxvZy5jb20vJndjdHg9cm09MCZpZD05ZmExOTcyNC1kMzZjLTQ4ZDEtODg2Yi03MDE4YjNiM2M2OGMmcnU9JTI1MmZlbiUyNTJmbXlhbmFsb2clMjUyZm1hbmFnZS11cGRhdGVzJTI1MmZtYW5hZ2UtbmV3c2xldHRlcnMuaHRtbCZ3Y3Q9MjAxOC0xMS0wN1QxMTowODozMlomd3JlcGx5PWh0dHBzOi8vbXkuYW5hbG9nLmNvbS9TU08vU1NPSGFuZGxlci5hc2h4&>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 11:12:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.analog.com/en/products/ltc5556.html?icid=LTC5556_en_hp> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.analog.com/en/analog-dialogue.html?icid=analog-dialogue-october2018_en_hp> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:13:20 [scrapy.extensions.logstats] INFO: Crawled 3682 pages (at 22 pages/min), scraped 3439 items (at 14 items/min)
2018-11-07 11:14:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://investor.apple.com/investor-relations/default.aspx> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:14:21 [scrapy.extensions.logstats] INFO: Crawled 3697 pages (at 15 pages/min), scraped 3460 items (at 21 items/min)
2018-11-07 11:14:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.apple.com/legal/privacy/en-ww/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:14:48 [scrapy.core.scraper] ERROR: Error downloading <GET itmss://itunes.apple.com/us/movie/the-greatest-showman/id1324419603>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py", line 64, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme 'itmss': no handler available for that scheme
2018-11-07 11:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.apple.com/connectED/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:15:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.apple.com/us-hed/shop> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:15:20 [scrapy.extensions.logstats] INFO: Crawled 3719 pages (at 22 pages/min), scraped 3476 items (at 16 items/min)
2018-11-07 11:16:28 [scrapy.extensions.logstats] INFO: Crawled 3745 pages (at 26 pages/min), scraped 3498 items (at 22 items/min)
2018-11-07 11:17:26 [scrapy.extensions.logstats] INFO: Crawled 3758 pages (at 13 pages/min), scraped 3513 items (at 15 items/min)
2018-11-07 11:17:53 [root] ERROR: Unable to find match for url: http://investors.skyworksinc.com/
2018-11-07 11:18:09 [root] ERROR: Unable to find match for url: https://careers.skyworksinc.com/
2018-11-07 11:18:27 [scrapy.extensions.logstats] INFO: Crawled 3783 pages (at 25 pages/min), scraped 3536 items (at 23 items/min)
2018-11-07 11:19:22 [scrapy.extensions.logstats] INFO: Crawled 3799 pages (at 16 pages/min), scraped 3554 items (at 18 items/min)
2018-11-07 11:20:25 [scrapy.extensions.logstats] INFO: Crawled 3818 pages (at 19 pages/min), scraped 3575 items (at 21 items/min)
2018-11-07 11:21:25 [scrapy.extensions.logstats] INFO: Crawled 3837 pages (at 19 pages/min), scraped 3592 items (at 17 items/min)
2018-11-07 11:22:33 [scrapy.extensions.logstats] INFO: Crawled 3858 pages (at 21 pages/min), scraped 3612 items (at 20 items/min)
2018-11-07 11:23:20 [scrapy.extensions.logstats] INFO: Crawled 3879 pages (at 21 pages/min), scraped 3627 items (at 15 items/min)
2018-11-07 11:24:29 [scrapy.extensions.logstats] INFO: Crawled 3900 pages (at 21 pages/min), scraped 3653 items (at 26 items/min)
2018-11-07 11:25:22 [scrapy.extensions.logstats] INFO: Crawled 3915 pages (at 15 pages/min), scraped 3669 items (at 16 items/min)
2018-11-07 11:26:26 [scrapy.extensions.logstats] INFO: Crawled 3923 pages (at 8 pages/min), scraped 3681 items (at 12 items/min)
2018-11-07 11:27:48 [scrapy.extensions.logstats] INFO: Crawled 3936 pages (at 13 pages/min), scraped 3689 items (at 8 items/min)
2018-11-07 11:28:23 [scrapy.extensions.logstats] INFO: Crawled 3936 pages (at 0 pages/min), scraped 3693 items (at 4 items/min)
2018-11-07 11:29:36 [scrapy.extensions.logstats] INFO: Crawled 3944 pages (at 8 pages/min), scraped 3701 items (at 8 items/min)
2018-11-07 11:30:40 [scrapy.extensions.logstats] INFO: Crawled 3952 pages (at 8 pages/min), scraped 3709 items (at 8 items/min)
2018-11-07 11:31:47 [scrapy.extensions.logstats] INFO: Crawled 3960 pages (at 8 pages/min), scraped 3717 items (at 8 items/min)
2018-11-07 11:32:29 [scrapy.extensions.logstats] INFO: Crawled 3964 pages (at 4 pages/min), scraped 3721 items (at 4 items/min)
2018-11-07 11:33:46 [scrapy.extensions.logstats] INFO: Crawled 3972 pages (at 8 pages/min), scraped 3729 items (at 8 items/min)
2018-11-07 11:34:21 [scrapy.extensions.logstats] INFO: Crawled 3976 pages (at 4 pages/min), scraped 3733 items (at 4 items/min)
2018-11-07 11:35:37 [scrapy.extensions.logstats] INFO: Crawled 3984 pages (at 8 pages/min), scraped 3741 items (at 8 items/min)
2018-11-07 11:36:47 [scrapy.extensions.logstats] INFO: Crawled 3992 pages (at 8 pages/min), scraped 3749 items (at 8 items/min)
2018-11-07 11:37:23 [scrapy.extensions.logstats] INFO: Crawled 3996 pages (at 4 pages/min), scraped 3753 items (at 4 items/min)
2018-11-07 11:38:28 [scrapy.extensions.logstats] INFO: Crawled 4004 pages (at 8 pages/min), scraped 3761 items (at 8 items/min)
2018-11-07 11:39:36 [scrapy.extensions.logstats] INFO: Crawled 4012 pages (at 8 pages/min), scraped 3769 items (at 8 items/min)
2018-11-07 11:40:51 [scrapy.extensions.logstats] INFO: Crawled 4020 pages (at 8 pages/min), scraped 3777 items (at 8 items/min)
2018-11-07 11:41:26 [scrapy.extensions.logstats] INFO: Crawled 4024 pages (at 4 pages/min), scraped 3781 items (at 4 items/min)
2018-11-07 11:42:33 [scrapy.extensions.logstats] INFO: Crawled 4032 pages (at 8 pages/min), scraped 3789 items (at 8 items/min)
2018-11-07 11:43:40 [scrapy.extensions.logstats] INFO: Crawled 4039 pages (at 7 pages/min), scraped 3797 items (at 8 items/min)
2018-11-07 11:44:31 [scrapy.extensions.logstats] INFO: Crawled 4044 pages (at 5 pages/min), scraped 3804 items (at 7 items/min)
2018-11-07 11:44:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://thebuzz.web.analog.com>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/endpoints.py", line 975, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: thebuzz.web.analog.com.
2018-11-07 11:45:50 [scrapy.extensions.logstats] INFO: Crawled 4065 pages (at 21 pages/min), scraped 3818 items (at 14 items/min)
2018-11-07 11:46:24 [scrapy.extensions.logstats] INFO: Crawled 4078 pages (at 13 pages/min), scraped 3828 items (at 10 items/min)
2018-11-07 11:47:22 [scrapy.extensions.logstats] INFO: Crawled 4093 pages (at 15 pages/min), scraped 3843 items (at 15 items/min)
2018-11-07 11:47:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/news-releases/news-release-details/arcturus-therapeutics-achieves-program-milestones-and-refines> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:48:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/news-releases/news-release-details/arcturus-therapeutics-announces-annual-and-extraordinary-general> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:48:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.appliedstemcell.com/research/cell-line-models/cell-line-irradiation>: HTTP status code is not handled or not allowed
2018-11-07 11:48:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/news-releases/news-release-details/arcturus-therapeutics-present-three-investor-conferences> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:48:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/news-releases/news-release-details/arcturus-therapeutics-announces-appointment-ernst-young-llp> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:48:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/news-releases/news-release-details/arcturus-therapeutics-expands-management-team> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:48:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/news-releases/news-release-details/arcturus-therapeutics-appoints-andrew-sassine-interim-chief> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:48:39 [scrapy.extensions.logstats] INFO: Crawled 4123 pages (at 30 pages/min), scraped 3857 items (at 14 items/min)
2018-11-07 11:48:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/news-releases/news-release-details/arcturus-therapeutics-present-october-investor-conferences> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:48:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/news-releases/news-release-details/arcturus-therapeutics-reports-second-quarter-2018-financial> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:48:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/news-releases/news-release-details/arcturus-therapeutics-hosts-ribbon-cutting-ceremony-its-research> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:49:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.arcturusrx.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-07 11:49:25 [scrapy.extensions.logstats] INFO: Crawled 4123 pages (at 0 pages/min), scraped 3863 items (at 6 items/min)
2018-11-07 11:50:40 [scrapy.extensions.logstats] INFO: Crawled 4138 pages (at 15 pages/min), scraped 3878 items (at 15 items/min)
2018-11-07 11:51:41 [scrapy.extensions.logstats] INFO: Crawled 4154 pages (at 16 pages/min), scraped 3893 items (at 15 items/min)
2018-11-07 11:52:38 [scrapy.extensions.logstats] INFO: Crawled 4164 pages (at 10 pages/min), scraped 3905 items (at 12 items/min)
2018-11-07 11:53:34 [scrapy.extensions.logstats] INFO: Crawled 4178 pages (at 14 pages/min), scraped 3916 items (at 11 items/min)
2018-11-07 11:54:24 [scrapy.extensions.logstats] INFO: Crawled 4191 pages (at 13 pages/min), scraped 3926 items (at 10 items/min)
2018-11-07 11:55:23 [scrapy.extensions.logstats] INFO: Crawled 4202 pages (at 11 pages/min), scraped 3939 items (at 13 items/min)
2018-11-07 11:56:26 [scrapy.extensions.logstats] INFO: Crawled 4209 pages (at 7 pages/min), scraped 3952 items (at 13 items/min)
2018-11-07 11:57:33 [scrapy.extensions.logstats] INFO: Crawled 4233 pages (at 24 pages/min), scraped 3970 items (at 18 items/min)
2018-11-07 11:58:44 [scrapy.extensions.logstats] INFO: Crawled 4251 pages (at 18 pages/min), scraped 3987 items (at 17 items/min)
2018-11-07 11:59:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://arborpharma.com/team/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-07 11:59:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-07 11:59:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 594,
 'downloader/exception_type_count/scrapy.exceptions.NotSupported': 1,
 'downloader/exception_type_count/twisted.internet.error.ConnectError': 15,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 21,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 6,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 24,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 527,
 'downloader/request_bytes': 2465684,
 'downloader/request_count': 5507,
 'downloader/request_method_count/GET': 5507,
 'downloader/response_bytes': 130113313,
 'downloader/response_count': 4913,
 'downloader/response_status_count/200': 4240,
 'downloader/response_status_count/301': 487,
 'downloader/response_status_count/302': 118,
 'downloader/response_status_count/303': 20,
 'downloader/response_status_count/307': 1,
 'downloader/response_status_count/403': 4,
 'downloader/response_status_count/404': 20,
 'downloader/response_status_count/406': 1,
 'downloader/response_status_count/408': 19,
 'downloader/response_status_count/418': 3,
 'dupefilter/filtered': 529,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 7, 11, 59, 17, 356790),
 'httperror/response_ignored_count': 28,
 'httperror/response_ignored_status_count/403': 4,
 'httperror/response_ignored_status_count/404': 20,
 'httperror/response_ignored_status_count/406': 1,
 'httperror/response_ignored_status_count/418': 3,
 'item_scraped_count': 3998,
 'log_count/ERROR': 220,
 'log_count/INFO': 432,
 'log_count/WARNING': 2,
 'memusage/max': 329203712,
 'memusage/startup': 96317440,
 'offsite/domains': 321,
 'offsite/filtered': 788,
 'request_depth_max': 1,
 'response_received_count': 4255,
 'retry/count': 538,
 'retry/max_reached': 74,
 'retry/reason_count/408 Request Time-out': 19,
 'retry/reason_count/twisted.internet.error.ConnectError': 14,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 14,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 4,
 'retry/reason_count/twisted.internet.error.TimeoutError': 23,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 464,
 'scheduler/dequeued': 5507,
 'scheduler/dequeued/memory': 5507,
 'scheduler/enqueued': 5507,
 'scheduler/enqueued/memory': 5507,
 'spider_exceptions/AttributeError': 135,
 'spider_exceptions/NoSuchWindowException': 1,
 'spider_exceptions/TimeoutException': 1,
 'start_time': datetime.datetime(2018, 11, 7, 5, 5, 18, 680935)}
2018-11-07 11:59:17 [scrapy.core.engine] INFO: Spider closed (finished)
