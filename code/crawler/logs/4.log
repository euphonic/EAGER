nohup: ignoring input
Checking url for W&Wsens Devices
	Trying http://wwsensdevices.com/
Checking url for Butamax(TM) Advanced Biofuels LLC
	Trying http://butamax.com/
Checking url for Confluence Energy
	Trying http://confluenceenergy.com/
Checking url for COOK MEDICAL TECHNOLOGIES LLC
	Trying http://cookmedical.com/
Checking url for COVERIS FLEXIBLES US LLC
	Trying http://coveris.com/
Checking url for Hollingsworth & Vose Company
	Trying http://hollingsworth-vose.com/
Checking url for JFE STEEL CORPORATION
	Trying http://jfe-steel.co.jp/en/
	Trying http://www.jfe-steel.co.jp/en/
Checking url for Landauer
	Trying http://landauer.com/
Checking url for Fianium Ltd.
	Trying http://nktphotonics.com/
Checking url for Prosoft International
	Trying http://prosoft-technology.com/
Checking url for Sagacious Investment Group L.L.C.
	Trying http://sagaciousinvestmentservices.com/
Checking url for SEaB Energy Holdings Ltd.
	Trying http://seabenergy.com/
Checking url for Starlight Energy Holdings LLC
	Trying http://starlightenergy.us/
Checking url for Solaire Generation LLC
	Trying http://sunpowercarports.com/
Checking url for Tesla Nanocoatings
	Trying http://teslanano.com/
	Trying http://www.teslanano.com/
	Trying https://teslanano.com/
	Trying https://www.teslanano.com/
Checking url for Applied Biosystems
	Trying http://thermofisher.com/us/en/home/brands/applied-biosystems.html
Checking url for AltaRock Energy
	Trying http://altarockenergy.com/
Checking url for Cbrite Inc.
	Trying http://cbriteinc.com/
Checking url for Dow AgroSciences LLC
	Trying http://dowagro.com/en-us/
Checking url for Entech Solar
	Trying http://entechsolutions.us/
Checking url for Gas Technology Institute
	Trying http://gastechnology.org/
Checking url for Seiko Epson Corporation
	Trying http://global.epson.com/
Checking url for GLYCON LLC
	Trying http://glycon.com/
Checking url for k-Space Associates
	Trying http://k-space.com/
Checking url for Kureha Corporation
	Trying http://kureha.co.jp/en/
	Trying http://www.kureha.co.jp/en/
Checking url for MirTech
	Trying http://mirtechusa.com/
Checking url for Northwest Biotherapeutics
	Trying http://nwbio.com/
Checking url for Skidmore
	Trying http://skidmore.edu/
Checking url for Tela Innovations
	Trying http://tela-inc.com/
Checking url for Wikipad
	Trying http://wikipad.com/
Checking url for Akron Polymer Systems
	Trying http://akronpolysys.com/
Checking url for Ampio Pharmaceuticals
	Trying http://ampiopharma.com/
Checking url for ATOMERA INCORPORATED
	Trying http://atomera.com/
Checking url for Cambridge Electronics
	Trying http://cambridgeelectronics.com/
Checking url for Delavau LLC
	Trying http://delavaufood.com/
Checking url for GE Healthcare Dharmacon
	Trying http://dharmacon.horizondiscovery.com/
Checking url for ESCAPE THERAPEUTICS
	Trying http://escapetherapeutics.com/
Checking url for HIQ SOLAR
	Trying http://hiqsolar.com/
Checking url for Rima Enterprises
	Trying http://rimaenterprises.in/
Checking url for Tau Therapeutics LLC
	Trying http://taurx.com/
Checking url for Corporation for National Research Initiatives
	Trying http://cnri.reston.va.us/
Checking url for Element One
	Trying http://elementonescreens.com/
Checking url for Litron Laboratories Limited
	Trying http://litronlabs.com/
Checking url for Nutech Ventures
	Trying http://nutechventures.org/
Checking url for Pentron Clinical Technologies
	Trying http://pentron.com/
Checking url for PolyPlus Battery Company
	Trying http://polyplus.com/
Checking url for Synaptic Research
	Trying http://research.synaptic.co.uk/
Checking url for Roche Diabetes Care
	Trying http://roche.com/partnering/diagnostics-areas-of-interest/diabetes-management.htm
Checking url for Sierra Sciences
	Trying http://sierrasci.com/?p=home
Checking url for ADVANCED INNOVATION CENTER LLC
	Trying http://aicchile.com/en/
Checking url for Ambature
	Trying http://ambature.com/
Checking url for Robert Bosch GmbH
	Trying http://bosch.com/
	Trying http://www.bosch.com/
Checking url for Calysta
	Trying http://calysta.com/
Checking url for CERION LLC
	Trying http://cerionadvancedmaterials.com/
Checking url for Dexerials Corporation
	Trying http://dexerials.jp/en/
	Trying http://www.dexerials.jp/en/
Checking url for Formula Plastics
	Trying http://formulaplastics.com/
Checking url for Canon Kabushiki Kaisha
	Trying http://global.canon/en/index.html
Checking url for B.G. Negev Technologies and Applications Ltd.
	Trying http://in.bgu.ac.il/en/bgn/Pages/default.aspx
Checking url for Nthdegree Technologies Worldwide Inc.
	Trying http://ndeg.com/
Checking url for NGK Spark Plug Co.
	Trying http://ngksparkplugs.com/
Checking url for Sanken Electric Co.
	Trying http://sanken-ele.co.jp/en/index.php
	Trying http://www.sanken-ele.co.jp/en/index.php
Checking url for Smart Planet Technologies
	Trying http://smartplanettech.com/
Checking url for Tokyo Ohka Kogyo Co.
	Trying http://tok.co.jp/eng/
	Trying http://www.tok.co.jp/eng/
Checking url for Ansun Biopharma
	Trying http://ansunbiopharma.com/
Checking url for Cima NanoTech Israel Ltd.
	Trying http://cimananotech.com/
Checking url for Courtagen Life Sciences
	Trying http://courtagen.com/
Checking url for Delta Electronics
	Trying http://deltaww.com/
	Trying http://www.deltaww.com/
Checking url for Deployable Space Systems
	Trying http://dss-space.com/
Checking url for Em-Tech LLC
	Trying http://em-techinc.com/
Checking url for Genisphere
	Trying http://genisphere.com/
Checking url for Tanaka Kikinzoku Kogyo K.K.
	Trying http://gold.tanaka.co.jp/english/
Checking url for MICROSOFT TECHNOLOGY LICENSING
	Trying http://microsoft.com/en-us/legal/intellectualproperty/mtl/default.aspx
Checking url for Molecular Rebar Design
	Trying http://molecularrebar.com/
Checking url for Nanoholdings
	Trying http://nh2.com/
Checking url for Novon
	Trying http://novon.com/
Checking url for Parion Sciences
	Trying http://parion.com/
Checking url for Pyrexar Medical Inc.
	Trying http://pyrexar.com/
Checking url for Aushon Biosystems
	Trying http://aushon.com/
Checking url for Bird-B-Gone
	Trying http://birdbgone.com/
Checking url for Energysolutions
	Trying http://energysolutions.com/
	Trying http://www.energysolutions.com/
Checking url for Kronos International Inc
	Trying http://kronos.com/
Checking url for Sirnaomics
	Trying http://new.sirnaomics.com/
Checking url for WestPoint Home
	Trying http://westpointhome.com/
Checking url for WiSys Technology Foundation
	Trying http://wisys.org/
Checking url for Alcotek
	Trying http://alcotek.com/
Checking url for Bruin Biometrics
	Trying http://bruinbiometrics.com/us/
Checking url for Echogen Power Systems
	Trying http://echogen.com/
Checking url for LATITUDE PHARMACEUTICALS INC.
	Trying http://latitudepharma.com/
Checking url for NEWFIELD THERAPEUTICS CORPORATION
	Trying http://newfieldthera.com/
Checking url for Pulse Therapeutics
	Trying http://pulsetherapeutics.com/
Checking url for Swagelok Company
	Trying http://swagelok.com/
Checking url for Unity Semiconductor Corporation
	Trying http://unity-sc.com/
Checking url for Gemex Systems
	Trying http://gemex.com/
Checking url for PELLION TECHNOLOGIES
	Trying http://pelliontech.com/
Checking url for Quantapore
	Trying http://quantapore.com/
Checking url for Taiyo Ink Mfg. Co.
	Trying http://taiyo-hd.co.jp/en/group/ink/
Checking url for Traex Corporation
	Trying http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm
Checking url for Wentworth Laboratories
	Trying http://wentworthlabs.com/
Checking url for DNA2.0
	Trying http://atum.bio/
Checking url for Dynamic Solutions Worldwide
	Trying http://dynatrap.com/
[{'domain': 'www.wwsensdevices.com',
  'firm_name': 'W&Wsens Devices',
  'url': 'https://www.wwsensdevices.com/'},
 {'domain': 'www.butamax.com',
  'firm_name': 'Butamax(TM) Advanced Biofuels LLC',
  'url': 'http://www.butamax.com/'},
 {'domain': 'www.confluenceenergy.com',
  'firm_name': 'Confluence Energy',
  'url': 'http://www.confluenceenergy.com/'},
 {'domain': 'www.cookmedical.com',
  'firm_name': 'COOK MEDICAL TECHNOLOGIES LLC',
  'url': 'https://www.cookmedical.com/'},
 {'domain': 'www.coveris.com',
  'firm_name': 'COVERIS FLEXIBLES US LLC',
  'url': 'http://www.coveris.com/'},
 {'domain': 'www.hollingsworth-vose.com',
  'firm_name': 'Hollingsworth & Vose Company',
  'url': 'https://www.hollingsworth-vose.com/'},
 {'domain': 'www.jfe-steel.co.jp',
  'firm_name': 'JFE STEEL CORPORATION',
  'url': 'http://www.jfe-steel.co.jp/en/'},
 {'domain': 'www.landauer.com',
  'firm_name': 'Landauer',
  'url': 'https://www.landauer.com/'},
 {'domain': 'www.nktphotonics.com',
  'firm_name': 'Fianium Ltd.',
  'url': 'https://www.nktphotonics.com/'},
 {'domain': 'www.prosoft-technology.com',
  'firm_name': 'Prosoft International',
  'url': 'https://www.prosoft-technology.com/'},
 {'domain': 'www.sagaciousinvestmentservices.com',
  'firm_name': 'Sagacious Investment Group L.L.C.',
  'url': 'http://www.sagaciousinvestmentservices.com/'},
 {'domain': 'seabenergy.com',
  'firm_name': 'SEaB Energy Holdings Ltd.',
  'url': 'http://seabenergy.com/'},
 {'domain': 'www.starlightenergy.us',
  'firm_name': 'Starlight Energy Holdings LLC',
  'url': 'http://www.starlightenergy.us/'},
 {'domain': 'sunpowercarports.com',
  'firm_name': 'Solaire Generation LLC',
  'url': 'http://sunpowercarports.com/'},
 {'domain': 'www.thermofisher.com',
  'firm_name': 'Applied Biosystems',
  'url': 'https://www.thermofisher.com/us/en/home/brands/applied-biosystems.html'},
 {'domain': 'altarockenergy.com',
  'firm_name': 'AltaRock Energy',
  'url': 'http://altarockenergy.com/'},
 {'domain': 'cbriteinc.com',
  'firm_name': 'Cbrite Inc.',
  'url': 'http://cbriteinc.com/'},
 {'domain': 'www.dowagro.com',
  'firm_name': 'Dow AgroSciences LLC',
  'url': 'http://www.dowagro.com/en-us/'},
 {'domain': 'entechsolutions.us',
  'firm_name': 'Entech Solar',
  'url': 'http://entechsolutions.us/'},
 {'domain': 'www.gastechnology.org',
  'firm_name': 'Gas Technology Institute',
  'url': 'http://www.gastechnology.org/Pages/default.aspx'},
 {'domain': 'global.epson.com',
  'firm_name': 'Seiko Epson Corporation',
  'url': 'https://global.epson.com/'},
 {'domain': 'www.glycon.com',
  'firm_name': 'GLYCON LLC',
  'url': 'http://www.glycon.com/'},
 {'domain': 'www.k-space.com',
  'firm_name': 'k-Space Associates',
  'url': 'https://www.k-space.com/'},
 {'domain': 'www.kureha.co.jp',
  'firm_name': 'Kureha Corporation',
  'url': 'http://www.kureha.co.jp/en/'},
 {'domain': 'www.mirtechusa.com',
  'firm_name': 'MirTech',
  'url': 'http://www.mirtechusa.com/'},
 {'domain': 'www.nwbio.com',
  'firm_name': 'Northwest Biotherapeutics',
  'url': 'https://www.nwbio.com/'},
 {'domain': 'www.skidmore.edu',
  'firm_name': 'Skidmore',
  'url': 'https://www.skidmore.edu/'},
 {'domain': 'www.tela-inc.com',
  'firm_name': 'Tela Innovations',
  'url': 'http://www.tela-inc.com/'},
 {'domain': 'www.wikipad.com',
  'firm_name': 'Wikipad',
  'url': 'http://www.wikipad.com/'},
 {'domain': 'akronpolysys.com',
  'firm_name': 'Akron Polymer Systems',
  'url': 'http://akronpolysys.com/'},
 {'domain': 'ampiopharma.com',
  'firm_name': 'Ampio Pharmaceuticals',
  'url': 'https://ampiopharma.com/'},
 {'domain': 'atomera.com',
  'firm_name': 'ATOMERA INCORPORATED',
  'url': 'http://atomera.com/'},
 {'domain': 'www.cambridgeelectronics.com',
  'firm_name': 'Cambridge Electronics',
  'url': 'https://www.cambridgeelectronics.com/'},
 {'domain': 'www.delavaufood.com',
  'firm_name': 'Delavau LLC',
  'url': 'https://www.delavaufood.com/'},
 {'domain': 'dharmacon.horizondiscovery.com',
  'firm_name': 'GE Healthcare Dharmacon',
  'url': 'https://dharmacon.horizondiscovery.com/'},
 {'domain': 'escapetherapeutics.com',
  'firm_name': 'ESCAPE THERAPEUTICS',
  'url': 'http://escapetherapeutics.com/'},
 {'domain': 'hiqsolar.com',
  'firm_name': 'HIQ SOLAR',
  'url': 'http://hiqsolar.com/'},
 {'domain': 'www.rimaenterprises.in',
  'firm_name': 'Rima Enterprises',
  'url': 'http://www.rimaenterprises.in/'},
 {'domain': 'taurx.com',
  'firm_name': 'Tau Therapeutics LLC',
  'url': 'http://taurx.com/'},
 {'domain': 'cnri.reston.va.us',
  'firm_name': 'Corporation for National Research Initiatives',
  'url': 'http://cnri.reston.va.us/'},
 {'domain': 'elementonescreens.com',
  'firm_name': 'Element One',
  'url': 'http://elementonescreens.com/'},
 {'domain': 'litronlabs.com',
  'firm_name': 'Litron Laboratories Limited',
  'url': 'https://litronlabs.com/'},
 {'domain': 'www.nutechventures.org',
  'firm_name': 'Nutech Ventures',
  'url': 'http://www.nutechventures.org/'},
 {'domain': 'www.pentron.com',
  'firm_name': 'Pentron Clinical Technologies',
  'url': 'https://www.pentron.com/'},
 {'domain': 'polyplus.com',
  'firm_name': 'PolyPlus Battery Company',
  'url': 'http://polyplus.com/'},
 {'domain': 'research.synaptic.co.uk',
  'firm_name': 'Synaptic Research',
  'url': 'https://research.synaptic.co.uk/SynapticResearch/login.asp?t=64024&page=/Default.asp?'},
 {'domain': 'www.roche.com',
  'firm_name': 'Roche Diabetes Care',
  'url': 'https://www.roche.com/partnering/diagnostics-areas-of-interest/diabetes-management.htm'},
 {'domain': 'www.sierrasci.com',
  'firm_name': 'Sierra Sciences',
  'url': 'https://www.sierrasci.com/?p=home'},
 {'domain': 'aicchile.com',
  'firm_name': 'ADVANCED INNOVATION CENTER LLC',
  'url': 'http://aicchile.com/en/'},
 {'domain': 'ambature.com',
  'firm_name': 'Ambature',
  'url': 'http://ambature.com/'},
 {'domain': 'www.bosch.com',
  'firm_name': 'Robert Bosch GmbH',
  'url': 'https://www.bosch.com/'},
 {'domain': 'calysta.com',
  'firm_name': 'Calysta',
  'url': 'http://calysta.com/'},
 {'domain': 'www.cerionadvancedmaterials.com',
  'firm_name': 'CERION LLC',
  'url': 'https://www.cerionadvancedmaterials.com'},
 {'domain': 'www.dexerials.jp',
  'firm_name': 'Dexerials Corporation',
  'url': 'http://www.dexerials.jp/en/'},
 {'domain': 'formulaplastics.com',
  'firm_name': 'Formula Plastics',
  'url': 'http://formulaplastics.com/'},
 {'domain': 'global.canon',
  'firm_name': 'Canon Kabushiki Kaisha',
  'url': 'https://global.canon/en/index.html'},
 {'domain': 'in.bgu.ac.il',
  'firm_name': 'B.G. Negev Technologies and Applications Ltd.',
  'url': 'http://in.bgu.ac.il/en/bgn/Pages/default.aspx'},
 {'domain': 'www.ndeg.com',
  'firm_name': 'Nthdegree Technologies Worldwide Inc.',
  'url': 'https://www.ndeg.com/'},
 {'domain': 'ngksparkplugs.com',
  'firm_name': 'NGK Spark Plug Co.',
  'url': 'http://ngksparkplugs.com/'},
 {'domain': 'www.sanken-ele.co.jp',
  'firm_name': 'Sanken Electric Co.',
  'url': 'https://www.sanken-ele.co.jp/en/index.php'},
 {'domain': 'www.smartplanettech.com',
  'firm_name': 'Smart Planet Technologies',
  'url': 'https://www.smartplanettech.com/'},
 {'domain': 'www.tok.co.jp',
  'firm_name': 'Tokyo Ohka Kogyo Co.',
  'url': 'https://www.tok.co.jp/eng'},
 {'domain': 'www.ansunbiopharma.com',
  'firm_name': 'Ansun Biopharma',
  'url': 'http://www.ansunbiopharma.com/'},
 {'domain': 'cimananotech.com',
  'firm_name': 'Cima NanoTech Israel Ltd.',
  'url': 'http://cimananotech.com/en/closure/'},
 {'domain': 'courtagen.com',
  'firm_name': 'Courtagen Life Sciences',
  'url': 'http://courtagen.com/'},
 {'domain': 'www.deltaww.com',
  'firm_name': 'Delta Electronics',
  'url': 'http://www.deltaww.com/'},
 {'domain': 'www.dss-space.com',
  'firm_name': 'Deployable Space Systems',
  'url': 'https://www.dss-space.com/'},
 {'domain': 'www.em-techinc.com',
  'firm_name': 'Em-Tech LLC',
  'url': 'http://www.em-techinc.com/'},
 {'domain': 'genisphere.com',
  'firm_name': 'Genisphere',
  'url': 'https://genisphere.com/'},
 {'domain': 'gold.tanaka.co.jp',
  'firm_name': 'Tanaka Kikinzoku Kogyo K.K.',
  'url': 'https://gold.tanaka.co.jp/english/'},
 {'domain': 'www.microsoft.com',
  'firm_name': 'MICROSOFT TECHNOLOGY LICENSING',
  'url': 'https://www.microsoft.com/en-us/legal/intellectualproperty/mtl/default.aspx'},
 {'domain': 'www.molecularrebar.com',
  'firm_name': 'Molecular Rebar Design',
  'url': 'http://www.molecularrebar.com/'},
 {'domain': 'www.nh2.com',
  'firm_name': 'Nanoholdings',
  'url': 'https://www.nh2.com/'},
 {'domain': 'novon.com', 'firm_name': 'Novon', 'url': 'http://novon.com/'},
 {'domain': 'parion.com',
  'firm_name': 'Parion Sciences',
  'url': 'http://parion.com/'},
 {'domain': 'pyrexar.com',
  'firm_name': 'Pyrexar Medical Inc.',
  'url': 'https://pyrexar.com/'},
 {'domain': 'www.quanterix.com',
  'firm_name'2018-11-11 00:11:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: FirmDB)
2018-11-11 00:11:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.6 (default, Sep 12 2018, 18:26:19) - [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Linux-4.15.0-1023-aws-x86_64-with-Ubuntu-18.04-bionic
2018-11-11 00:11:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'FirmDB', 'CONCURRENT_REQUESTS_PER_DOMAIN': 4, 'DEPTH_LIMIT': '1', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'FirmDB.spiders', 'ROBOTSTXT_OBEY': 'False', 'SPIDER_MODULES': ['FirmDB.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36'}
2018-11-11 00:11:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-11 00:11:22 [py.warnings] WARNING: /home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2018-11-11 00:11:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'random_useragent.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-11 00:11:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-11 00:11:22 [scrapy.middleware] INFO: Enabled item pipelines:
['FirmDB.pipelines.FirmDBPipeline']
2018-11-11 00:11:22 [scrapy.core.engine] INFO: Spider opened
2018-11-11 00:11:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
/bin/sh: 1: kill: Illegal number: 
/bin/sh: 1: kill: Illegal number: 
2018-11-11 00:12:29 [scrapy.extensions.logstats] INFO: Crawled 37 pages (at 37 pages/min), scraped 8 items (at 8 items/min)
/bin/sh: 1: kill: Illegal number: 
/bin/sh: 1: kill: Illegal number: 
2018-11-11 00:13:25 [scrapy.extensions.logstats] INFO: Crawled 41 pages (at 4 pages/min), scraped 19 items (at 11 items/min)
2018-11-11 00:13:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/About-Us/Employment>: HTTP status code is not handled or not allowed
2018-11-11 00:13:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/About-Us/Corporate-Profile>: HTTP status code is not handled or not allowed
2018-11-11 00:14:28 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 7 pages/min), scraped 28 items (at 9 items/min)
: 'Aushon Biosystems',
  'url': 'https://www.quanterix.com/'},
 {'domain': 'www.birdbgone.com',
  'firm_name': 'Bird-B-Gone',
  'url': 'https://www.birdbgone.com/'},
 {'domain': 'www.energysolutions.com',
  'firm_name': 'Energysolutions',
  'url': 'https://www.energysolutions.com/'},
 {'domain': 'www.kronos.com',
  'firm_name': 'Kronos International Inc',
  'url': 'https://www.kronos.com/'},
 {'domain': 'new.sirnaomics.com',
  'firm_name': 'Sirnaomics',
  'url': 'http://new.sirnaomics.com/'},
 {'domain': 'www.westpointhome.com',
  'firm_name': 'WestPoint Home',
  'url': 'https://www.westpointhome.com/'},
 {'domain': 'wisys.org',
  'firm_name': 'WiSys Technology Foundation',
  'url': 'http://wisys.org/'},
 {'domain': 'alcotek.com',
  'firm_name': 'Alcotek',
  'url': 'https://alcotek.com/'},
 {'domain': 'bruinbiometrics.com',
  'firm_name': 'Bruin Biometrics',
  'url': 'http://bruinbiometrics.com/us/'},
 {'domain': 'www.echogen.com',
  'firm_name': 'Echogen Power Systems',
  'url': 'https://www.echogen.com/'},
 {'domain': 'latitudepharma.com',
  'firm_name': 'LATITUDE PHARMACEUTICALS INC.',
  'url': 'http://latitudepharma.com/'},
 {'domain': 'newfieldthera.com',
  'firm_name': 'NEWFIELD THERAPEUTICS CORPORATION',
  'url': 'https://newfieldthera.com/'},
 {'domain': 'www.pulsetherapeutics.com',
  'firm_name': 'Pulse Therapeutics',
  'url': 'https://www.pulsetherapeutics.com/'},
 {'domain': 'www.swagelok.com:443',
  'firm_name': 'Swagelok Company',
  'url': 'https://www.swagelok.com:443/en'},
 {'domain': 'www.unity-sc.com',
  'firm_name': 'Unity Semiconductor Corporation',
  'url': 'http://www.unity-sc.com/'},
 {'domain': 'gemex.com',
  'firm_name': 'Gemex Systems',
  'url': 'https://gemex.com/'},
 {'domain': 'www.pelliontech.com',
  'firm_name': 'PELLION TECHNOLOGIES',
  'url': 'http://www.pelliontech.com/'},
 {'domain': 'quantapore.com',
  'firm_name': 'Quantapore',
  'url': 'https://quantapore.com/'},
 {'domain': 'taiyo-hd.co.jp',
  'firm_name': 'Taiyo Ink Mfg. Co.',
  'url': 'http://taiyo-hd.co.jp/en/group/ink/'},
 {'domain': 'vollrath.com',
  'firm_name': 'Traex Corporation',
  'url': 'http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm'},
 {'domain': 'www.wentworthlabs.com',
  'firm_name': 'Wentworth Laboratories',
  'url': 'https://www.wentworthlabs.com/'},
 {'domain': 'www.atum.bio',
  'firm_name': 'DNA2.0',
  'url': 'https://www.atum.bio/'},
 {'domain': 'dynatrap.com',
  'firm_name': 'Dynamic Solutions Worldwide',
  'url': 'https://dynatrap.com/'}]
Missing Tesla Nanocoatings in the fixed urls list
Pages to scrape: ['https://www.wwsensdevices.com/', 'http://www.butamax.com/', 'http://www.confluenceenergy.com/', 'https://www.cookmedical.com/', 'http://www.coveris.com/', 'https://www.hollingsworth-vose.com/', 'http://www.jfe-steel.co.jp/en/', 'https://www.landauer.com/', 'https://www.nktphotonics.com/', 'https://www.prosoft-technology.com/', 'http://www.sagaciousinvestmentservices.com/', 'http://seabenergy.com/', 'http://www.starlightenergy.us/', 'http://sunpowercarports.com/', 'https://www.thermofisher.com/us/en/home/brands/applied-biosystems.html', 'http://altarockenergy.com/', 'http://cbriteinc.com/', 'http://www.dowagro.com/en-us/', 'http://entechsolutions.us/', 'http://www.gastechnology.org/Pages/default.aspx', 'https://global.epson.com/', 'http://www.glycon.com/', 'https://www.k-space.com/', 'http://www.kureha.co.jp/en/', 'http://www.mirtechusa.com/', 'https://www.nwbio.com/', 'https://www.skidmore.edu/', 'http://www.tela-inc.com/', 'http://www.wikipad.com/', 'http://akronpolysys.com/', 'https://ampiopharma.com/', 'http://atomera.com/', 'https://www.cambridgeelectronics.com/', 'https://www.delavaufood.com/', 'https://dharmacon.horizondiscovery.com/', 'http://escapetherapeutics.com/', 'http://hiqsolar.com/', 'http://www.rimaenterprises.in/', 'http://taurx.com/', 'http://cnri.reston.va.us/', 'http://elementonescreens.com/', 'https://litronlabs.com/', 'http://www.nutechventures.org/', 'https://www.pentron.com/', 'http://polyplus.com/', 'https://research.synaptic.co.uk/SynapticResearch/login.asp?t=64024&page=/Default.asp?', 'https://www.roche.com/partnering/diagnostics-areas-of-interest/diabetes-management.htm', 'https://www.sierrasci.com/?p=home', 'http://aicchile.com/en/', 'http://ambature.com/', 'https://www.bosch.com/', 'http://calysta.com/', 'https://www.cerionadvancedmaterials.com', 'http://www.dexerials.jp/en/', 'http://formulaplastics.com/', 'https://global.canon/en/index.html', 'http://in.bgu.ac.il/en/bgn/Pages/default.aspx', 'https://www.ndeg.com/', 'http://ngksparkplugs.com/', 'https://www.sanken-ele.co.jp/en/index.php', 'https://www.smartplanettech.com/', 'https://www.tok.co.jp/eng', 'http://www.ansunbiopharma.com/', 'http://cimananotech.com/en/closure/', 'http://courtagen.com/', 'http://www.deltaww.com/', 'https://www.dss-space.com/', 'http://www.em-techinc.com/', 'https://genisphere.com/', 'https://gold.tanaka.co.jp/english/', 'https://www.microsoft.com/en-us/legal/intellectualproperty/mtl/default.aspx', 'http://www.molecularrebar.com/', 'https://www.nh2.com/', 'http://novon.com/', 'http://parion.com/', 'https://pyrexar.com/', 'https://www.quanterix.com/', 'https://www.birdbgone.com/', 'https://www.energysolutions.com/', 'https://www.kronos.com/', 'http://new.sirnaomics.com/', 'https://www.westpointhome.com/', 'http://wisys.org/', 'https://alcotek.com/', 'http://bruinbiometrics.com/us/', 'https://www.echogen.com/', 'http://latitudepharma.com/', 'https://newfieldthera.com/', 'https://www.pulsetherapeutics.com/', 'https://www.swagelok.com:443/en', 'http://www.unity-sc.com/', 'https://gemex.com/', 'http://www.pelliontech.com/', 'https://quantapore.com/', 'http://taiyo-hd.co.jp/en/group/ink/', 'http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm', 'https://www.wentworthlabs.com/', 'https://www.atum.bio/', 'https://dynatrap.com/']
Crawling page: https://www.landauer.com/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/Industrial---Engineered-Composite-Materials/       valid
Crawling page: https://www.thermofisher.com/us/en/home.html       valid
Crawling page: https://www.landauer.com/history       valid
Crawling page: https://www.thermofisher.com/search/results?query=Citations+%26+References%20&type=Citations+%26+References       valid
Crawling page: https://www.landauer.com/terms-use       valid
Crawling page: http://sunpowercarports.com/       valid
Crawling page: http://sunpowercarports.com/products       valid
Crawling page: https://www.landauer.com/contact-webmaster       valid
Crawling page: https://www.landauer.com/landauer-privacy-policy       valid
Crawling page: http://www.dowagro.com/en-us/       valid
Crawling page: http://sunpowercarports.com/projects       valid
Crawling page: http://sunpowercarports.com/contact       valid
Crawling page: http://cbriteinc.com/?page_id=display-technology       valid
Crawling page: http://cbriteinc.com/?page_id=biosensors       valid
Crawling page: http://cbriteinc.com/?page_id=digital-imaging       valid
Crawling page: http://cbriteinc.com/       valid
Crawling page: http://altarockenergy.com/privacy-policy/       valid
Crawling page: http://altarockenergy.com/terms-conditions/       valid
Crawling page: http://www.dowagro.com/en-us?sitemode=mobile       valid
Crawling page: http://www.dowagro.com/en-us?sitemode=desktop       valid
Crawling page: https://www.wwsensdevices.com       valid
Crawling page: https://www.cookmedical.com/about/ethics-compliance/human-rights-statement/       valid
Crawling page: https://www.cookmedical.com/cookie-compliance/       valid
Crawling page: https://www.prosoft-technology.com/privacy       valid
Crawling page: https://www.nktphotonics.com/news/       valid
Crawling page: https://www.nktphotonics.com/imprint/       valid
Crawling page: https://www.nktphotonics.com/legal/       valid
Crawling page: https://www.nktphotonics.com/lios/en/contact/       valid
Crawling page: https://www.nktphotonics.com/privacy-policy/       valid
Crawling page: https://www.nktphotonics.com/lios/en/support/technical-support-customer-service/       valid
Crawling page: https://www.nktphotonics.com/lios/en/application/2018-11-11 00:15:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Where-to-Buy/node_9087>: HTTP status code is not handled or not allowed
2018-11-11 00:15:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/About-Us/Contact-Us>: HTTP status code is not handled or not allowed
2018-11-11 00:15:29 [scrapy.extensions.logstats] INFO: Crawled 65 pages (at 17 pages/min), scraped 38 items (at 10 items/min)
2018-11-11 00:15:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/News-Events/Events>: HTTP status code is not handled or not allowed
2018-11-11 00:15:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/News-Events/ProSoft-Magazine>: HTTP status code is not handled or not allowed
2018-11-11 00:15:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/News-Events/Press-Releases>: HTTP status code is not handled or not allowed
2018-11-11 00:15:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Services-Support/Literature>: HTTP status code is not handled or not allowed
2018-11-11 00:15:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Services-Support/node_4963>: HTTP status code is not handled or not allowed
2018-11-11 00:15:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Services-Support/Training>: HTTP status code is not handled or not allowed
2018-11-11 00:15:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Products/ProSoft-Software>: HTTP status code is not handled or not allowed
2018-11-11 00:15:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Services-Support/Legacy-Downloads>: HTTP status code is not handled or not allowed
2018-11-11 00:15:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Services-Support/Customer-Support>: HTTP status code is not handled or not allowed
2018-11-11 00:15:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/News-Events/Success-Stories>: HTTP status code is not handled or not allowed
2018-11-11 00:16:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Products/Rockwell-Automation-In-chassis>: HTTP status code is not handled or not allowed
2018-11-11 00:16:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Products/Industrial-Wireless>: HTTP status code is not handled or not allowed
2018-11-11 00:16:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Products/Gateways>: HTTP status code is not handled or not allowed
2018-11-11 00:16:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Products/Schneider-Electric-In-chassis>: HTTP status code is not handled or not allowed
2018-11-11 00:16:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/Products/Remote-Access>: HTTP status code is not handled or not allowed
2018-11-11 00:16:26 [scrapy.extensions.logstats] INFO: Crawled 92 pages (at 27 pages/min), scraped 48 items (at 10 items/min)
2018-11-11 00:17:37 [scrapy.extensions.logstats] INFO: Crawled 103 pages (at 11 pages/min), scraped 60 items (at 12 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 00:18:31 [scrapy.extensions.logstats] INFO: Crawled 108 pages (at 5 pages/min), scraped 69 items (at 9 items/min)
2018-11-11 00:19:31 [scrapy.extensions.logstats] INFO: Crawled 121 pages (at 13 pages/min), scraped 80 items (at 11 items/min)
2018-11-11 00:20:28 [scrapy.extensions.logstats] INFO: Crawled 134 pages (at 13 pages/min), scraped 87 items (at 7 items/min)
2018-11-11 00:21:52 [scrapy.extensions.logstats] INFO: Crawled 145 pages (at 11 pages/min), scraped 105 items (at 18 items/min)
2018-11-11 00:22:44 [scrapy.extensions.logstats] INFO: Crawled 156 pages (at 11 pages/min), scraped 115 items (at 10 items/min)
2018-11-11 00:24:02 [scrapy.extensions.logstats] INFO: Crawled 169 pages (at 13 pages/min), scraped 127 items (at 12 items/min)
       valid
Crawling page: https://www.nktphotonics.com/lasers-fibers/contact/select-your-region/       valid
Crawling page: https://www.nktphotonics.com/lasers-fibers/applications/       valid
Crawling page: https://www.nktphotonics.com/lasers-fibers/2018/10/26/faster-greener-internet-coming-up/       valid
Crawling page: https://www.nktphotonics.com/lasers-fibers/2018/10/29/supercontinuum-lasers-in-pursuit-of-a-cleaner-world/       valid
Crawling page: https://www.nktphotonics.com/lasers-fibers/2018/11/05/chirped-pulse-amplification-for-the-benefit-of-mankind/       valid
Crawling page: https://www.nktphotonics.com/lasers-fibers/2018/10/24/get-a-speedy-delivery-of-your-new-laser/       valid
Crawling page: https://www.nktphotonics.com/event/       valid
Crawling page: https://www.nktphotonics.com/contact/       valid
Crawling page: https://www.nktphotonics.com/about/careers/       valid
Crawling page: https://www.nktphotonics.com/about/values-dream-design-deliver/       valid
Crawling page: https://www.nktphotonics.com/about/corporate-social-responsibility-csr/       valid
Crawling page: https://www.nktphotonics.com/about/press/       valid
Crawling page: https://www.nktphotonics.com/lasers-fibers/support/technical-support-and-customer-service/       valid
Crawling page: https://www.nktphotonics.com/about/history-nkt-photonics/       valid
Crawling page: https://www.nktphotonics.com/about/management-team/       valid
Crawling page: https://www.nktphotonics.com/about/       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Launch/Computing-solution-that-s-not-a-PC       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/platform/industrial-wireless-solutions       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/BlueHose       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Connect       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Industry/Plant-Energy-Management-Solutions       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Water-Wastewater-Solutions       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Flow-Computer-for-Oil-and-Gas       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Material-Handling       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2018/180509.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/movie/       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2018/180607.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2018/180605.html       valid
Crawling page: http://www.confluenceenergy.com/site-map       valid
Crawling page: http://www.confluenceenergy.com/news       valid
Crawling page: http://www.confluenceenergy.com/media       valid
Crawling page: https://www.nktphotonics.com/       valid
Crawling page: https://www.nktphotonics.com/lios/en/       valid
Crawling page: https://www.nktphotonics.com/lasers-fibers/       valid
Crawling page: http://www.confluenceenergy.com/about/our-story       valid
Crawling page: http://www.confluenceenergy.com/truechar-biochar-featured-colorado-biz-magazine.html       valid
Crawling page: http://www.confluenceenergy.com/tips-help-prepare-chicken-coop-winter.html       valid
Crawling page: http://www.confluenceenergy.com/about/contact       valid
Crawling page: http://www.confluenceenergy.com/quote       valid
Crawling page: http://www.confluenceenergy.com/about/team       valid
Crawling page: http://www.confluenceenergy.com/about       valid
Crawling page: http://www.confluenceenergy.com/about/facilities       valid
Crawling page: http://www.confluenceenergy.com/about/careers       valid
Crawling page: http://www.confluenceenergy.com/residential-products/cat-litter       valid
Crawling page: http://www.confluenceenergy.com/residential-products/pet-bedding       valid
Crawling page: http://www.confluenceenergy.com/products       valid
Crawling page: http://www.confluenceenergy.com/residential-products/soil-amendments       valid
Crawling page: http://www.confluenceenergy.com/residential-products/absorbents       valid
Crawling page: http://www.confluenceenergy.com/residential-products/grilling-pellets       valid
Crawling page: http://www.confluenceenergy.com/residential-products/heating       valid
Crawling page: http://www.confluenceenergy.com/agriculture       valid
Crawling page: http://www.confluenceenergy.com/agriculture/golf-course       valid
Crawling page: https://www.thermofisher.com/us/en/home/global/online-pricing-policy.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/global/terms-and-conditions.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/global/privacy-policy.html       valid
Crawling page: http://www.confluenceenergy.com/industry/erosion-control       valid
Crawling page: http://www.confluenceenergy.com/industry/bio-remediation       valid
Crawling page: http://www.dowagro.com/en-us/sitemap       valid
Crawling page: http://www.dowagro.com/en-us/transparency       valid
Crawling page: http://www.confluenceenergy.com/industry/airwater-filtration       valid
Crawling page: http://www.confluenceenergy.com/industry/reclamation       valid
Crawling page: http://www.dowagro.com/en-us/terms-of-use       valid
Crawling page: http://www.dowagro.com/en-us/blog       valid
Crawling page: http://www.dowagro.com/en-us/newsroom/pressreleases/2018/02/dowdupont-agriculture-division-to-become-corteva-agriscience       valid
Crawling page: http://www.dowagro.com/en-us/newsroom/pressreleases/2018/03/protein-science-to-advance-through-leniobio-and-dow-agrosciences-license-agreement       valid
Crawling page: http://www.dowagro.com/en-us/about-dow-agrosciences/commitment       valid
Crawling page: http://www.dowagro.com/en-us/newsroom/pressreleases/2018/05/featured-farmers-announced-for-2018-indiana-state-fair       valid
Crawling page: http://www.confluenceenergy.com/industry/hydromulch       valid
Crawling page: http://www.confluenceenergy.com/industry/absorbents       valid
Crawling page: http://www.confluenceenergy.com/industry-products/solids-control       valid
Crawling page: http://www.confluenceenergy.com/industry-products/site-reclamation       valid
Crawling page: http://seabenergy.com/feed/       valid
Crawling page: http://seabenergy.com/imprint/       valid
Crawling page: http://seabenergy.com/accessibility/       valid
Crawling page: http://seabenergy.com/sitemap/       valid
Crawling page: http://seabenergy.com/website-terms-of-use/       valid
Crawling page: http://www.confluenceenergy.com/industry-products/ecoseal       valid
Crawling page: http://www.confluenceenergy.com/industry-products/ecosponge       valid
Crawling page: http://www.confluenceenergy.com/industry-products/ecopondsweep       valid
Crawling page: http://www.confluenceenergy.com/industry-products/truechar       valid
Crawling page: http://seabenergy.com/privacy-policy/       valid
Crawling page: http://seabenergy.com/case-studies/       valid
Crawling page: http://seabenergy.com/work-with-us/resellers-home-page/       valid
Crawling page: http://seabenergy.com/grants-and-planning/       valid
Crawling page: http://seabenergy.com/work-with-us/careers/       valid
Crawling page: http://seabenergy.com/products/mb400-faqs/       valid
Crawling page: http://seabenergy.com/category/events/       valid
Crawling page: http://www.confluenceenergy.com/category/blog       valid
Crawling page: http://seabenergy.com/on-our-way-to-sydney-and-melbourne-with-innovate-uk/       valid
Crawling page: https://www.cookmedical.com/privacy-policy/       valid
Crawling page: https://www.cookmedical.com/newsroom/cook-medical-receives-fda-approval-for-first-5-mm-diameter-sfa-drug-eluting-stent/       valid
Crawling page: http://seabenergy.com/seab-energy-at-the-ecosummit-in-paris/       valid
Crawling page: http://seabenergy.com/products/mb400/       valid
Crawling page: http://seabenergy.com/products/anaerobic-digesters/       valid
Crawling page: https://www.cookmedical.com/terms-of-use/       valid
Crawling page: https://www.cookmedical.com/newsroom/bloomington-best-places-to-work-2018/2018-11-11 00:24:32 [scrapy.extensions.logstats] INFO: Crawled 169 pages (at 0 pages/min), scraped 132 items (at 5 items/min)
2018-11-11 00:25:23 [scrapy.extensions.logstats] INFO: Crawled 175 pages (at 6 pages/min), scraped 138 items (at 6 items/min)
2018-11-11 00:26:26 [scrapy.extensions.logstats] INFO: Crawled 183 pages (at 8 pages/min), scraped 145 items (at 7 items/min)
2018-11-11 00:27:44 [scrapy.extensions.logstats] INFO: Crawled 194 pages (at 11 pages/min), scraped 154 items (at 9 items/min)
2018-11-11 00:28:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.prosoft-technology.com/Landing-Pages/Connect> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 00:28:37 [scrapy.extensions.logstats] INFO: Crawled 202 pages (at 8 pages/min), scraped 160 items (at 6 items/min)
2018-11-11 00:29:35 [scrapy.extensions.logstats] INFO: Crawled 208 pages (at 6 pages/min), scraped 168 items (at 8 items/min)
2018-11-11 00:30:28 [scrapy.extensions.logstats] INFO: Crawled 214 pages (at 6 pages/min), scraped 175 items (at 7 items/min)
/bin/sh: 1: kill: Illegal number: 
/bin/sh: 1: kill: Illegal number: 
2018-11-11 00:31:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.prosoft-technology.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 00:31:49 [scrapy.extensions.logstats] INFO: Crawled 230 pages (at 16 pages/min), scraped 186 items (at 11 items/min)
2018-11-11 00:32:25 [scrapy.extensions.logstats] INFO: Crawled 231 pages (at 1 pages/min), scraped 191 items (at 5 items/min)
2018-11-11 00:33:24 [scrapy.extensions.logstats] INFO: Crawled 236 pages (at 5 pages/min), scraped 196 items (at 5 items/min)
2018-11-11 00:34:41 [scrapy.extensions.logstats] INFO: Crawled 243 pages (at 7 pages/min), scraped 203 items (at 7 items/min)
2018-11-11 00:35:23 [scrapy.extensions.logstats] INFO: Crawled 251 pages (at 8 pages/min), scraped 209 items (at 6 items/min)
2018-11-11 00:36:23 [scrapy.extensions.logstats] INFO: Crawled 259 pages (at 8 pages/min), scraped 216 items (at 7 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 00:37:26 [scrapy.extensions.logstats] INFO: Crawled 268 pages (at 9 pages/min), scraped 225 items (at 9 items/min)
       valid
Crawling page: http://seabenergy.com/author/atelierstudios/       valid
Crawling page: http://seabenergy.com/category/news/       valid
Crawling page: http://seabenergy.com/contact/       valid
Crawling page: http://seabenergy.com/work-with-us/       valid
Crawling page: https://www.cookmedical.com/endoscopy/hemospray-wins-approval-to-market-in-the-us/       valid
Crawling page: https://www.cookmedical.com/newsroom/cook-medical-begins-distribution-of-taewoong-medical-products/       valid
Crawling page: https://www.cookmedical.com/newsroom/new-results-from-2400-zilver-ptx-patients/       valid
Crawling page: https://www.cookmedical.com/sitemap/       valid
Crawling page: https://www.cookmedical.com/contact/       valid
Crawling page: https://www.cookmedical.com/urology/       valid
Crawling page: https://www.cookmedical.com/surgery/       valid
Crawling page: https://www.cookmedical.com/reproductive-health/       valid
Crawling page: https://www.cookmedical.com/otolaryngology/       valid
Crawling page: https://www.cookmedical.com/divisions/medsurg-division/       valid
Crawling page: https://www.cookmedical.com/endoscopy/       valid
Crawling page: https://www.cookmedical.com/critical-care/       valid
Crawling page: https://www.cookmedical.com/peripheral-intervention/       valid
Crawling page: https://www.cookmedical.com/lead-management/       valid
Crawling page: https://www.cookmedical.com/aortic-intervention/       valid
Crawling page: https://www.cookmedical.com/interventional-radiology/       valid
Crawling page: https://www.cookmedical.com/divisions/vascular-division/       valid
Crawling page: https://www.cookmedical.com/about/sustainability-environmental-practices/       valid
Crawling page: https://www.cookmedical.com/about/mission-and-values/       valid
Crawling page: https://www.cookmedical.com/about/history/       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Training-Videos       valid
Crawling page: https://www.cookmedical.com/newsroom/       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Data-Logger/Limited-Network-Bandwidth       valid
Crawling page: https://www.cookmedical.com/about/diversity-inclusion/       valid
Crawling page: https://www.cookmedical.com/about/ethics-compliance/       valid
Crawling page: https://www.prosoft-technology.com/About-Us/Affiliations       valid
Crawling page: http://www.prosoft-technology.com/Landing-Pages/Connect       Crawling page: https://www.prosoft-technology.com/About-Us/Customer-References       valid
Crawling page: https://www.cookmedical.com/careers/       valid
Crawling page: https://www.prosoft-technology.com/About-Us       valid
Crawling page: https://www.cookmedical.com/about/       valid
Crawling page: https://www.prosoft-technology.com/Where-to-Buy/node_9087       valid
Crawling page: https://www.cookmedical.com/support/supplier-information/       valid
Crawling page: https://www.cookmedical.com/support/reimbursement/       valid
Crawling page: https://www.prosoft-technology.com/Where-to-Buy       valid
Crawling page: https://www.cookmedical.com/support/product-performance-reporting/       valid
Crawling page: https://www.prosoft-technology.com/News-Events/Success-Stories       valid
Crawling page: https://www.prosoft-technology.com/Services-Support/Training       valid
Crawling page: https://www.cookmedical.com/support/ordering-returns/       valid
Crawling page: https://www.prosoft-technology.com/Services-Support/Legacy-Downloads       valid
Crawling page: https://www.cookmedical.com/support/general-product-information/       valid
Crawling page: https://www.prosoft-technology.com/Products/ProSoft-Software       valid
Crawling page: https://www.cookmedical.com/support/       valid
Crawling page: https://www.prosoft-technology.com/insights       valid
Crawling page: https://www.prosoft-technology.com/Products/Industrial-Wireless       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2018/180918.html       valid
Crawling page: https://www.prosoft-technology.com/Products/Remote-Access       valid
Crawling page: https://www.cookmedical.com/open-payments/       valid
Crawling page: https://www.cookmedical.com/products/       valid
Crawling page: https://www.prosoft-technology.com/cdn-cgi/l/email-protection       valid
Crawling page: http://www.jfe-steel.co.jp/en/contact.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2018/180926.html       valid
Crawling page: https://www.prosoft-technology.com/       valid
Crawling page: http://www.prosoft-technology.com/       Crawling page: https://www.prosoft-technology.com/Products       valid
Crawling page: http://www.jfe-steel.co.jp/en/terms.html       valid
Crawling page: https://www.cookmedical.com/healthcare-business-solutions/       valid
Crawling page: http://www.jfe-steel.co.jp/en/research/report.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/privacy.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/research/location.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/research/info.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/research/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/energy/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/list.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/slag/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/titanium/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/stainless/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/shapes/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/plate/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/sheets/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2008.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2009.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2012.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2011.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2010.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2013.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/ironpowders/index.php       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/wirerods/index.php       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2014.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2015.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/pipes/index.php       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2016.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/products/electrical/index.php       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2017.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/company/about.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/2018.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/release/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/company/management.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/company/steel.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/company/philosophy.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/company/ceo.html       valid
Crawling page: http://www.confluenceenergy.com/       valid
Crawling page: http://www.jfe-steel.co.jp/en/company/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/ch/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/index.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/sitemap.html       valid
Crawling page: http://www.jfe-steel.co.jp/en/company/facilities.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/sequencing/sanger-sequencing/sanger-sequencing-technology-accessories/applied-biosystems-sanger-sequencing-3500-series-genetic-analyzers/3500-series-genetic-analyzer.html?icid=Default_WB313352018-11-11 00:38:27 [scrapy.extensions.logstats] INFO: Crawled 270 pages (at 2 pages/min), scraped 231 items (at 6 items/min)
2018-11-11 00:40:08 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 15 pages/min), scraped 238 items (at 7 items/min)
2018-11-11 00:41:14 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 0 pages/min), scraped 244 items (at 6 items/min)
2018-11-11 00:41:38 [scrapy.extensions.logstats] INFO: Crawled 286 pages (at 1 pages/min), scraped 246 items (at 2 items/min)
2018-11-11 00:42:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.thermofisher.com/order/catalog/en/US/adirect/lt?cmd=catDisplayStyle&catKey=101&&filterType=1&OP=filter&filter=ft_1701%2Ff_2020619*&_bcs_=H4sIAAAAAAAAANM1VDWwCCjKTylNLinWVjUy0w5OLSrLTE4txiOeUVJSUKxq7Khq5AZE5eXleiUZ%0AqUW5%2BWmZxUBaLzk%2FFyhcWgwkUvOAREZ%2BbiqQyi9KAUpmlOTmAI1QNTIGIQOLkqLSVCAFAFTSfayI%0AAAAA> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 00:42:42 [scrapy.extensions.logstats] INFO: Crawled 307 pages (at 21 pages/min), scraped 253 items (at 7 items/min)
2018-11-11 00:45:09 [scrapy.extensions.logstats] INFO: Crawled 312 pages (at 5 pages/min), scraped 259 items (at 6 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 00:45:53 [scrapy.extensions.logstats] INFO: Crawled 312 pages (at 0 pages/min), scraped 267 items (at 8 items/min)
2018-11-11 00:46:40 [scrapy.extensions.logstats] INFO: Crawled 315 pages (at 3 pages/min), scraped 272 items (at 5 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 00:47:26 [scrapy.extensions.logstats] INFO: Crawled 322 pages (at 7 pages/min), scraped 276 items (at 4 items/min)
2018-11-11 00:48:41 [scrapy.extensions.logstats] INFO: Crawled 329 pages (at 7 pages/min), scraped 285 items (at 9 items/min)
2018-11-11 00:49:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 http://www.butamax.com/Default.aspx?tabid=125&error=An%20unexpected%20error%20has%20occurred&content=0>: HTTP status code is not handled or not allowed
2018-11-11 00:49:34 [scrapy.extensions.logstats] INFO: Crawled 333 pages (at 4 pages/min), scraped 289 items (at 4 items/min)
2018-11-11 00:50:25 [scrapy.extensions.logstats] INFO: Crawled 337 pages (at 4 pages/min), scraped 293 items (at 4 items/min)
       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/taqman-multiplex-qpcr-solution/taqpath-one-step-multiplex-master-mix.html?icid=Default_WB31173       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/sequencing/sanger-sequencing/sanger-sequencing-technology-accessories/seqstudio-genetic-analyzer.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/sequencing/sequencing-technology-solutions.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-reagents.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cloning/cloning-learning-center/invitrogen-school-of-molecular-biology/pcr-education.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/gene-expression-analysis-genotyping/genotyping-genomic-profiling.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-promotions.html       valid
Crawling page: http://altarockenergy.com/about-us/partners/       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/sequencing/sequencing-kits-reagents.html       valid
Crawling page: http://altarockenergy.com/super-hot-egs/       valid
Crawling page: http://altarockenergy.com/bcep/       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-learning-center/real-time-pcr-basics/real-time-vs-digital-vs-traditional-pcr.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/ion-torrent.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/gibco.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-instruments/quantstudio-qpcr-product-portfolio.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-reagents/real-time-master-mix-selection-guide.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/gene-expression-analysis-genotyping/laser-capture-microdissection.html       valid
Crawling page: http://www.dowagro.com/en-us/contact-us       valid
Crawling page: http://www.dowagro.com/en-us       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-learning-center.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-learning-center/real-time-pcr-basics/ask-taqman-video-series.html       valid
Crawling page: http://altarockenergy.com/technology/       valid
Crawling page: http://altarockenergy.com/about-us/       valid
Crawling page: https://www.thermofisher.com/order/catalog/en/US/adirect/lt?cmd=catDisplayStyle&catKey=101&&filterType=1&OP=filter&filter=ft_1701%2Ff_2020619*&_bcs_=H4sIAAAAAAAAANM1VDWwCCjKTylNLinWVjUy0w5OLSrLTE4txiOeUVJSUKxq7Khq5AZE5eXleiUZ%0AqUW5%2BWmZxUBaLzk%2FFyhcWgwkUvOAREZ%2BbiqQyi9KAUpmlOTmAI1QNTIGIQOLkqLSVCAFAFTSfayI%0AAAAA       Crawling page: http://seabenergy.com/products/       valid
Crawling page: http://www.dowagro.com/en-us/on-the-table       valid
Crawling page: http://altarockenergy.com       valid
Crawling page: http://www.dowagro.com/en-us/careers       valid
Crawling page: http://www.dowagro.com/en-us/newsroom       valid
Crawling page: http://www.dowagro.com/en-us/sustainability       valid
Crawling page: http://altarockenergy.com/feed/       valid
Crawling page: http://www.butamax.com/DesktopModules/DnnForge%20-%20NewsArticles/Rss.aspx?TabID=108&ModuleID=590       valid
Crawling page: http://www.butamax.com/privacy-statement.aspx       valid
Crawling page: http://www.butamax.com/legal-notice.aspx       valid
Crawling page: http://seabenergy.com/about-seab/       valid
Crawling page: http://seabenergy.com/       valid
Crawling page: http://www.dowagro.com/en-us/innovation       valid
Crawling page: http://www.dowagro.com/en-us/about-dow-agrosciences       valid
Crawling page: http://www.butamax.com/contact.aspx       valid
Crawling page: http://www.butamax.com/latest-news-updates.aspx       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-assays/taqman-gene-expression.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/digital-pcr.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/microarray-analysis/affymetrix.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/bioproduction/contaminant-and-impurity-testing.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/digital-pcr/quantstudio-3d-digital-pcr-system.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/pcr-enzymes-master-mixes.html       valid
Crawling page: http://www.butamax.com/       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/sequencing/sanger-sequencing.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-reagents/sybr-green-real-time-master-mixes.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/thermal-cyclers-realtime-instruments/thermal-cyclers/proflex-pcr-system.html       valid
Crawling page: http://www.butamax.com/biofuel-company.aspx       valid
Crawling page: http://www.butamax.com/The-Bio-Isobutanol-Advantage/The-Bio-Isobutanol-Advantage.aspx       valid
Crawling page: http://www.butamax.com/renewable-fuel-technologies.aspx       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-instruments.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/global/forms/life-science/real-time-pcr-innovations-poster-request.html?icid=L1-BRAB-TB-GSD-WB34678-qPCRInnovationsPoster-20180910-na       valid
Crawling page: https://www.thermofisher.com/us/en/home/about-us/partnering-licensing.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cell-culture/transfection/transfection-support/transfection-protocol-calculator.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cell-culture/cell-culture-plastics/corning-nunc-cross-reference-tool.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/thermo-scientific/molecular-biology/molecular-biology-learning-center/molecular-biology-resource-library/thermo-scientific-web-tools.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-data-management-analysis-software/lab-apps.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cell-culture/mammalian-cell-culture/classical-media/gibco-media-formulation-tool.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-data-management-analysis-software/lab-apps/cell-staining-tool.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cloning/restriction-enzyme-digestion-and-ligation/restriction-enzyme-cloning/anza-restriction-enzyme-system/anza-enzyme-selection-tool.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/technical-reference-library.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/instrument-support.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/cloud.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/support/webinars.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/services/training-services.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/technical-reference-library/how-to-and-educational-videos.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/about-us/events.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/services/financial-leasing-services.html2018-11-11 00:51:52 [scrapy.extensions.logstats] INFO: Crawled 344 pages (at 7 pages/min), scraped 300 items (at 7 items/min)
2018-11-11 00:52:31 [scrapy.extensions.logstats] INFO: Crawled 348 pages (at 4 pages/min), scraped 303 items (at 3 items/min)
2018-11-11 00:53:33 [scrapy.extensions.logstats] INFO: Crawled 353 pages (at 5 pages/min), scraped 308 items (at 5 items/min)
2018-11-11 00:54:33 [scrapy.extensions.logstats] INFO: Crawled 359 pages (at 6 pages/min), scraped 313 items (at 5 items/min)
2018-11-11 00:55:36 [scrapy.extensions.logstats] INFO: Crawled 365 pages (at 6 pages/min), scraped 319 items (at 6 items/min)
2018-11-11 00:56:51 [scrapy.extensions.logstats] INFO: Crawled 369 pages (at 4 pages/min), scraped 325 items (at 6 items/min)
2018-11-11 00:57:31 [scrapy.extensions.logstats] INFO: Crawled 373 pages (at 4 pages/min), scraped 328 items (at 3 items/min)
2018-11-11 00:58:47 [scrapy.extensions.logstats] INFO: Crawled 376 pages (at 3 pages/min), scraped 333 items (at 5 items/min)
2018-11-11 00:59:54 [scrapy.extensions.logstats] INFO: Crawled 382 pages (at 6 pages/min), scraped 338 items (at 5 items/min)
2018-11-11 01:00:27 [scrapy.extensions.logstats] INFO: Crawled 386 pages (at 4 pages/min), scraped 341 items (at 3 items/min)
2018-11-11 01:01:51 [scrapy.extensions.logstats] INFO: Crawled 391 pages (at 5 pages/min), scraped 347 items (at 6 items/min)
2018-11-11 01:02:27 [scrapy.extensions.logstats] INFO: Crawled 395 pages (at 4 pages/min), scraped 350 items (at 3 items/min)
2018-11-11 01:03:46 [scrapy.extensions.logstats] INFO: Crawled 401 pages (at 6 pages/min), scraped 356 items (at 6 items/min)
2018-11-11 01:04:23 [scrapy.extensions.logstats] INFO: Crawled 404 pages (at 3 pages/min), scraped 359 items (at 3 items/min)
2018-11-11 01:05:51 [scrapy.extensions.logstats] INFO: Crawled 410 pages (at 6 pages/min), scraped 365 items (at 6 items/min)
2018-11-11 01:06:38 [scrapy.extensions.logstats] INFO: Crawled 413 pages (at 3 pages/min), scraped 368 items (at 3 items/min)
2018-11-11 01:07:50 [scrapy.extensions.logstats] INFO: Crawled 418 pages (at 5 pages/min), scraped 374 items (at 6 items/min)
       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/services/enterprise-services.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-data-management-analysis-software/enterprise-level-lab-informatics.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/services/custom-services.html       valid
Crawling page: https://www.thermofisher.com/search/results?query=Product+Literature%20&type=Product+Literature       valid
Crawling page: https://www.thermofisher.com/us/en/home/references/newsletters-and-journals.html       valid
Crawling page: https://www.thermofisher.com/search/results?query=Media+Formulations&type=Media+Formulations       valid
Crawling page: https://www.thermofisher.com/search/results?query=Chemical+Structures&type=Chemical+Structures       valid
Crawling page: https://www.thermofisher.com/search/results?query=Vector+Data&type=Vector+Data       valid
Crawling page: https://www.thermofisher.com/search/results?query=SDS&type=SDS       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/rohs-certificates.html       valid
Crawling page: https://www.thermofisher.com/search/results?query=Certificates&type=Certificates       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/declarations-conformity.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/references/protocols.html       valid
Crawling page: https://www.thermofisher.com/search/results?query=Manuals+%26+Protocols&type=Manuals+%26+Protocols       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/order-support.html       valid
Crawling page: https://www.thermofisher.com/order/catalog/en/US/direct/lt?cmd=IVGNQuickOrderLanding       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/ordering-web-faqs/shopping-cart-checkout/how-to-order.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/data-analysis-bioinformatics-software.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/primers-oligos-cloning-gene-synthesis.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/labware.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/antibodies/immunoassays/elisa-kits.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/lab-reagents-chemicals.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/lab-instruments-equipment.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/drug-discovery-assays.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/chromatography-columns-resins.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/cell-culture-transfection-reagents.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/antibodies-immunoassays.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/product-brand/trizol.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/product-brand/superscript.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-plasticware-supplies/nalgene-labware.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/product-brand/lipofectamine.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-equipment/lab-centrifuges.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/promotions/life-science/LPE-Marketplace.html?icid=L1-SA-MN5-XPLAT-LPD-WB42184-mkpl-10-15-18       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/thermo-scientific/molecular-biology/marketplace.html?icid=L1-SA-MN3-BID-WB34554-MolBioMarketplace3-20180906-na       valid
Crawling page: https://www.thermofisher.com/search/onlineoffers?icid=L1-SA-MN2-XPLAT-LSG-WB32540-online-only-offers-20170517-NA       valid
Crawling page: https://www.thermofisher.com/us/en/home/order.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/about-us/partnering-licensing/oem-commercial-supply.html       valid
Crawling page: https://www.thermofisher.com/search/onlineoffers       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/promotions.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/new-products.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/services.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/sample-storage-management.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-plasticware-supplies.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-equipment.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-data-management-analysis-software.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-equipment/lab-automation.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-equipment/cold-storage/lab-freezers/ultra-low-temperature-freezers-minus-80.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/chemicals.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/lab-solutions.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical/preclinical-companion-diagnostic-development.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical/precision-medicine.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical/diagnostic-testing.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical/diagnostic-development.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical/clinical-translational-research.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical/clinical-microbiology.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical/biobanking.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical/anatomical-pathology.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/spectroscopy-elemental-isotope-analysis.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/radiation-detection-measurement.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/pharma-biopharma.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/microbiology.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/mass-spectrometry.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/manufacturing-processing.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/food-beverage.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/environmental.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/electron-microscopy.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/pharma-biopharma/drug-discovery-development.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/cement-coal-minerals.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/bioproduction.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/animal-health.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/agricultural-biotechnology.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/stem-cell-research.html2018-11-11 01:08:31 [scrapy.extensions.logstats] INFO: Crawled 422 pages (at 4 pages/min), scraped 377 items (at 3 items/min)
2018-11-11 01:09:43 [scrapy.extensions.logstats] INFO: Crawled 428 pages (at 6 pages/min), scraped 383 items (at 6 items/min)
2018-11-11 01:10:28 [scrapy.extensions.logstats] INFO: Crawled 431 pages (at 3 pages/min), scraped 386 items (at 3 items/min)
2018-11-11 01:11:37 [scrapy.extensions.logstats] INFO: Crawled 436 pages (at 5 pages/min), scraped 392 items (at 6 items/min)
2018-11-11 01:12:40 [scrapy.extensions.logstats] INFO: Crawled 440 pages (at 4 pages/min), scraped 397 items (at 5 items/min)
2018-11-11 01:13:29 [scrapy.extensions.logstats] INFO: Crawled 454 pages (at 14 pages/min), scraped 407 items (at 10 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 01:14:24 [scrapy.extensions.logstats] INFO: Crawled 464 pages (at 10 pages/min), scraped 416 items (at 9 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 01:15:30 [scrapy.extensions.logstats] INFO: Crawled 482 pages (at 18 pages/min), scraped 431 items (at 15 items/min)
2018-11-11 01:16:31 [scrapy.extensions.logstats] INFO: Crawled 486 pages (at 4 pages/min), scraped 441 items (at 10 items/min)
       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/sequencing.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/rnai.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/protein-biology.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/microarray-analysis.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/genome-editing.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/gene-expression-analysis-genotyping.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cell-analysis/flow-cytometry.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/epigenetics-noncoding-rna-research.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/dna-rna-purification-analysis.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cell-culture.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cell-analysis.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/unity-lab-services.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/invitrogen.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/thermo-scientific.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/applications-techniques.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cell-culture/cell-culture-plastics.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/antibodies.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/pcr/real-time-pcr/real-time-pcr-assays.html       valid
Crawling page: https://www.thermofisher.com/order/catalog/en/US/partnerMkt/lt?cmd=IVGNMCPWorkspaceSummaryDisplay       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/services/instrument-qualification-services/instruments-and-services-portal.html       valid
Crawling page: https://www.thermofisher.com/order/catalog/en/US/partnerMkt/lt?cmd=SharedListLanding       valid
Crawling page: https://www.thermofisher.com/store/orders/details/details.html       valid
Crawling page: https://www.thermofisher.com/order/catalog/en/US/partnerMkt/lt?cmd=WorkspaceTemplateRequest       valid
Crawling page: https://www.thermofisher.com/order/catalog/en/US/partnerMkt/lt?cmd=RecurringOrderLanding       valid
Crawling page: https://www.thermofisher.com/order/catalog/en/US/partnerMkt/lt?cmd=IVGNMyActivityDisplay       valid
Crawling page: https://www.thermofisher.com/order/catalog/en/US/adirect/lt?cmd=IVGNQuickOrderLanding       valid
Crawling page: https://www.thermofisher.com/order/catalog/en/US/direct/lt?cmd=IVGNMyActivityDisplay       valid
Crawling page: http://www.coveris.com/privacy/cookie-policy/       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/contact-us.html       valid
Crawling page: http://www.coveris.com/coveris-reports-first-quarter-2018-financial-results/       valid
Crawling page: http://www.coveris.com/personal-data-protection-new-coveris-gdpr-policy/       valid
Crawling page: http://www.coveris.com/coveris-management-host-call-discuss-first-quarter-2018-financial-results/       valid
Crawling page: https://www.thermofisher.com:443/oam/server/obrareq.cgi?wh%3Dwww.thermofisher.com%20wu%3D%2Forder%2Fcatalog%2Fen%2FUS%2Fdirect%2Flt%3Fcmd%3DdirectLogin%26LoginData-Command%3DupdateExecute%26LoginData-entryPoint%3Ddirect%26LoginData-messageType%3DFullRegistrationData%26LoginData-anonymousHomePageMsg%3DOnlineOrderingPageDisplay%26LoginData-GroupKey%3D103%20wo%3D1%20rh%3Dhttps%3A%2F%2Fwww.thermofisher.com%20ru%3D%252Forder%252Fcatalog%252Fen%252FUS%252Fdirect%252Flt%20rq%3Dcmd%253DdirectLogin%2526LoginData-Command%253DupdateExecute%2526LoginData-entryPoint%253Ddirect%2526LoginData-messageType%253DFullRegistrationData%2526LoginData-anonymousHomePageMsg%253DOnlineOrderingPageDisplay%2526LoginData-GroupKey%253D103       valid
Crawling page: https://www.thermofisher.com:443/oam/server/obrareq.cgi?wh%3Dwww.thermofisher.com%20wu%3D%2Forder%2Fcatalog%2Fen%2FUS%2FpartnerMkt%2Flt%3Fcmd%3DpartnerMktLogin%26LoginData-entryPoint%3DpartnerMkt%26LoginData-messageType%3DUserProfileDisplay%20wo%3D1%20rh%3Dhttps%3A%2F%2Fwww.thermofisher.com%20ru%3D%252Forder%252Fcatalog%252Fen%252FUS%252FpartnerMkt%252Flt%20rq%3Dcmd%253DpartnerMktLogin%2526LoginData-entryPoint%253DpartnerMkt%2526LoginData-messageType%253DUserProfileDisplay       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/applied-biosystems.html       valid
Crawling page: https://www.thermofisher.com:443/oam/server/obrareq.cgi?wh%3Dwww.thermofisher.com%20wu%3D%2Forder%2Fcatalog%2Fen%2FUS%2Fadirect%2Flt%3Fcmd%3DpartnerMktLogin%26LoginData-referer%3Dtrue%26LoginData-ReturnURL%3Dhttps%253a%252f%252fwww%252ethermofisher%252ecom%252fus%252fen%252fhome%252fbrands%252fapplied%252dbiosystems%252ehtml%20wo%3D1%20rh%3Dhttps%3A%2F%2Fwww.thermofisher.com%20ru%3D%252Forder%252Fcatalog%252Fen%252FUS%252Fadirect%252Flt%20rq%3Dcmd%253DpartnerMktLogin%2526LoginData-referer%253Dtrue%2526LoginData-ReturnURL%253Dhttps%25253a%25252f%25252fwww%25252ethermofisher%25252ecom%25252fus%25252fen%25252fhome%25252fbrands%25252fapplied%25252dbiosystems%25252ehtml       valid
Crawling page: http://www.coveris.com/technologies/printing/       valid
Crawling page: http://www.coveris.com/technologies/molding/       valid
Crawling page: http://www.coveris.com/technologies/converting/       valid
Crawling page: http://www.coveris.com/technologies/labeling/       valid
Crawling page: http://www.coveris.com/markets/medical/       valid
Crawling page: http://www.coveris.com/technologies/extrusion/       valid
Crawling page: http://www.coveris.com/markets/performance-industrial/       valid
Crawling page: http://www.coveris.com/markets/mailings-security/       valid
Crawling page: http://www.coveris.com/markets/food-service/       valid
Crawling page: http://www.coveris.com/markets/household-personal-care/       valid
Crawling page: http://www.coveris.com/markets/beverage/       valid
Crawling page: http://www.sagaciousinvestmentservices.com/       valid
Crawling page: http://www.sagaciousinvestmentservices.com/contact.html       valid
Crawling page: http://www.coveris.com/markets/produce/       valid
Crawling page: http://www.coveris.com/markets/pet-food/       valid
Crawling page: http://www.coveris.com/markets/cheese-dairy/       valid
Crawling page: http://www.sagaciousinvestmentservices.com/services.html       valid
Crawling page: http://www.coveris.com/markets/       valid
Crawling page: http://www.coveris.com/company/compliance/       valid
Crawling page: http://www.coveris.com/company/sustainability/       valid
Crawling page: https://www.hollingsworth-vose.com/Privacy-Notice/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Rss-Feed/       valid
Crawling page: http://www.sagaciousinvestmentservices.com/about-us22.html       valid
Crawling page: http://www.sagaciousinvestmentservices.com/home.html       valid
Crawling page: https://www.hollingsworth-vose.com/en/Privacy-Notice/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/News--Events/Events/2018/FSA-2018--FILTREX-ASIA-2018/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Battery-Separators/Valve-Regulated-Lead-Acid/Automotive-Start-Stop/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Contact-Us/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Press/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/News--Events/2018-11-11 01:17:39 [scrapy.extensions.logstats] INFO: Crawled 505 pages (at 19 pages/min), scraped 456 items (at 15 items/min)
2018-11-11 01:18:27 [scrapy.extensions.logstats] INFO: Crawled 513 pages (at 8 pages/min), scraped 468 items (at 12 items/min)
2018-11-11 01:19:39 [scrapy.extensions.logstats] INFO: Crawled 529 pages (at 16 pages/min), scraped 484 items (at 16 items/min)
2018-11-11 01:20:30 [scrapy.extensions.logstats] INFO: Crawled 545 pages (at 16 pages/min), scraped 496 items (at 12 items/min)
2018-11-11 01:21:35 [scrapy.extensions.logstats] INFO: Crawled 557 pages (at 12 pages/min), scraped 511 items (at 15 items/min)
2018-11-11 01:22:31 [scrapy.extensions.logstats] INFO: Crawled 569 pages (at 12 pages/min), scraped 524 items (at 13 items/min)
/bin/sh: 1: kill: No such process

       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Certifications/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Company-History/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Careers/Entry-Programs/       valid
Crawling page: https://www.hollingsworth-vose.com/KnowledgeCenter/Videos/       valid
Crawling page: https://www.hollingsworth-vose.com/Products/Filtration-Media/Air-Filtration1/HVAC-filtration/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Careers/Current-Open-Positions/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Careers/Benefits/       valid
Crawling page: http://www.coveris.com/markets/protein-packaging/       valid
Crawling page: http://www.coveris.com/markets/dry-foods/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Careers/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Code-of-Ethics/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/Liam-Weston/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/David-von-Loesecke/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/Nick-Starita/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/John-Zhang/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/Deirdre-Murphy/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/John-Madej/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/Jochem-Hofstetter/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/Bio2/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/Ken-Fausnacht/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/Mike-Clark/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/Bio1/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/Josh-Ayer1/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Management-Bios/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/White-Papers/veils/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/Global-Presence/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Company/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/White-Papers/Media/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/White-Papers/nanofiber/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/White-Papers/hepa-upla/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/White-Papers/WhitePaper2/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/White-Papers/White-paper-5/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/Videos/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/White-Papers/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/Links/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/Industrial---Apparel--Home-Furnishings/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/Industrial---Home-Furnishings-/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/Glossary/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/Industrial-FAQs/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/FAQ/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/Liquid-Filtration-FAQs/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/Lithium-FAQs/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/Industrial---Advanced-Fiber-Nonwovens/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/Hi-Sep-FAQs/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/Lead-Acid-FAQs/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/Case-Studies/Case-Study5/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/FAQs/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Innovation/Testing-Standards/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/Case-Studies/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/       valid
Crawling page: https://www.hollingsworth-vose.com/en/KnowledgeCenter/Case-Studies/Case-Study6/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Innovation/Open-Innovation/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Innovation/Process-Capabilities/Lamination--Composites/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Innovation/Process-Capabilities/Dry-Laid/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Innovation/Process-Capabilities/Polymer-to-Web/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Innovation/Process-Capabilities/Wet-Laid/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Innovation/Process-Capabilities/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Innovation/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Industries/Aerospace/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Industries/Industrial--Manufacturing/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Industries/Apparel-And-Home-Furnishings/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Industries/Other-Chemistries/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Industries/Heavy-Equipment/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Industries/Indoor-Air-Quality/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Industries/Transportation/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Industries/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Products-Index/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Industrial-Products/Product-Sub-Cat2/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Industrial-Products/Product-Sub-Cat1/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Industrial-Products/Home-Furnishings/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Industrial-Products/Industrial-Nonwovens/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Industrial-Products/Advanced-Fiber-Nonwovens/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Industrial-Products/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Battery-Separators/Lithium/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Battery-Separators/Hi-Sep/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Battery-Separators/Valve-Regulated-Lead-Acid/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Battery-Separators/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Filtration-Media/Liquid-Filtration1/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Filtration-Media/Air-Filtration1/       valid
Crawling page: https://www.landauer.com/sitemap       valid
Crawling page: https://www.hollingsworth-vose.com/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/       valid
Crawling page: https://www.hollingsworth-vose.com/en/Products/Filtration-Media/       valid
Crawling page: https://www.landauer.com/resource/clinical-dose-optimization-servicetm-briefing-series-22018-11-11 01:23:24 [scrapy.extensions.logstats] INFO: Crawled 581 pages (at 12 pages/min), scraped 532 items (at 8 items/min)
2018-11-11 01:24:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://www.landauer.com/medical-dental-veterinary-old>: HTTP status code is not handled or not allowed
2018-11-11 01:24:47 [scrapy.extensions.logstats] INFO: Crawled 587 pages (at 6 pages/min), scraped 542 items (at 10 items/min)
2018-11-11 01:25:45 [scrapy.extensions.logstats] INFO: Crawled 595 pages (at 8 pages/min), scraped 549 items (at 7 items/min)
2018-11-11 01:26:30 [scrapy.extensions.logstats] INFO: Crawled 601 pages (at 6 pages/min), scraped 553 items (at 4 items/min)
2018-11-11 01:27:31 [scrapy.extensions.logstats] INFO: Crawled 609 pages (at 8 pages/min), scraped 561 items (at 8 items/min)
2018-11-11 01:28:42 [scrapy.extensions.logstats] INFO: Crawled 615 pages (at 6 pages/min), scraped 569 items (at 8 items/min)
2018-11-11 01:29:30 [scrapy.extensions.logstats] INFO: Crawled 628 pages (at 13 pages/min), scraped 574 items (at 5 items/min)
2018-11-11 01:30:46 [scrapy.extensions.logstats] INFO: Crawled 637 pages (at 9 pages/min), scraped 592 items (at 18 items/min)
2018-11-11 01:31:35 [scrapy.extensions.logstats] INFO: Crawled 647 pages (at 10 pages/min), scraped 597 items (at 5 items/min)
2018-11-11 01:32:41 [scrapy.extensions.logstats] INFO: Crawled 649 pages (at 2 pages/min), scraped 601 items (at 4 items/min)
2018-11-11 01:33:25 [scrapy.extensions.logstats] INFO: Crawled 649 pages (at 0 pages/min), scraped 604 items (at 3 items/min)
2018-11-11 01:35:04 [scrapy.extensions.logstats] INFO: Crawled 661 pages (at 12 pages/min), scraped 614 items (at 10 items/min)
2018-11-11 01:35:29 [scrapy.extensions.logstats] INFO: Crawled 661 pages (at 0 pages/min), scraped 618 items (at 4 items/min)
       valid
Crawling page: https://www.landauer.com/resource/diagnostic-imaging-services-standards-survey-experience-future-directions-joint-commission       valid
Crawling page: https://www.landauer.com/resource/how-wear-your-luxel-dosimeter-badge-correctly       valid
Crawling page: https://www.landauer.com/residency-programs       valid
Crawling page: https://www.landauer.com/news       valid
Crawling page: https://www.landauer.com/data-security       valid
Crawling page: https://www.landauer.com/faq       valid
Crawling page: https://www.landauer.com/global       valid
Crawling page: https://www.landauer.com/request-quote       valid
Crawling page: https://www.landauer.com/distributors       valid
Crawling page: https://www.landauer.com/military-first-responders       valid
Crawling page: https://www.landauer.com/sales       valid
Crawling page: https://www.landauer.com/radiation-monitoring-programs       valid
Crawling page: https://www.landauer.com/multiple-accreditations       valid
Crawling page: https://www.landauer.com/industry-energy       valid
Crawling page: https://www.landauer.com/luxel       valid
Crawling page: https://www.landauer.com/medical-dental-veterinary       valid
Crawling page: https://www.landauer.com/radiation-safety-support       valid
Crawling page: https://www.landauer.com/therapy-medical-physics-residency-programs       valid
Crawling page: https://www.landauer.com/special-physics-consulting       valid
Crawling page: https://www.landauer.com/regulatory-compliance       valid
Crawling page: https://www.landauer.com/onsite-physics-dosimetry       valid
Crawling page: https://www.landauer.com/oncology-practice-accreditation       valid
Crawling page: https://www.landauer.com/radiation-oncology-commissioning       valid
Crawling page: https://www.landauer.com/radiation-oncology       valid
Crawling page: https://www.landauer.com/standardization       valid
Crawling page: https://www.landauer.com/imaging-accreditation       valid
Crawling page: https://www.landauer.com/imaging-equipment-performance       valid
Crawling page: https://www.landauer.com/imaging-equipment-acceptance       valid
Crawling page: https://www.landauer.com/nuclear-medicine-physics       valid
Crawling page: https://www.landauer.com/radiation-protection-program       valid
Crawling page: https://www.landauer.com/imaging-shielding-design       valid
Crawling page: https://www.landauer.com/cdos       valid
Crawling page: https://www.landauer.com/equipment-performance-testing       valid
Crawling page: https://www.landauer.com/imaging-physics       valid
Crawling page: https://www.landauer.com/abcs-radiation-safety-culture       valid
Crawling page: https://www.landauer.com/real-time-dosimetry       valid
Crawling page: https://www.landauer.com/dosimetry-management       valid
Crawling page: https://www.landauer.com/health-care       valid
Crawling page: https://www.landauer.com/knowledge-center       valid
Crawling page: https://www.landauer.com/medical-physics-services       valid
Crawling page: https://www.landauer.com/dosimetry-solutions       valid
Crawling page: https://www.landauer.com/careers       valid
Crawling page: https://www.landauer.com/about       valid
Crawling page: https://www.landauer.com/contact       valid
Crawling page: https://www.landauer.com/events       valid
Crawling page: http://www.coveris.com/careers/       valid
Crawling page: http://www.coveris.com/investor-relations/       valid
Crawling page: http://www.coveris.com/news-events/       valid
Crawling page: http://www.coveris.com/legal/       valid
Crawling page: http://www.coveris.com/privacy/       valid
Crawling page: http://www.coveris.com/coveris-completes-sale-rigid-unit/       valid
Crawling page: http://entechsolutions.us/?page_id=13       valid
Crawling page: http://entechsolutions.us/?page_id=119       valid
Crawling page: http://entechsolutions.us/?page_id=17       valid
Crawling page: http://entechsolutions.us/?page_id=9       valid
Crawling page: http://www.coveris.com/contact/       valid
Crawling page: http://www.coveris.com/privacy/recruitment-policy-notice/       valid
Crawling page: http://www.coveris.com/sitemap/       valid
Crawling page: http://entechsolutions.us/?cat=3       valid
Crawling page: http://entechsolutions.us/?page_id=126       valid
Crawling page: http://entechsolutions.us/?page_id=27       valid
Crawling page: http://entechsolutions.us/?page_id=21       valid
Crawling page: http://www.coveris.com/ca-disclosure/       valid
Crawling page: http://entechsolutions.us/?page_id=117       valid
Crawling page: http://entechsolutions.us       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/oligonucleotides-primers-probes-genes.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/forensics.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/chromatography.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cancer-research.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/clinical/public-health.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cloning/synthetic-biology.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/safety-security-threat-detection.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/product-selection-guides-and-tools.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/promotions/25-off-primary-secondary-promo.html?icid=L1-SA-MN1-BID-WB31326-AntibodyAware25PctPromo-20180906-na       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-plasticware-supplies/pipettes-pipette-tips.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/order/gels-membranes.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/manufacturing-site-iso-certifications.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/knowledgebase-faqs.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cell-analysis/labeling-chemistry/fluorescence-spectraviewer.html       valid
Crawling page: http://www.butamax.com/The-Bio-Isobutanol-Advantage/Chemical-Applications.aspx       valid
Crawling page: http://altarockenergy.com/newsroom/       valid
Crawling page: https://www.thermofisher.com/search/results?query=Spectra+Data&type=Spectra+Data       valid
Crawling page: http://www.jfe-steel.co.jp/en/index.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/services/instrument-qualification-services.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/about-us/corporate-social-responsibility.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/forensics/human-identification.html       valid
Crawling page: http://altarockenergy.com/projects/       valid
Crawling page: http://www.dowagro.com/en-us/products       valid
Crawling page: http://www.dowagro.com/en-us/labels-and-sds       valid
Crawling page: https://www.thermofisher.com/us/en/home/global/trademark-information.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/eprocurement.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/supply-center.html       valid
Crawling page: https://www.thermofisher.com/blog/       valid
Crawling page: https://www.thermofisher.com/us/en/home/industrial/forensics/human-identification.html       valid
Crawling page: https://www.thermofisher.com:443/oam/server/obrareq.cgi?wh%3Dwww.thermofisher.com%20wu%3D%2Forder%2Fcatalog%2Fen%2FUS%2Fadirect%2Flt%3Fcmd%3DpartnerMktLogin%26LoginData-referer%3Dtrue%26LoginData-ReturnURL%3Dhttps%253a%252f%252fwww%252ethermofisher%252ecom%252fus%252fen%252fhome%252fbrands%252fapplied%252dbiosystems%252ehtml%20wo%3D1%20rh%3Dhttps%3A%2F%2Fwww.thermofisher.com%20ru%3D%252Forder%252Fcatalog%252Fen%252FUS%252Fadirect%252Flt%20rq%3Dcmd%253DpartnerMktLogin%2526LoginData-referer%253Dtrue%2526LoginData-ReturnURL%253Dhttps%25253a%25252f%25252fwww%25252ethermofisher%25252ecom%25252fus%25252fen%25252fhome%25252fbrands%25252fapplied%25252dbiosystems%25252ehtml2018-11-11 01:37:27 [scrapy.extensions.logstats] INFO: Crawled 679 pages (at 18 pages/min), scraped 630 items (at 12 items/min)
2018-11-11 01:38:24 [scrapy.extensions.logstats] INFO: Crawled 688 pages (at 9 pages/min), scraped 637 items (at 7 items/min)
2018-11-11 01:38:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/About-Us/Company-History>: HTTP status code is not handled or not allowed
2018-11-11 01:39:05 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.starlightenergy.us/sitemap/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:39:05 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.starlightenergy.us/contact-us-1/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:39:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/About-Us/Customer-References>: HTTP status code is not handled or not allowed
2018-11-11 01:39:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/About-Us/Affiliations>: HTTP status code is not handled or not allowed
2018-11-11 01:39:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.prosoft-technology.com/prosoft/About-Us/Industry-Recognition>: HTTP status code is not handled or not allowed
2018-11-11 01:39:29 [scrapy.extensions.logstats] INFO: Crawled 700 pages (at 12 pages/min), scraped 647 items (at 10 items/min)
2018-11-11 01:40:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com/technologies/blow-molding/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:40:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com/technologies/injection-molding/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:40:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com/technologies/films/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:40:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com/technologies/laminates/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:40:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.starlightenergy.us/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:40:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com/company/about-us/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:40:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com/company/locations/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:40:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com/company/customer-services/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:40:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com/business-system/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:40:33 [scrapy.extensions.logstats] INFO: Crawled 705 pages (at 5 pages/min), scraped 653 items (at 6 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 01:41:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com/company/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:41:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coveris.com>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:41:29 [scrapy.extensions.logstats] INFO: Crawled 732 pages (at 27 pages/min), scraped 663 items (at 10 items/min)
2018-11-11 01:41:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ampiopharma.com/privacy-policy/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:42:37 [scrapy.extensions.logstats] INFO: Crawled 746 pages (at 14 pages/min), scraped 674 items (at 11 items/min)
2018-11-11 01:43:25 [scrapy.extensions.logstats] INFO: Crawled 753 pages (at 7 pages/min), scraped 683 items (at 9 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 01:44:29 [scrapy.extensions.logstats] INFO: Crawled 759 pages (at 6 pages/min), scraped 693 items (at 10 items/min)
2018-11-11 01:44:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.skidmore.edu/athletics/intramurals/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:44:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/foundations/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:45:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/donor_relations/index.php> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/news/index.php> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:45:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/videos/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:45:33 [scrapy.extensions.logstats] INFO: Crawled 768 pages (at 9 pages/min), scraped 696 items (at 3 items/min)
2018-11-11 01:45:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/admissions/saratoga/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:45:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/summer/camps-and-sports.php> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:45:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.skidmore.edu/registrar/datesdeadlines.php> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/about/ctm/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:46:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/admissions/info/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:46:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/financialaid/index.php> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:46:37 [scrapy.extensions.logstats] INFO: Crawled 776 pages (at 8 pages/min), scraped 698 items (at 2 items/min)
2018-11-11 01:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/odsp/residencies.php> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:46:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/admissions/academics/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/skidmorehistory/index.php> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:47:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.skidmore.edu/tel:18008676007>: HTTP status code is not handled or not allowed
2018-11-11 01:47:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/about/mission.php> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:47:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.skidmore.edu/tel:15185805000>: HTTP status code is not handled or not allowed
2018-11-11 01:47:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/diversity/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:47:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/admissions/news/nine-reasons.php> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:47:30 [scrapy.extensions.logstats] INFO: Crawled 786 pages (at 10 pages/min), scraped 699 items (at 1 items/min)
2018-11-11 01:48:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/directions/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-plasticware-supplies/reusable-plasticware/plastic-beakers.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/communities-social/socialhub.html       valid
Crawling page: https://www.prosoft-technology.com/Services-Support/Customer-Support       valid
Crawling page: https://www.prosoft-technology.com/Services-Support       valid
Crawling page: https://www.prosoft-technology.com/Services-Support/Literature       valid
Crawling page: https://www.prosoft-technology.com/News-Events       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/lab-data-management-analysis-software/lab-apps.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/services/training-services/application-instrument-training-courses.html       valid
Crawling page: https://www.prosoft-technology.com/Services-Support/node_4963       valid
Crawling page: https://www.prosoft-technology.com/News-Events/Press-Releases       valid
Crawling page: https://www.prosoft-technology.com/News-Events/ProSoft-Magazine       valid
Crawling page: https://www.prosoft-technology.com/News-Events/Events       valid
Crawling page: https://www.thermofisher.com/us/en/home/technical-resources/learning-centers.html       valid
Crawling page: https://www.prosoft-technology.com/About-Us/Industry-Recognition       valid
Crawling page: https://www.prosoft-technology.com/About-Us/Corporate-Profile       valid
Crawling page: https://www.prosoft-technology.com/About-Us/Company-History       valid
Crawling page: https://www.prosoft-technology.com/About-Us/Contact-Us       valid
Crawling page: https://www.prosoft-technology.com/About-Us/Employment       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Automation-Fair-2018       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Automotive       valid
Crawling page: http://altarockenergy.com/altarock-stimulation-services/       valid
Crawling page: http://altarockenergy.com/contact/       valid
Crawling page: https://www.thermofisher.com/us/en/home/brands/fisher-scientific.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cloning.html       valid
Crawling page: https://www.thermofisher.com/us/en/home/life-science/cloning/gene-synthesis/geneart-gene-synthesis.html       valid
Crawling page: https://www.prosoft-technology.com/knowledge-base       valid
Crawling page: https://www.thermofisher.com/us/en/home/products-and-services/aspire-member-program.html?icid=AspireDDSignIn       valid
Crawling page: https://www.prosoft-technology.com/Products/Schneider-Electric-In-chassis       valid
Crawling page: https://www.prosoft-technology.com/Products/Rockwell-Automation-In-chassis       valid
Crawling page: https://www.prosoft-technology.com/Landing-Pages/Sitemap       valid
Crawling page: https://www.prosoft-technology.com/privacy/       valid
Crawling page: https://www.prosoft-technology.com/ProSoft-Technology-Legal-Terms-and-Conditions       valid
Crawling page: https://www.cookmedical.com/       valid
Crawling page: https://www.prosoft-technology.com/Products/Gateways       valid
Crawling page: https://www.delavaufood.com/category/events/       valid
Crawling page: https://www.delavaufood.com/terms-of-use/       valid
Crawling page: https://www.delavaufood.com/sitemap/       valid
Crawling page: https://www.delavaufood.com/baked-in-science-what-are-enzymes/       valid
Crawling page: https://www.delavaufood.com/clean-label-in-bakery-faster/       valid
Crawling page: http://hiqsolar.com/index.html       valid
Crawling page: http://www.glycon.com/our-products/barrier-screws       valid
Crawling page: http://ampiopharma.com/privacy-policy/       Crawling page: http://hiqsolar.com/phone/index.html?devicelock=phone       valid
Crawling page: http://hiqsolar.com/executive-team.html       valid
Crawling page: http://akronpolysys.com/index.php       valid
Crawling page: http://www.tela-inc.com/company-overview/investors/       valid
Crawling page: http://hiqsolar.com/news.html       valid
Crawling page: http://hiqsolar.com/contact-us.html       valid
Crawling page: http://hiqsolar.com/faqs---inverter.html       valid
Crawling page: http://hiqsolar.com/faqs---gw.html       valid
Crawling page: https://ampiopharma.com/news/ampio-reports-manuscript-on-the-mechanisms-of-action-moa-for-ampion-accepted-for-publication-in-clinical-and-experimental-rheumatology/       valid
Crawling page: http://blog.atomera.com/news/atomera-announces-significant-improvements-in-high-k-metal-gate-transistors/       valid
Crawling page: http://blog.atomera.com/news/atomera-licenses-mst-technology-to-asahi-kasei-microdevices-akm/       valid
Crawling page: https://dharmacon.horizondiscovery.com/privacy-policy/       valid
Crawling page: https://dharmacon.horizondiscovery.com/ordering-forms/       valid
Crawling page: http://hiqsolar.com/faqs---compliance.html       valid
Crawling page: http://hiqsolar.com/contact-support.html       valid
Crawling page: https://dharmacon.horizondiscovery.com/select-language/       valid
Crawling page: http://hiqsolar.com/gateway-mounting.html       valid
Crawling page: http://hiqsolar.com/resources.html       valid
Crawling page: https://dharmacon.horizondiscovery.com/forgot-password/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/screening-libraries/shrna/decode-pooled-lentiviral-shrna-screening-libraries-and-reagents/       valid
Crawling page: http://hiqsolar.com/ground-mount.html       valid
Crawling page: http://hiqsolar.com/tracker.html       valid
Crawling page: https://dharmacon.horizondiscovery.com/search-for-your-gene/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/tools-and-calculators/blast-tool/       valid
Crawling page: https://www.skidmore.edu/       valid
Crawling page: https://www.skidmore.edu/fosa/       valid
Crawling page: https://www.skidmore.edu/skidmorefund/index.php       valid
Crawling page: https://www.skidmore.edu/cof/       valid
Crawling page: https://www.skidmore.edu/giving/       valid
Crawling page: http://www.skidmore.edu/athletics/intramurals/       Crawling page: https://www.skidmore.edu/communications/web/feedback.php       valid
Crawling page: https://www.skidmore.edu/foundations/       Crawling page: https://www.skidmore.edu/admissions/visit/youvisit.php       valid
Crawling page: https://www.skidmore.edu/donor_relations/index.php       Crawling page: https://www.skidmore.edu/news/index.php       Crawling page: https://www.skidmore.edu/videos/       Crawling page: https://www.skidmore.edu/admissions/saratoga/       Crawling page: https://www.skidmore.edu/summer/camps-and-sports.php       Crawling page: http://www.skidmore.edu/registrar/datesdeadlines.php       Crawling page: https://www.skidmore.edu/about/ctm/       Crawling page: https://www.skidmore.edu/admissions/info/       Crawling page: https://www.skidmore.edu/financialaid/index.php       Crawling page: https://www.skidmore.edu/news/2018/1102-journalism-in-posttruth-era.php       valid
Crawling page: https://www.skidmore.edu/news/2018/1101-midterm-election-responses.php       valid
Crawling page: https://www.skidmore.edu/odsp/residencies.php       Crawling page: https://www.skidmore.edu/admissions/academics/       Crawling page: https://www.skidmore.edu/skidmorehistory/index.php       Crawling page: https://www.skidmore.edu/about/mission.php       Crawling page: https://www.skidmore.edu/diversity/       Crawling page: https://www.skidmore.edu/about/index.php       valid
Crawling page: https://www.skidmore.edu/admissions/news/nine-reasons.php       Crawling page: https://www.skidmore.edu/community/index.php       valid
Crawling page: https://www.skidmore.edu/careers/index.php       valid
Crawling page: https://www.skidmore.edu/campus/index.php       valid
Crawling page: https://www.skidmore.edu/curriculum/index.php       valid
Crawling page: https://www.skidmore.edu/directions/       Crawling page: https://www.skidmore.edu/news/2018/1015-skidmore-why-early-decision.php       valid
2018-11-11 01:48:23 [scrapy.extensions.logstats] INFO: Crawled 791 pages (at 5 pages/min), scraped 705 items (at 6 items/min)
2018-11-11 01:49:30 [scrapy.extensions.logstats] INFO: Crawled 800 pages (at 9 pages/min), scraped 714 items (at 9 items/min)
2018-11-11 01:50:25 [scrapy.extensions.logstats] INFO: Crawled 810 pages (at 10 pages/min), scraped 721 items (at 7 items/min)
2018-11-11 01:51:26 [scrapy.extensions.logstats] INFO: Crawled 817 pages (at 7 pages/min), scraped 728 items (at 7 items/min)
2018-11-11 01:52:25 [scrapy.extensions.logstats] INFO: Crawled 822 pages (at 5 pages/min), scraped 736 items (at 8 items/min)
2018-11-11 01:53:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.skidmore.edu/presidentssociety//> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:53:29 [scrapy.extensions.logstats] INFO: Crawled 834 pages (at 12 pages/min), scraped 744 items (at 8 items/min)
2018-11-11 01:53:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.alumni.skidmore.edu/s/1187/index.aspx?sid=1187&gid=1&pgid=3156>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 01:54:33 [scrapy.extensions.logstats] INFO: Crawled 839 pages (at 5 pages/min), scraped 752 items (at 8 items/min)
2018-11-11 01:56:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://calendar.skidmore.edu/mastercalendar/MasterCalendar.aspx> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 01:56:51 [scrapy.extensions.logstats] INFO: Crawled 847 pages (at 8 pages/min), scraped 757 items (at 5 items/min)
2018-11-11 01:57:42 [scrapy.extensions.logstats] INFO: Crawled 861 pages (at 14 pages/min), scraped 764 items (at 7 items/min)
2018-11-11 01:58:23 [scrapy.extensions.logstats] INFO: Crawled 863 pages (at 2 pages/min), scraped 770 items (at 6 items/min)
2018-11-11 01:59:25 [scrapy.extensions.logstats] INFO: Crawled 873 pages (at 10 pages/min), scraped 779 items (at 9 items/min)
2018-11-11 02:00:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/purchaseterms>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 02:00:37 [scrapy.extensions.logstats] INFO: Crawled 879 pages (at 6 pages/min), scraped 788 items (at 9 items/min)
2018-11-11 02:01:30 [scrapy.extensions.logstats] INFO: Crawled 892 pages (at 13 pages/min), scraped 795 items (at 7 items/min)
Crawling page: https://www.skidmore.edu/news/2018/1004-hassan-lopez-maniacal.php       valid
Crawling page: https://www.skidmore.edu/news/2018/1030-statement-pittsburgh-synagogue-shooting.php       valid
Crawling page: https://www.skidmore.edu/news/2018/1025-career-jam.php       valid
Crawling page: https://www.skidmore.edu/news/2018/1030-freespeech.php       valid
Crawling page: https://www.skidmore.edu/news/2018/1020-cis-groundbreaking.php       valid
Crawling page: https://www.skidmore.edu/news/2018/1025-why-skidmore-jesse-epstein.php       valid
Crawling page: https://www.skidmore.edu/advancement/staff.php       valid
Crawling page: https://www.skidmore.edu/advancement/       valid
Crawling page: https://www.skidmore.edu/sustainability/       valid
Crawling page: https://www.skidmore.edu/news/2018/1101-leonardbernsteinconcert.php       valid
Crawling page: https://www.skidmore.edu/saratogaclassic/       valid
Crawling page: https://www.skidmore.edu/parents/giving.php       valid
Crawling page: https://www.skidmore.edu/fosa/benefit/       valid
Crawling page: https://www.skidmore.edu/hof/       valid
Crawling page: https://www.skidmore.edu/youngalumni/       valid
Crawling page: https://www.skidmore.edu/athletics/intramurals/       valid
Crawling page: https://www.skidmore.edu/directions/off-campus.php       valid
Crawling page: https://www.skidmore.edu/campuslife/       valid
Crawling page: https://www.skidmore.edu/sga/index.php       valid
Crawling page: https://www.skidmore.edu/studentlife/clubs.php       valid
Crawling page: https://www.skidmore.edu/diningservice/       valid
Crawling page: https://www.skidmore.edu/admissions/saratoga/index.php       valid
Crawling page: https://www.skidmore.edu/reslife/       valid
Crawling page: https://www.skidmore.edu/studentlife/       valid
Crawling page: https://www.skidmore.edu/admissions/openhouse/       valid
Crawling page: https://www.skidmore.edu/admissions/visit/schedule.php       valid
Crawling page: https://www.skidmore.edu/admissions/visit/groups.php       valid
Crawling page: https://www.skidmore.edu/financialaid/       valid
Crawling page: https://www.skidmore.edu/admissions/transfer/       valid
Crawling page: https://www.skidmore.edu/admissions/international/       valid
Crawling page: https://www.skidmore.edu/admissions/apply/index.php       valid
Crawling page: https://www.skidmore.edu/admissions/apply/early.php       valid
Crawling page: https://www.skidmore.edu/registrar/datesdeadlines.php       valid
Crawling page: https://www.skidmore.edu/registrar/       valid
Crawling page: https://www.skidmore.edu/admissions/       valid
Crawling page: https://www.skidmore.edu/dof-vpaa/summer-research/       valid
Crawling page: https://www.skidmore.edu/career/cic/index.php       valid
Crawling page: https://www.skidmore.edu/presidentssociety//       Crawling page: https://www.skidmore.edu/career/       valid
Crawling page: https://www.skidmore.edu/ocse/       valid
Crawling page: https://www.skidmore.edu/mdocs/       valid
Crawling page: https://www.skidmore.edu/hf/       valid
Crawling page: https://www.skidmore.edu/fye/       valid
Crawling page: https://www.skidmore.edu/ocse/london_fye/index.php       valid
Crawling page: https://www.skidmore.edu/precollege/       valid
Crawling page: https://www.skidmore.edu/summersession/       valid
Crawling page: https://www.skidmore.edu/news/       valid
Crawling page: https://www.skidmore.edu/academics/majors.php       valid
Crawling page: https://www.skidmore.edu/academics/       valid
Crawling page: https://www.skidmore.edu/opportunity_program/index.php       valid
Crawling page: https://www.skidmore.edu/sgbm/       valid
Crawling page: https://www.skidmore.edu/sustainability/index.php       valid
Crawling page: https://www.skidmore.edu/directions/maps.php       valid
Crawling page: https://www.skidmore.edu/diversity/index.php       valid
Crawling page: http://calendar.skidmore.edu/mastercalendar/MasterCalendar.aspx       Crawling page: https://www.skidmore.edu/president/       valid
Crawling page: https://www.skidmore.edu/summer/       valid
Crawling page: https://www.skidmore.edu/admissions/facts/index.php       valid
Crawling page: https://www.skidmore.edu/about/rankings/       valid
Crawling page: https://dharmacon.horizondiscovery.com/transfection/dharmafect-kb-dna-transfection-reagent/       valid
Crawling page: https://dharmacon.horizondiscovery.com/viral-packaging/trans-lentiviral-orf-packaging-system/       valid
Crawling page: https://dharmacon.horizondiscovery.com/viral-packaging/trans-lentiviral-shrna-packaging-system/       valid
Crawling page: https://www.skidmore.edu/admissions/why/index.php       valid
Crawling page: https://www.skidmore.edu/ctm/       valid
Crawling page: https://dharmacon.horizondiscovery.com/transfection/dharmafect-duo-transfection-reagent/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/videos/edit-r/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/?internalcid=homepage-carousel-edit-r-crispr-cas9-gene-editing       valid
Crawling page: https://www.skidmore.edu/lifeatskidmore/index.php       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/hdr-donor-templates/?internalcid=homepage-carousel-hdr-plasmid-donor-kit       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/videos/how-to-use-cherry-pick-library-plater/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/crispr-guide-rna/synthetic-sgrna/?internalcid=homepage-carousel-synthetic-sgrna       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/featured-articles/guaranteed-silencing-accell-sirna/?internalcid=homepage-carousel-guaranteed-silencing-accell-sirna       valid
Crawling page: https://dharmacon.horizondiscovery.com/crispr-activation/?internalcid=homepage-carousel-crispr-activation       valid
Crawling page: https://www.skidmore.edu/about/       valid
Crawling page: https://dharmacon.horizondiscovery.com/social-hub/       valid
Crawling page: https://dharmacon.horizondiscovery.com/events/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/crispr-guide-rna/synthetic-crrna/edit-r-crrna-library/?internalcid=homepage-carousel-edit-r-crrna-library       valid
Crawling page: https://www.skidmore.edu/admissions/apply/       valid
Crawling page: https://www.skidmore.edu/lifeatskidmore/2018/1102-skidmore-dining-hall-love.php       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/faqs/       valid
Crawling page: https://dharmacon.horizondiscovery.com/about-us/       valid
Crawling page: https://dharmacon.horizondiscovery.com/service-and-support/       valid
Crawling page: https://www.skidmore.edu/about/contacts.php       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/webinars/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/videos/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/tools-and-calculators/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/technical-notes/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/recommended-reading/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/safety-data-sheets/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/product-inserts/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/protocols/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/product-and-technical-manuals/       valid
Crawling page: https://www.skidmore.edu/search/       valid
Crawling page: https://www.skidmore.edu/students/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/certificate-of-analysis/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/featured-articles/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/posters-and-presentations/       valid
Crawling page: https://www.skidmore.edu/facstaff/2018-11-11 02:02:27 [scrapy.extensions.logstats] INFO: Crawled 895 pages (at 3 pages/min), scraped 804 items (at 9 items/min)
2018-11-11 02:03:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/cei-world/cei-worldwide> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:03:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/catalogues/partners-catalogues> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:03:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/cei-world/cei-uk> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:03:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/catalogues> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:03:27 [scrapy.extensions.logstats] INFO: Crawled 909 pages (at 14 pages/min), scraped 810 items (at 6 items/min)
2018-11-11 02:03:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/bespoke-design/bespoke-cable-assemblies> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:03:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/cei-world> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:03:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/bespoke-design/bespoke-integrated-solutions> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:03:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/bespoke-design> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:03:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Tooling/Coaxial-Tooling> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:04:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Tooling/DIN41612%20Tooling> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:04:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/bespoke-design/bespoke-connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:04:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Card-Edge/2.54mmcardedge> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:04:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Card-Edge/3.18mmcardedge> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:04:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Card-Edge/3.96mmcardedge> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:04:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Tooling> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:04:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Tooling/D-Type-Tooling> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:04:40 [scrapy.extensions.logstats] INFO: Crawled 920 pages (at 11 pages/min), scraped 810 items (at 0 items/min)
2018-11-11 02:04:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Card-Edge/1.27mmcardedge> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:04:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Card-Edge/2.00mmcardedge> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:05:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Card-Edge> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:05:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Card-Edge/1.00mmcardedge> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:05:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/d-type/D-type-Accessories> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:05:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/d-type/D-type-high-density> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:05:22 [scrapy.extensions.logstats] INFO: Crawled 920 pages (at 0 pages/min), scraped 810 items (at 0 items/min)
2018-11-11 02:05:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/d-type/D-type-mixed-layout> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:05:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/d-type/D-type-standard-filtered> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:05:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/d-type/waterproofD> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:06:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/DIN-41612-connectors/DIN41612-Accessories> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:06:26 [scrapy.extensions.logstats] INFO: Crawled 942 pages (at 22 pages/min), scraped 817 items (at 7 items/min)
2018-11-11 02:06:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/DIN-41612-connectors/R-DIN41612> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:06:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/Card-Edge/1.98mmcardedge/JCK10DKBS> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:06:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/DIN-41612-connectors/M-DIN41612> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:07:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/DIN-41612-connectors/C-DIN41612> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:07:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/d-type/D-type-piggy-back/DPiggyback> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:07:31 [scrapy.extensions.logstats] INFO: Crawled 945 pages (at 3 pages/min), scraped 823 items (at 6 items/min)
2018-11-11 02:08:28 [scrapy.extensions.logstats] INFO: Crawled 956 pages (at 11 pages/min), scraped 833 items (at 10 items/min)
2018-11-11 02:09:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/products/DIN-41612-connectors/Q-DIN41612/QBodyDIN41612>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 02:09:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/products/DIN-41612-connectors/I-DIN41612/IBodyDIN41612>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 02:09:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/products/DIN-41612-connectors/D-DIN41612/DBodyDIN41612>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 02:09:42 [scrapy.extensions.logstats] INFO: Crawled 966 pages (at 10 pages/min), scraped 845 items (at 12 items/min)
       valid
Crawling page: https://www.skidmore.edu/parents/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/application-notes/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/       valid
Crawling page: https://dharmacon.horizondiscovery.com/brands/smartvector/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/controls/sirna/reporter-sistable-other/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/controls/sirna/siglo/       valid
Crawling page: https://dharmacon.horizondiscovery.com/brands/smartchoice/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/sirna/on-targetplus/       valid
Crawling page: https://dharmacon.horizondiscovery.com/about-us/about-open-biosystems/       valid
Crawling page: https://dharmacon.horizondiscovery.com/brands/shmimic/       valid
Crawling page: https://www.cambridgeelectronics.com/cei-world/cei-worldwide       Crawling page: https://www.cambridgeelectronics.com/catalogues/partners-catalogues       Crawling page: https://www.cambridgeelectronics.com/cei-world/cei-uk       Crawling page: https://www.cambridgeelectronics.com/catalogues       Crawling page: https://www.cambridgeelectronics.com/bespoke-design/bespoke-cable-assemblies       Crawling page: https://www.cambridgeelectronics.com/cei-world       Crawling page: https://www.cambridgeelectronics.com/bespoke-design/bespoke-integrated-solutions       Crawling page: https://www.cambridgeelectronics.com/bespoke-design       Crawling page: https://www.cambridgeelectronics.com/products/Tooling/Coaxial-Tooling       Crawling page: https://www.cambridgeelectronics.com/products/Tooling/DIN41612%20Tooling       Crawling page: https://www.cambridgeelectronics.com/bespoke-design/bespoke-connectors       Crawling page: https://www.cambridgeelectronics.com/products/Card-Edge/2.54mmcardedge       Crawling page: https://www.cambridgeelectronics.com/products/Card-Edge/3.18mmcardedge       Crawling page: https://www.cambridgeelectronics.com/products/Card-Edge/3.96mmcardedge       Crawling page: https://www.cambridgeelectronics.com/products/Tooling       Crawling page: https://www.cambridgeelectronics.com/products/Tooling/D-Type-Tooling       Crawling page: https://www.cambridgeelectronics.com/products/Card-Edge/1.27mmcardedge       Crawling page: https://www.cambridgeelectronics.com/products/Card-Edge/2.00mmcardedge       Crawling page: https://www.cambridgeelectronics.com/products/Card-Edge       Crawling page: https://www.cambridgeelectronics.com/products/Card-Edge/1.00mmcardedge       Crawling page: https://www.cambridgeelectronics.com/products/d-type/D-type-Accessories       Crawling page: https://www.cambridgeelectronics.com/products/d-type/D-type-high-density       Crawling page: http://www.mirtechusa.com/2018/10/12/hot-list/       valid
Crawling page: http://www.mirtechusa.com/our-company/news/       valid
Crawling page: http://www.mirtechusa.com/2018/08/10/boyle-ms-combine-clinic-and-open-house/       valid
Crawling page: https://www.cambridgeelectronics.com/products/d-type/D-type-mixed-layout       Crawling page: https://www.cambridgeelectronics.com/products/d-type/D-type-standard-filtered       Crawling page: https://www.cambridgeelectronics.com/products/d-type/waterproofD       Crawling page: http://www.mirtechusa.com/%D1%81atalog/track-loaders/       valid
Crawling page: https://www.cambridgeelectronics.com/products/DIN-41612-connectors/DIN41612-Accessories       Crawling page: https://dharmacon.horizondiscovery.com/brands/gene-editing/edit-r/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/sirna/lincode/       valid
Crawling page: https://dharmacon.horizondiscovery.com/brands/dharmafect/       valid
Crawling page: https://www.cambridgeelectronics.com/products/DIN-41612-connectors/R-DIN41612       Crawling page: https://www.cambridgeelectronics.com/products/Card-Edge/1.98mmcardedge/JCK10DKBS       Crawling page: https://www.cambridgeelectronics.com/products/DIN-41612-connectors/M-DIN41612       Crawling page: https://dharmacon.horizondiscovery.com/rnai/screening-libraries/shrna/pooled-lentiviral-screening-libraries/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/sirna/accell/       valid
Crawling page: https://dharmacon.horizondiscovery.com/brands/       valid
Crawling page: https://www.cambridgeelectronics.com/products/DIN-41612-connectors/C-DIN41612       Crawling page: https://www.cambridgeelectronics.com/products/d-type/D-type-piggy-back/DPiggyback       Crawling page: https://dharmacon.horizondiscovery.com/applications/functional-genomic-screening-libraries/seed-sibling-sirna-controls/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/rna-interference/sirna/c911-controls/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/functional-genomic-screening-libraries/crispr-cas9-reverse-transfection-arrayed-crrna-screening-libraries/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/functional-genomic-screening-libraries/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-expression/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/custom-rna-synthesis/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/rna-interference/microrna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/rna-interference/regulatory-noncoding-rna-microrna-lncrna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/rna-interference/shrna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/rna-interference/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/crispr-screening-validation-engineered-cell-lines/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/hdr-single-strand-dna-donor-oligos/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/homology-directed-repair-plasmid-donor/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/multiplex-crispr-cas9-knockout/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/crispr-cas9-genome-editing-synthetic-99mer-sgrna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/crispr-cas9-guide-rna-specificity/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/crispr-cas9-guide-rna-functionality-algorithm/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/inducible-lentiviral-cas9-nuclease/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/engineering-a-knockout-cell-line/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/gene-editing/       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/custom-modulation-tools/       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/midscale-oem-rna-dna-synthesis/       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/custom-synthesis/rna/multiple-single-strand-rna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/custom-synthesis/rna/single-strand-rna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/custom-synthesis/dna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/customsmartpool/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/screening-libraries/zoonome-custom-sirna-libraries/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/screening-libraries/shrna/custom-pooled-lentiviral-screening-libraries/       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/custom-synthesis/sirna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/custom-sirna/2018-11-11 02:10:57 [scrapy.extensions.logstats] INFO: Crawled 980 pages (at 14 pages/min), scraped 857 items (at 12 items/min)
2018-11-11 02:11:46 [scrapy.extensions.logstats] INFO: Crawled 988 pages (at 8 pages/min), scraped 865 items (at 8 items/min)
2018-11-11 02:12:32 [scrapy.extensions.logstats] INFO: Crawled 996 pages (at 8 pages/min), scraped 873 items (at 8 items/min)
2018-11-11 02:13:30 [scrapy.extensions.logstats] INFO: Crawled 1008 pages (at 12 pages/min), scraped 881 items (at 8 items/min)
2018-11-11 02:14:33 [scrapy.extensions.logstats] INFO: Crawled 1016 pages (at 8 pages/min), scraped 889 items (at 8 items/min)
2018-11-11 02:15:23 [scrapy.extensions.logstats] INFO: Crawled 1020 pages (at 4 pages/min), scraped 897 items (at 8 items/min)
2018-11-11 02:16:40 [scrapy.extensions.logstats] INFO: Crawled 1034 pages (at 14 pages/min), scraped 907 items (at 10 items/min)
2018-11-11 02:17:27 [scrapy.extensions.logstats] INFO: Crawled 1038 pages (at 4 pages/min), scraped 915 items (at 8 items/min)
2018-11-11 02:18:35 [scrapy.extensions.logstats] INFO: Crawled 1046 pages (at 8 pages/min), scraped 927 items (at 12 items/min)
2018-11-11 02:18:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/3GHz%20Patch%20Cables> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:18:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/6Ghz%20Patch%20Cables> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:19:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/CoaxPress/CoaXPress%20Cables> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:19:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/datacom-cables/Datacom%20Cables> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:19:25 [scrapy.extensions.logstats] INFO: Crawled 1062 pages (at 16 pages/min), scraped 932 items (at 5 items/min)
2018-11-11 02:19:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/DIN-41612-cable-assemblies/DIN%2041612%20Cable%20Assemblies> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:19:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/panels/Panel> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:19:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/mains-power-cables/Mains%20Power%20Cables> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:19:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/12GHzpatch-cables> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:19:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/mdr-cables/MDRCables> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/coaxial-rf-assemblies/Coaxial%20RF%20Assemblies> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/fibre-cable-assemblies/Fibre%20Cable%20Assemblies> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/cables/cable-looms/Cable%20Looms> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/N-Series-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/RF-Accessories> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:24 [scrapy.extensions.logstats] INFO: Crawled 1065 pages (at 3 pages/min), scraped 932 items (at 0 items/min)
2018-11-11 02:20:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/SMB-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/1.6-5.6-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/SMA-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/RF-Connector-Adaptors-Inter-Series> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:20:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/MCX-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:21:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/Stacking-System-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
       valid
Crawling page: https://global.epson.com/teams_conditions.html       valid
Crawling page: https://global.epson.com/web_sites.html       valid
Crawling page: https://global.epson.com/sitemap.html       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/custom-synthesis/dna/multiple-single-strand-dna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/custom-synthesis/dna/single-strand-dna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/libraryimport/       valid
Crawling page: https://global.epson.com/privacy_policy.html       valid
Crawling page: https://global.epson.com/products_and_drivers/semicon/       valid
Crawling page: https://global.epson.com/products_and_drivers/sensing_system/       valid
Crawling page: https://global.epson.com/products_and_drivers/wearable.html       valid
Crawling page: https://global.epson.com/products_and_drivers/visual.html       valid
Crawling page: https://global.epson.com/products_and_drivers/printing.html       valid
Crawling page: https://global.epson.com/innovation/paperlab/       valid
Crawling page: https://global.epson.com/innovation/manufacturing/       valid
Crawling page: https://global.epson.com/innovation/core_technology/       valid
Crawling page: https://global.epson.com/innovation/research_development/       valid
Crawling page: https://global.epson.com/innovation/microdevice/       valid
Crawling page: https://global.epson.com/innovation/intellectual_property/       valid
Crawling page: https://global.epson.com/innovation/vision/       valid
Crawling page: https://global.epson.com/SR/communication/       valid
Crawling page: https://www.k-space.com/k-space-associates-inc-grows-in-line-sales-revenue-through-q3-by-26-percent/       valid
Crawling page: https://www.k-space.com/atomic-absorption-spectroscopy-tool-development-continues-with-the-addition-of-soma-perooly/       valid
Crawling page: https://www.k-space.com/new-in-line-metrology-solution-for-the-building-products-industry/       valid
Crawling page: https://www.k-space.com/company/shows/       valid
Crawling page: https://www.k-space.com/company/news/       valid
Crawling page: https://www.k-space.com/company/contact/       valid
Crawling page: https://www.k-space.com/company/customers/       valid
Crawling page: https://www.k-space.com/company/careers/       valid
Crawling page: https://www.k-space.com/company/newsletter-archive/       valid
Crawling page: https://www.k-space.com/company/distributors/       valid
Crawling page: https://www.k-space.com/measure/surface-roughness-and-quality/       valid
Crawling page: https://www.k-space.com/measure/wafer-curvature-bow-and-tilt/       valid
Crawling page: https://www.k-space.com/company/       valid
Crawling page: https://www.k-space.com/company/company-videos/       valid
Crawling page: https://www.k-space.com/videos/       valid
Crawling page: https://www.k-space.com/article-references/       valid
Crawling page: https://www.k-space.com/support/material-properties/       valid
Crawling page: https://www.k-space.com/support/       valid
Crawling page: https://www.k-space.com/measure/wafer-and-film-temperature/       valid
Crawling page: https://www.k-space.com/measure/thin-film-stress-and-strain/       valid
Crawling page: https://www.k-space.com/applications/pld/       valid
Crawling page: https://www.k-space.com/applications/pvd/       valid
Crawling page: https://www.k-space.com/applications/thermal-and-e-beam-evaporation/       valid
Crawling page: https://www.k-space.com/applications/sputtering/       valid
Crawling page: https://www.k-space.com/applications/mocvd/       valid
Crawling page: https://www.k-space.com/applications/mbe/       valid
Crawling page: https://www.k-space.com/products/accessories/       valid
Crawling page: https://www.k-space.com/products/ksa-emissometer/       valid
Crawling page: https://www.k-space.com/applications/       valid
Crawling page: https://www.k-space.com/applications/thin-film-characterization-services/       valid
Crawling page: http://ir.atomera.com/news-releases/news-release-details/atomera-licenses-mst-stmicroelectronics       valid
Crawling page: http://atomera.com/internet-of-things/       valid
Crawling page: https://www.k-space.com/products/ksa-raterat-pro/       valid
Crawling page: https://www.k-space.com/products/ksa-spectratemp/       valid
Crawling page: https://www.k-space.com/products/ksa-scanning-pyro/       valid
Crawling page: https://www.k-space.com/products/ksa-ice/       valid
Crawling page: http://ir.atomera.com/       valid
Crawling page: http://atomera.com/infrastructure/       valid
Crawling page: http://atomera.com/mobile/       valid
Crawling page: http://atomera.com/contact/       valid
Crawling page: https://www.k-space.com/products/mos-scan/       valid
Crawling page: https://www.k-space.com/products/mos/       valid
Crawling page: https://www.k-space.com/products/bandit-pv/       valid
Crawling page: https://www.k-space.com/products/bandit/       valid
Crawling page: http://blog.atomera.com       valid
Crawling page: http://atomera.com/publications/       valid
Crawling page: https://www.k-space.com/products/400-rheed/       valid
Crawling page: https://www.k-space.com/products/       valid
Crawling page: http://atomera.com/overview/       valid
Crawling page: http://atomera.com/management/       valid
Crawling page: http://atomera.com/sram-3/       valid
Crawling page: http://atomera.com/logic-and-processors/       valid
Crawling page: http://atomera.com/analog-3/       valid
Crawling page: http://atomera.com/finfet-technology/       valid
Crawling page: http://atomera.com/dram/       valid
Crawling page: http://atomera.com/applications/       valid
Crawling page: http://atomera.com/pub-and-pat/       valid
Crawling page: https://www.cambridgeelectronics.com/products/cables/3GHz%20Patch%20Cables       Crawling page: https://www.cambridgeelectronics.com/products/cables/6Ghz%20Patch%20Cables       Crawling page: http://atomera.com/mst/       valid
Crawling page: http://atomera.com/implementation/       valid
Crawling page: http://atomera.com/benefits/       valid
Crawling page: http://atomera.com/technology/       valid
Crawling page: https://www.cambridgeelectronics.com/products/cables/CoaxPress/CoaXPress%20Cables       Crawling page: https://www.cambridgeelectronics.com/products/cables/datacom-cables/Datacom%20Cables       Crawling page: https://www.cambridgeelectronics.com/products/cables/DIN-41612-cable-assemblies/DIN%2041612%20Cable%20Assemblies       Crawling page: https://www.cambridgeelectronics.com/products/cables/panels/Panel       Crawling page: https://www.cambridgeelectronics.com/products/cables/mains-power-cables/Mains%20Power%20Cables       Crawling page: https://www.cambridgeelectronics.com/products/cables/12GHzpatch-cables       Crawling page: https://www.cambridgeelectronics.com/products/cables/mdr-cables/MDRCables       Crawling page: https://www.cambridgeelectronics.com/products/cables/coaxial-rf-assemblies/Coaxial%20RF%20Assemblies       Crawling page: https://www.cambridgeelectronics.com/products/cables/fibre-cable-assemblies/Fibre%20Cable%20Assemblies       Crawling page: https://www.cambridgeelectronics.com/products/cables/cable-looms/Cable%20Looms       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/N-Series-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/RF-Accessories       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/SMB-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/1.6-5.6-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/SMA-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/RF-Connector-Adaptors-Inter-Series       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/MCX-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/Stacking-System-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/Changeable-Interface-RF-Connectors2018-11-11 02:21:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/Changeable-Interface-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:21:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/Two-Part-System> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:21:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/1.0-2.3-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:21:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/Mini-BNC-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:21:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/Micro-BNC-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:21:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/BNC-RF-Connectors> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:21:43 [scrapy.extensions.logstats] INFO: Crawled 1077 pages (at 12 pages/min), scraped 932 items (at 0 items/min)
2018-11-11 02:21:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/news/job-vacancies> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:21:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:22:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/news/press-releases> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:22:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/news/press-releases/April2018pressrelease> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:22:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/news/new-products> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:22:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/rf-connectors/F-Connector/C-SX-163> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:22:27 [scrapy.extensions.logstats] INFO: Crawled 1097 pages (at 20 pages/min), scraped 934 items (at 2 items/min)
2018-11-11 02:22:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/About-Us/Quality/IPC%20WMHA-A-620> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:22:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/About-Us/Quality/ISOCertification> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:22:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/news> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:22:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/About-Us/Quality/EnvironmentalPolicies> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:23:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/About-Us/Quality> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:23:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/About-Us/Supply-Partners> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:23:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/About-Us/Markets-Served> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:23:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/About-Us/Company-History> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:23:59 [scrapy.extensions.logstats] INFO: Crawled 1099 pages (at 2 pages/min), scraped 938 items (at 4 items/min)
2018-11-11 02:24:24 [scrapy.extensions.logstats] INFO: Crawled 1105 pages (at 6 pages/min), scraped 942 items (at 4 items/min)
2018-11-11 02:24:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/About-Us/Company-Profile> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:25:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/About-Us> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:25:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.mirtechusa.com/2018/02/07/spring-tillage-sale/>: HTTP status code is not handled or not allowed
2018-11-11 02:25:37 [scrapy.extensions.logstats] INFO: Crawled 1119 pages (at 14 pages/min), scraped 953 items (at 11 items/min)
2018-11-11 02:26:22 [scrapy.extensions.logstats] INFO: Crawled 1136 pages (at 17 pages/min), scraped 962 items (at 9 items/min)
2018-11-11 02:27:28 [scrapy.extensions.logstats] INFO: Crawled 1140 pages (at 4 pages/min), scraped 974 items (at 12 items/min)
2018-11-11 02:28:25 [scrapy.extensions.logstats] INFO: Crawled 1152 pages (at 12 pages/min), scraped 983 items (at 9 items/min)
2018-11-11 02:29:34 [scrapy.extensions.logstats] INFO: Crawled 1160 pages (at 8 pages/min), scraped 994 items (at 11 items/min)
2018-11-11 02:30:42 [scrapy.extensions.logstats] INFO: Crawled 1171 pages (at 11 pages/min), scraped 1005 items (at 11 items/min)
       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/Two-Part-System       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/1.0-2.3-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/Mini-BNC-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/Micro-BNC-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/BNC-RF-Connectors       Crawling page: https://www.cambridgeelectronics.com/news/job-vacancies       Crawling page: https://www.cambridgeelectronics.com/products       Crawling page: https://www.cambridgeelectronics.com/news/press-releases       Crawling page: https://www.cambridgeelectronics.com/news/press-releases/April2018pressrelease       Crawling page: https://www.cambridgeelectronics.com/news/new-products       Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors/F-Connector/C-SX-163       Crawling page: http://www.mirtechusa.com/%D1%81atalog/planters/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/forage-harvesters/       valid
Crawling page: https://www.cambridgeelectronics.com/About-Us/Quality/IPC%20WMHA-A-620       Crawling page: https://www.cambridgeelectronics.com/About-Us/Quality/ISOCertification       Crawling page: https://www.cambridgeelectronics.com/news       Crawling page: https://www.cambridgeelectronics.com/About-Us/Quality/EnvironmentalPolicies       Crawling page: http://www.mirtechusa.com/%D1%81atalog/grain-drill-1/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/spreaders/       valid
Crawling page: https://www.cambridgeelectronics.com/About-Us/Quality       Crawling page: https://www.cambridgeelectronics.com/About-Us/Supply-Partners       Crawling page: https://www.cambridgeelectronics.com/About-Us/Markets-Served       Crawling page: https://www.cambridgeelectronics.com/About-Us/Company-History       Crawling page: http://www.mirtechusa.com/%D1%81atalog/hipperbedders/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/articulated-loader/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/tillage/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/tractors/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/precision-farming/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/grain-carts/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/rotary-cutters/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/compact-excavators/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/rear-blades/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/hay-tools/       valid
Crawling page: https://www.cambridgeelectronics.com/About-Us/Company-Profile       Crawling page: https://www.cambridgeelectronics.com/About-Us       Crawling page: http://www.mirtechusa.com/%D1%81atalog/round-balers/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/seed-tenders/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/square-balers/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/combines/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/telehandlers/       valid
Crawling page: http://www.mirtechusa.com/catalog/round-balers/variant-480-465-460/       valid
Crawling page: http://www.mirtechusa.com/%D1%81atalog/sprayers/       valid
Crawling page: http://www.mirtechusa.com/2018/08/03/new-boyle-ms-location-announcement/       valid
Crawling page: http://www.mirtechusa.com/request/       valid
Crawling page: http://www.mirtechusa.com/contacts-2/       valid
Crawling page: http://www.mirtechusa.com/our-company/careers/       valid
Crawling page: http://www.kureha.co.jp/en/terms/index.html       valid
Crawling page: http://www.mirtechusa.com/our-company/       valid
Crawling page: http://www.mirtechusa.com/category/news/       valid
Crawling page: http://www.mirtechusa.com/category/events/       valid
Crawling page: http://www.mirtechusa.com/category/special-offers/       valid
Crawling page: http://www.kureha.co.jp/en/privacy/index.html       valid
Crawling page: http://www.mirtechusa.com/used-equipment/sprayers/       valid
Crawling page: http://www.mirtechusa.com/used-equipment/seeding/       valid
Crawling page: http://www.mirtechusa.com/used-equipment/attachments/       valid
Crawling page: http://www.mirtechusa.com/used-equipment/spreaders/       valid
Crawling page: http://www.kureha.co.jp/en/information_disclosure/index.html       valid
Crawling page: http://www.kureha.co.jp/en/business/other/index.html       valid
Crawling page: http://www.kureha.co.jp/en/information_security/index.html       valid
Crawling page: http://www.mirtechusa.com/used-equipment/tillage/       valid
Crawling page: http://www.mirtechusa.com/used-equipment/tractors/       valid
Crawling page: http://www.mirtechusa.com/used-equipment/headers/       valid
Crawling page: http://www.mirtechusa.com/used-equipment/combines/       valid
Crawling page: http://www.kureha.co.jp/en/business/polymer/index.html       valid
Crawling page: http://www.kureha.co.jp/en/business/chemical/index.html       valid
Crawling page: http://www.kureha.co.jp/en/newsrelease/       valid
Crawling page: http://www.kureha.co.jp/en/business/material/index.html       valid
Crawling page: http://www.kureha.co.jp/en/about/group.html       valid
Crawling page: http://www.mirtechusa.com/service-spare-parts/       valid
Crawling page: http://www.mirtechusa.com/used-equipment/       valid
Crawling page: http://www.mirtechusa.com/catalog/       valid
Crawling page: https://dharmacon.horizondiscovery.com/cdnas-and-orfs/       valid
Crawling page: https://dharmacon.horizondiscovery.com/cdnas-and-orfs/mammalian-cdnas/       valid
Crawling page: https://dharmacon.horizondiscovery.com/cdnas-and-orfs/mammalian-orfs/       valid
Crawling page: https://dharmacon.horizondiscovery.com/cdnas-and-orfs/non-mammalian-cdnas-and-orfs/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/ancillary-reagents/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/screening-libraries/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/microrna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/controls/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/shrna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/sirna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/       valid
Crawling page: https://dharmacon.horizondiscovery.com/crispr-activation/screening-libraries/edit-r-crispra-crrna-libraries/       valid
Crawling page: https://dharmacon.horizondiscovery.com/crispr-activation/crispra-controls/       valid
Crawling page: https://dharmacon.horizondiscovery.com/crispr-activation/dcas9-vpr/       valid
Crawling page: https://dharmacon.horizondiscovery.com/crispr-activation/crispra-guide-rna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/crispr-activation/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/edit-r-hdr-donor-designer/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/crispr-design-tool/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/hdr-donor-templates/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/crispr-screening-libraries/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/crispr-controls-and-detection-primers/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/cas9-nuclease/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/crispr-guide-rna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/       valid
Crawling page: https://dharmacon.horizondiscovery.com/selectcountry/?returnurl=%2f       valid2018-11-11 02:31:25 [scrapy.extensions.logstats] INFO: Crawled 1175 pages (at 4 pages/min), scraped 1012 items (at 7 items/min)
2018-11-11 02:32:38 [scrapy.extensions.logstats] INFO: Crawled 1194 pages (at 19 pages/min), scraped 1024 items (at 12 items/min)
2018-11-11 02:33:27 [scrapy.extensions.logstats] INFO: Crawled 1198 pages (at 4 pages/min), scraped 1032 items (at 8 items/min)
/bin/sh: 1: kill: No such process

/bin/sh: 1: kill: No such process

/bin/sh: 1: kill: No such process

2018-11-11 02:34:58 [scrapy.extensions.logstats] INFO: Crawled 1212 pages (at 14 pages/min), scraped 1047 items (at 15 items/min)
2018-11-11 02:35:30 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 10 pages/min), scraped 1052 items (at 5 items/min)
/bin/sh: 1: kill: No such process

/bin/sh: 1: kill: No such process

2018-11-11 02:36:24 [scrapy.extensions.logstats] INFO: Crawled 1226 pages (at 4 pages/min), scraped 1060 items (at 8 items/min)
2018-11-11 02:37:26 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 13 pages/min), scraped 1069 items (at 9 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 02:38:26 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 1 pages/min), scraped 1077 items (at 8 items/min)
2018-11-11 02:39:03 [root] ERROR: Unable to find match for url: https://www.kureha.jp/en/contact/index.html
2018-11-11 02:39:27 [scrapy.extensions.logstats] INFO: Crawled 1260 pages (at 20 pages/min), scraped 1088 items (at 11 items/min)
2018-11-11 02:40:22 [scrapy.extensions.logstats] INFO: Crawled 1272 pages (at 12 pages/min), scraped 1102 items (at 14 items/min)
2018-11-11 02:40:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sec.gov/cgi-bin/browse-edgar?company=Northwest+Biotherapeutics&owner=exclude&action=getcompany>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]

Crawling page: https://dharmacon.horizondiscovery.com/products/       valid
Crawling page: https://dharmacon.horizondiscovery.com/quickCart/       valid
Crawling page: https://dharmacon.horizondiscovery.com/signin/?returnurl=%2f       valid
Crawling page: https://dharmacon.horizondiscovery.com/cart/       valid
Crawling page: https://dharmacon.horizondiscovery.com/register-new/       valid
Crawling page: https://dharmacon.horizondiscovery.com/gene-editing/crispr-cas9/ready-made-cell-lines/       valid
Crawling page: https://global.epson.com/SR/environment/       valid
Crawling page: https://global.epson.com/SR/customer_commitment/       valid
Crawling page: https://global.epson.com/SR/report/       valid
Crawling page: https://global.epson.com/SR/csr_initiative/       valid
Crawling page: https://global.epson.com/newsroom/photos_index.html       valid
Crawling page: https://global.epson.com/SR/message/       valid
Crawling page: https://global.epson.com/newsroom/2013/       valid
Crawling page: https://global.epson.com/newsroom/2014/       valid
Crawling page: https://global.epson.com/newsroom/2015/       valid
Crawling page: https://global.epson.com/newsroom/2016/       valid
Crawling page: https://global.epson.com/newsroom/2017/       valid
Crawling page: https://global.epson.com/newsroom/2018/       valid
Crawling page: https://global.epson.com/IR/faq/       valid
Crawling page: https://global.epson.com/IR/information/       valid
Crawling page: https://global.epson.com/IR/library/       valid
Crawling page: https://global.epson.com/IR/financial_results/       valid
Crawling page: https://global.epson.com/IR/calendar/       valid
Crawling page: https://global.epson.com/IR/news/       valid
Crawling page: https://global.epson.com/company/corporate_history/       valid
Crawling page: https://global.epson.com/company/corporate_vision/       valid
Crawling page: https://global.epson.com/company/global_network/       valid
Crawling page: https://global.epson.com/company/leadership_team/       valid
Crawling page: https://global.epson.com/company/glance/       valid
Crawling page: https://global.epson.com/company/sports/       valid
Crawling page: https://global.epson.com/company/epson_way/       valid
Crawling page: https://global.epson.com/company/message/       valid
Crawling page: https://global.epson.com/company/sports/formula_one/       valid
Crawling page: https://www.k-space.com/       valid
Crawling page: http://www.mirtechusa.com/       valid
Crawling page: http://atomera.com/       valid
Crawling page: https://global.epson.com/company/epson_way/exceed_your_vision/       valid
Crawling page: https://global.epson.com/products_and_drivers/       valid
Crawling page: https://global.epson.com/innovation/       valid
Crawling page: https://global.epson.com/SR/       valid
Crawling page: https://global.epson.com/newsroom/       valid
Crawling page: https://global.epson.com/company/       valid
Crawling page: https://global.epson.com/IR/       valid
Crawling page: http://www.wikipad.com/gaming/       valid
Crawling page: http://www.wikipad.com/home-gallery/       valid
Crawling page: http://www.wikipad.com/buy-now/       valid
Crawling page: http://www.kureha.co.jp/en/development/prize.html       valid
Crawling page: http://www.kureha.co.jp/en/development/strategy.html       valid
Crawling page: http://www.kureha.co.jp/en/csr/index.html       valid
Crawling page: http://www.kureha.co.jp/en/about/challenge/philosophy.html       valid
Crawling page: http://www.wikipad.com       valid
Crawling page: https://global.epson.com/       valid
Crawling page: https://dharmacon.horizondiscovery.com/       valid
Crawling page: http://www.kureha.co.jp/en/about/index.html       valid
Crawling page: http://www.kureha.co.jp/en/development/index.html       valid
Crawling page: http://www.kureha.co.jp/en/business/index.html       valid
Crawling page: http://www.kureha.co.jp/en/ir/index.html       valid
Crawling page: http://www.kureha.co.jp/cn/       valid
Crawling page: https://www.nwbio.com/investors-media/       valid
Crawling page: https://www.nwbio.com/nwbio-announces-scientific-publication-interim-survival-data-phase-3-trial-dcvax-l-glioblastoma-brain-cancer/       valid
Crawling page: https://www.nwbio.com/nw-bio-announces-upcoming-presentation-dr-marnix-bosch-immuno-oncology-summit/       valid
Crawling page: https://www.nwbio.com/nw-bio-discuss-interim-phase-3-trial-data-industry-theater-session-asco/       valid
Crawling page: http://www.kureha.co.jp/en/sitemap/index.html       valid
Crawling page: http://www.kureha.co.jp/       valid
Crawling page: http://www.kureha.co.jp/en/       valid
Crawling page: https://www.nwbio.com/dcvax-personalized-dendritic-cell-vaccines/       valid
Crawling page: https://www.nwbio.com/contact-us/       valid
Crawling page: https://www.nwbio.com/asco-2018-webcast/       valid
Crawling page: https://www.nwbio.com/presentation-dr-marnix-boschs-presentation-clinical-development-dendritic-cell-based-immunotherapy-cancer-immuno-oncology-summit/       valid
Crawling page: http://www.kureha.co.jp/en/faq/index.html       valid
Crawling page: http://www.kureha.co.jp/en/index.html       valid
Crawling page: https://www.nwbio.com/notice-of-settlement/       valid
Crawling page: https://www.nwbio.com/about-us/       valid
Crawling page: https://www.nwbio.com/board-committee-charters/       valid
Crawling page: https://www.nwbio.com/webcasts/       valid
Crawling page: https://www.kureha.jp/en/contact/index.html       valid
Crawling page: http://akronpolysys.com/textpage.php?MenuID=5       valid
Crawling page: https://www.nwbio.com/dcvax-direct-phase-iii-for-all-types-of-inoperable-solid-tumor-cancers/       valid
Crawling page: https://www.nwbio.com/clinical-trials/       valid
Crawling page: https://www.nwbio.com/press-releases/       valid
Crawling page: https://www.nwbio.com/clinical-trials/dcvax-l-phase-iii-for-gbm-brain-cancer/       valid
Crawling page: http://akronpolysys.com/store/index.php?CategoryID=6&MenuID=20       valid
Crawling page: http://akronpolysys.com/store/index.php?CategoryID=7&MenuID=21       valid
Crawling page: https://www.nwbio.com/dcvax-prostate/       valid
Crawling page: https://www.nwbio.com/dcvax-direct/       valid
Crawling page: https://www.nwbio.com/dcvax-l/       valid
Crawling page: https://www.nwbio.com/product-candidates/       valid
Crawling page: http://akronpolysys.com/store/index.php?CategoryID=17&MenuID=33       valid
Crawling page: http://akronpolysys.com/store/index.php?CategoryID=15&MenuID=30       valid
Crawling page: http://akronpolysys.com/store/index.php?CategoryID=5&MenuID=19       valid
Crawling page: http://akronpolysys.com/contact_us.php?MenuID=6       valid
Crawling page: http://akronpolysys.com/services.php?CategoryID=1&MenuID=21       valid
Crawling page: http://akronpolysys.com/contact_us.php?MenuID=3       valid
Crawling page: http://akronpolysys.com/textpage_full.php?MenuID=13       valid
Crawling page: http://akronpolysys.com/store/index.php?CategoryID=16&MenuID=32       valid
Crawling page: http://akronpolysys.com/textpage_full.php?MenuID=11       valid
Crawling page: http://akronpolysys.com/textpage.php?MenuID=10       valid
Crawling page: http://akronpolysys.com/services.php?MenuID=9       valid
Crawling page: http://akronpolysys.com/textpage_full.php?MenuID=12       valid
Crawling page: http://akronpolysys.com/store/index_full.php?CategoryID=14&MenuID=29       valid
Crawling page: http://akronpolysys.com/store/index_full.php?CategoryID=13&MenuID=28       valid
Crawling page: http://akronpolysys.com/store/index_full.php?CategoryID=12&MenuID=27       valid
Crawling page: http://akronpolysys.com/store/index_full.php?CategoryID=11&MenuID=25       valid
Crawling page: http://www.akronpolysys.com/store/index.php?CategoryID=16&MenuID=32&MenuID=42       valid
Crawling page: http://www.akronpolysys.com/store/index.php?CategoryID=17&MenuID=33&MenuID=43       valid
Crawling page: http://www.akronpolysys.com/store/index.php?CategoryID=6&MenuID=20&MenuID=44       valid
Crawling page: http://www.akronpolysys.com/store/index.php?CategoryID=7&MenuID=21&MenuID=47       valid
Crawling page:2018-11-11 02:41:29 [scrapy.extensions.logstats] INFO: Crawled 1292 pages (at 20 pages/min), scraped 1118 items (at 16 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 02:42:35 [scrapy.extensions.logstats] INFO: Crawled 1300 pages (at 8 pages/min), scraped 1134 items (at 16 items/min)
2018-11-11 02:43:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <406 http://www.tela-inc.com>: HTTP status code is not handled or not allowed
2018-11-11 02:43:47 [scrapy.extensions.logstats] INFO: Crawled 1316 pages (at 16 pages/min), scraped 1151 items (at 17 items/min)
2018-11-11 02:44:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ampiopharma.com/pipeline/optina/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:44:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ampiopharma.com/pipeline/ampion/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:44:24 [scrapy.extensions.logstats] INFO: Crawled 1324 pages (at 8 pages/min), scraped 1157 items (at 6 items/min)
2018-11-11 02:45:49 [scrapy.extensions.logstats] INFO: Crawled 1339 pages (at 15 pages/min), scraped 1171 items (at 14 items/min)
2018-11-11 02:46:24 [scrapy.extensions.logstats] INFO: Crawled 1351 pages (at 12 pages/min), scraped 1178 items (at 7 items/min)
2018-11-11 02:47:22 [scrapy.extensions.logstats] INFO: Crawled 1361 pages (at 10 pages/min), scraped 1190 items (at 12 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 02:48:51 [scrapy.extensions.logstats] INFO: Crawled 1377 pages (at 16 pages/min), scraped 1209 items (at 19 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 02:49:32 [scrapy.extensions.logstats] INFO: Crawled 1385 pages (at 8 pages/min), scraped 1216 items (at 7 items/min)
 http://akronpolysys.com/textpage.php?MenuID=46       valid
Crawling page: http://akronpolysys.com/store/index_full.php?CategoryID=10&MenuID=24       valid
Crawling page: http://akronpolysys.com/store/index_full.php?CategoryID=8&MenuID=22       valid
Crawling page: http://akronpolysys.com/store/index_full.php?CategoryID=9&MenuID=23       valid
Crawling page: http://akronpolysys.com/textpage.php?MenuID=37       valid
Crawling page: http://akronpolysys.com/textpage.php?MenuID=40       valid
Crawling page: http://www.akronpolysys.com/store/index.php?CategoryID=15&MenuID=30&MenuID=41       valid
Crawling page: http://akronpolysys.com/       valid
Crawling page: http://www.tela-inc.com/tsmc-aiming-for-more-than-financial-returns-with-its-investment-in-us-start-up-tela-innovations/       valid
Crawling page: http://www.tela-inc.com/tela-resolves-patent-dispute-with-google-and-pantech/       valid
Crawling page: http://www.tela-inc.com/tela-adds-experienced-licensing-executive-to-management-team/       valid
Crawling page: http://www.tela-inc.com/samsung-to-license-patent-portfolio-from-tela-innovations/       valid
Crawling page: http://www.tela-inc.com/contact-us/       valid
Crawling page: http://www.tela-inc.com/category/events/       valid
Crawling page: http://www.tela-inc.com/category/press-coverage/       valid
Crawling page: http://www.tela-inc.com/category/press-releases/       valid
Crawling page: http://www.tela-inc.com/blog/       valid
Crawling page: http://www.tela-inc.com/government-programs/dod-silicon-validation/       valid
Crawling page: http://www.tela-inc.com/government-programs/lower-mask-costs/       valid
Crawling page: http://www.tela-inc.com/government-programs/domestic-manufacturing/       valid
Crawling page: http://www.tela-inc.com/technical-papers/       valid
Crawling page: http://www.tela-inc.com/products/power-optimization/tela-optimizer/       valid
Crawling page: http://www.tela-inc.com/government-programs/       valid
Crawling page: http://www.tela-inc.com/patents/       valid
Crawling page: http://hiqsolar.com/carport.html       valid
Crawling page: http://www.tela-inc.com/products/power-optimization/       valid
Crawling page: http://www.tela-inc.com/products/physical-ip/customization-services/       valid
Crawling page: http://www.tela-inc.com/products/power-optimization/variability-and-yield/       valid
Crawling page: http://www.tela-inc.com/products/power-optimization/leakage-speed-tradeoffs/       valid
Crawling page: http://hiqsolar.com/ac-splice.html       valid
Crawling page: http://hiqsolar.com/rooftop.html       valid
Crawling page: http://hiqsolar.com/features.html       valid
Crawling page: http://hiqsolar.com/mounting.html       valid
Crawling page: http://www.tela-inc.com/products/physical-ip/       valid
Crawling page: http://www.tela-inc.com/products/       valid
Crawling page: http://www.tela-inc.com/company-overview/board-of-directors/       valid
Crawling page: http://www.tela-inc.com/company-overview/management/       valid
Crawling page: http://www.tela-inc.com/company-overview/business-model/       valid
Crawling page: http://www.tela-inc.com/company-overview/       valid
Crawling page: http://ampiopharma.com/pipeline/optina/       Crawling page: http://ampiopharma.com/pipeline/ampion/       Crawling page: http://hiqsolar.com/products.html       valid
Crawling page: http://hiqsolar.com/gateway.html       valid
Crawling page: http://hiqsolar.com/480v-truestring-string-inverter.html       valid
Crawling page: http://hiqsolar.com/208v-truestring-string-inverter.html       valid
Crawling page: https://ampiopharma.com/news/ampio-provides-corporate-update-2/       valid
Crawling page: https://ampiopharma.com/news/ampio-updates-regulatory-and-clinical-status-for-ampion/       valid
Crawling page: https://ampiopharma.com/news/publications/       valid
Crawling page: https://ampiopharma.com/contact-us/       valid
Crawling page: https://ampiopharma.com/investors/corporate-governance/       valid
Crawling page: https://ampiopharma.com/investors/financial-filings/       valid
Crawling page: https://ampiopharma.com/partnering/       valid
Crawling page: https://ampiopharma.com/investors/presentations-media/       valid
Crawling page: https://ampiopharma.com/pipeline/optina/       valid
Crawling page: https://ampiopharma.com/investors/stock-information/       valid
Crawling page: https://ampiopharma.com/pipeline/about-diabetic-macular-edema/       valid
Crawling page: http://www.glycon.com/tie-bars       valid
Crawling page: http://www.glycon.com/qso-non-return-valves       valid
Crawling page: https://ampiopharma.com/news/latest-news/       valid
Crawling page: https://ampiopharma.com/about-us/scientific-advisory-board/       valid
Crawling page: http://www.glycon.com/glycon-barrels       valid
Crawling page: http://www.glycon.com/general-purpose-feed-screws       valid
Crawling page: http://www.glycon.com/resources/privacy-notice       valid
Crawling page: http://www.glycon.com/contact-us       valid
Crawling page: http://www.glycon.com/quote       valid
Crawling page: http://www.glycon.com/resources/videos       valid
Crawling page: https://ampiopharma.com/pipeline/ampion/       valid
Crawling page: https://ampiopharma.com/about-us/board-of-directors/       valid
Crawling page: https://ampiopharma.com/pipeline/about-osteoarthritis/       valid
Crawling page: https://ampiopharma.com/pipeline/       valid
Crawling page: http://www.glycon.com/resources/published-articles       valid
Crawling page: http://www.glycon.com/resources/educational-guides       valid
Crawling page: http://www.glycon.com/resources/blog       valid
Crawling page: http://www.glycon.com/resources/white-papers       valid
Crawling page: http://www.glycon.com/services/field-services       valid
Crawling page: http://www.glycon.com/resources       valid
Crawling page: http://www.glycon.com/services/consulting       valid
Crawling page: http://www.glycon.com/services/feedscrew-rebuilding       valid
Crawling page: https://ampiopharma.com/about-us/       valid
Crawling page: https://ampiopharma.com/       valid
Crawling page: http://www.glycon.com/bio-screw       valid
Crawling page: http://www.glycon.com/services/product-process-development       valid
Crawling page: http://www.glycon.com/our-products/tie-bars       valid
Crawling page: http://www.glycon.com/services       valid
Crawling page: http://www.glycon.com/our-products/feed-throats       valid
Crawling page: http://www.glycon.com/our-products/glycon-barrels       valid
Crawling page: http://www.glycon.com/our-products/end-caps       valid
Crawling page: http://www.glycon.com/our-products/qso-non-return-valves       valid
Crawling page: https://www.delavaufood.com/lesaffre-acquires-bakery-ingredients-company-delavau-food-partners/       valid
Crawling page: https://www.delavaufood.com/category/snack/       valid
Crawling page: https://www.delavaufood.com/three-fresh-ideas-for-frozen-pizza/       valid
Crawling page: https://www.delavaufood.com/category/news/       valid
Crawling page: https://ampiopharma.com/about-us/management-team/       valid
Crawling page: http://www.glycon.com/our-products/general-purpose-feed-screws       valid
Crawling page: http://www.glycon.com/our-products       valid
Crawling page: http://www.glycon.com/history/terms-and-conditions       valid
Crawling page: http://www.glycon.com/our-products/dm2-distributive-mixing-melting-screw       valid
Crawling page: http://www.glycon.com/history/what-s-new       valid
Crawling page: http://www.glycon.com/history       valid
Crawling page: http://www.glycon.com/       valid
Crawling page: https://www.delavaufood.com/category/fortification/       valid
Crawling page: https://www.delavaufood.com/category/clean-label/       valid
Crawling page: https://www.delavaufood.com/collaboration-for-customization/       valid
Crawling page: https://www.delavaufood.com/category/freshness/       valid
Crawling page: http://www.gastechnology.org/pages/SiteMap.aspx       valid
Crawling page: http://www.gastechnology.org/news/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/market_results/Pages/default.aspx2018-11-11 02:50:35 [scrapy.extensions.logstats] INFO: Crawled 1410 pages (at 25 pages/min), scraped 1232 items (at 16 items/min)
2018-11-11 02:51:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <401 http://www.gastechnology.org/_catalogs/masterpage/>: HTTP status code is not handled or not allowed
2018-11-11 02:51:31 [scrapy.extensions.logstats] INFO: Crawled 1414 pages (at 4 pages/min), scraped 1245 items (at 13 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 02:53:00 [scrapy.extensions.logstats] INFO: Crawled 1437 pages (at 23 pages/min), scraped 1262 items (at 17 items/min)
2018-11-11 02:53:41 [scrapy.extensions.logstats] INFO: Crawled 1437 pages (at 0 pages/min), scraped 1269 items (at 7 items/min)
2018-11-11 02:54:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/news/press-releases/Jan2018pressrelease> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:54:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/cei-world/cei-asia> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:54:38 [scrapy.extensions.logstats] INFO: Crawled 1462 pages (at 25 pages/min), scraped 1275 items (at 6 items/min)
2018-11-11 02:55:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/CEI%20Foundation> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:55:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/cei-world/cei-north-america> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:55:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/products/d-type> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:55:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/cei-world/cei-australia-new-zealand> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:55:37 [scrapy.extensions.logstats] INFO: Crawled 1464 pages (at 2 pages/min), scraped 1281 items (at 6 items/min)
2018-11-11 02:55:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/cei-world/cei-europe-middle-east> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:55:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/CEI%20Foundation/About%20CEI%20foundation> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:55:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/CEI%20Foundation/CEI%20Foundation%20Current%20Projects> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:55:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.cambridgeelectronics.com/CEI%20Foundation/CEI%20Foundation%20Continuing%20Projects> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 02:56:26 [scrapy.extensions.logstats] INFO: Crawled 1464 pages (at 0 pages/min), scraped 1285 items (at 4 items/min)
2018-11-11 02:56:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.cambridgeelectronics.com/products/DIN-41612-connectors/B-DIN41612>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 02:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.wikipad.com?lang=tr>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 02:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.wikipad.com/contact-us/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 02:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.wikipad.com/features/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 02:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.wikipad.com/privacy-policy/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 02:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.cambridgeelectronics.com/news/Upcoming-Shows>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 02:57:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/news/Upcoming-Shows>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 02:57:36 [scrapy.extensions.logstats] INFO: Crawled 1485 pages (at 21 pages/min), scraped 1297 items (at 12 items/min)
2018-11-11 02:57:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.nwbio.com/patient-stories-physician-comments/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 02:57:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/products/rf-connectors/TNC-RF-Connectors>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 02:57:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/products/cables/telco-telecom-cables>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 02:57:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/products/DIN-41612-connectors>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 02:58:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/sales%20terms>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
       valid
Crawling page: http://www.gastechnology.org/reports_software/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/Services/Pages/PerfExtra-A-Step-Change-in-Hydraulic-Fracturing.aspx       valid
Crawling page: http://www.gastechnology.org/STEPDemo/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/News/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/careers/pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/Solutions/Pages/Coal-Gasification.aspx       valid
Crawling page: http://www.gastechnology.org/Solutions/Pages/PowerGeneration.aspx       valid
Crawling page: http://www.gastechnology.org/Solutions/Pages/IntelligentInfrastructure.aspx       valid
Crawling page: http://www.gastechnology.org/Solutions/Pages/EnergyEfficiency.aspx       valid
Crawling page: https://www.delavaufood.com/contact/       valid
Crawling page: https://www.delavaufood.com/resource-center/       valid
Crawling page: https://www.delavaufood.com       valid
Crawling page: https://www.delavaufood.com/category/bakery/       valid
Crawling page: https://www.delavaufood.com/about/       valid
Crawling page: https://www.delavaufood.com/food-lab/       valid
Crawling page: https://www.delavaufood.com/expertise/       valid
Crawling page: http://www.gastechnology.org/Expertise/Pages/Hydraulic-Fracturing-Test-Site.aspx       valid
Crawling page: http://www.gastechnology.org/About/Pages/Working-with-GTI.aspx       valid
Crawling page: http://www.gastechnology.org/About/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/contact/Pages/default.aspx       valid
Crawling page: https://www.delavaufood.com/about/latest-news/       valid
Crawling page: https://www.delavaufood.com/our-products/       valid
Crawling page: http://www.gastechnology.org/events/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/Training/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/Expertise/Pages/SupplyExpertise.aspx       valid
Crawling page: http://www.gastechnology.org/Services/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/Solutions/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/Pages/default.aspx       valid
Crawling page: http://www.gastechnology.org/private/Pages/Energy-Learning-Center-Team-Site-Login.aspx       valid
Crawling page: https://www.nwbio.com/forward-looking-statements/       valid
Crawling page: https://dharmacon.horizondiscovery.com/transfection/       valid
Crawling page: https://dharmacon.horizondiscovery.com/cdnas-and-orfs/cdna-and-orf-libraries/       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/custom-synthesis/rna/       valid
Crawling page: https://www.nwbio.com/stock-quote/       valid
Crawling page: https://www.nwbio.com/related-links/       valid
Crawling page: https://www.nwbio.com/company-management/       valid
Crawling page: https://www.nwbio.com/legal-disclaimer/       valid
Crawling page: https://dharmacon.horizondiscovery.com/viral-packaging/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/product-selection-tools/       valid
Crawling page: https://dharmacon.horizondiscovery.com/new-products/       valid
Crawling page: https://dharmacon.horizondiscovery.com/services/       valid
Crawling page: http://www.wikipad.com/terms-of-use-2/       valid
Crawling page: http://www.wikipad.com/press/       valid
Crawling page: https://global.epson.com/SR/supply_chain_csr/       valid
Crawling page: https://global.epson.com/SR/our_people/       valid
Crawling page: https://global.epson.com/SR/organizational_governance/       valid
Crawling page: https://global.epson.com/SR/citizenship/       valid
Crawling page: https://www.nwbio.com/privacy-policy/       valid
Crawling page: https://dharmacon.horizondiscovery.com/design-center/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/rna-interference/sirna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/crispra-transcriptional-activation-for-gene-overexpression/       valid
Crawling page: https://dharmacon.horizondiscovery.com/applications/transfection/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/sirna/sigenome/       valid
Crawling page: https://www.cambridgeelectronics.com/       Crawling page: https://www.cambridgeelectronics.com/news/press-releases/Jan2018pressrelease       Crawling page: https://www.cambridgeelectronics.com/products/cables       valid
Crawling page: https://www.cambridgeelectronics.com/products/rf-connectors       valid
Crawling page: https://www.cambridgeelectronics.com/cei-world/cei-asia       Crawling page: https://www.k-space.com/privacy/       valid
Crawling page: https://www.k-space.com/products/ksa-emissometer/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/brochures-and-flyers/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/quick-protocols/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/technical-resources/       valid
Crawling page: https://dharmacon.horizondiscovery.com/about-us/genomics-discovery-initiative/       valid
Crawling page: https://www.cambridgeelectronics.com/CEI%20Foundation       Crawling page: https://www.cambridgeelectronics.com/cei-world/cei-north-america       Crawling page: https://www.cambridgeelectronics.com/products/d-type       Crawling page: https://www.cambridgeelectronics.com/cei-world/cei-australia-new-zealand       Crawling page: https://www.k-space.com/sitemap/       valid
Crawling page: https://www.cambridgeelectronics.com/cei-world/cei-europe-middle-east       Crawling page: https://www.cambridgeelectronics.com/CEI%20Foundation/About%20CEI%20foundation       Crawling page: https://www.cambridgeelectronics.com/CEI%20Foundation/CEI%20Foundation%20Current%20Projects       Crawling page: https://www.cambridgeelectronics.com/CEI%20Foundation/CEI%20Foundation%20Continuing%20Projects       Crawling page: https://dharmacon.horizondiscovery.com/resources/videos/crispr-rna-configurator-hdr/       valid
Crawling page: https://dharmacon.horizondiscovery.com/eprocurement-customized-online-ordering-solutions/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/featured-articles/considerations-t7-endonuclease-mismatch-assays-for-crispr-experiments/       valid
Crawling page: https://dharmacon.horizondiscovery.com/resources/videos/advantages-of-horizon-crispr-cas9-tools-gene-editing/       valid
Crawling page: https://dharmacon.horizondiscovery.com/rnai/shrna/tripz-lentiviral-shrna/       valid
Crawling page: https://dharmacon.horizondiscovery.com/geneontology/index.html       valid
Crawling page: https://dharmacon.horizondiscovery.com/terms-of-use/       valid
Crawling page: https://dharmacon.horizondiscovery.com/about-us/about-open-biosystems/       valid
Crawling page: https://dharmacon.horizondiscovery.com/signin/?returnUrl=/contact/       valid
Crawling page: https://dharmacon.horizondiscovery.com/sitemap/       valid
Crawling page: https://www.k-space.com/products/bandit-pv/       valid
Crawling page: https://www.nwbio.com/publications/       valid
Crawling page: https://www.nwbio.com       valid
Crawling page: https://www.nwbio.com/dcvax-technology/       valid
Crawling page: https://www.nwbio.com/dendritic-cell-immunotherapy/       valid
Crawling page: https://www.k-space.com/measure/film-thickness-and-deposition-rate/       valid
Crawling page: http://cnri.reston.va.us/projects.html       valid
Crawling page: http://cnri.reston.va.us/publications.html       valid
Crawling page: http://cnri.reston.va.us/contacts.html       valid
Crawling page: http://cnri.reston.va.us/activities.html       valid
Crawling page: http://cnri.reston.va.us/jobs.html       valid
Crawling page: http://cnri.reston.va.us/news.html       valid
Crawling page: http://taurx.com/business-development.html       valid
Crawling page: http://taurx.com/tau-inhibition.html       valid
Crawling page: http://www.rimaenterprises.in/       /bin/sh: 1: kill: No such process

2018-11-11 02:58:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/privacy>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 02:58:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cambridgeelectronics.com/about_us>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
/bin/sh: 1: kill: No such process

2018-11-11 02:58:36 [scrapy.extensions.logstats] INFO: Crawled 1494 pages (at 9 pages/min), scraped 1310 items (at 13 items/min)
2018-11-11 02:59:48 [scrapy.extensions.logstats] INFO: Crawled 1507 pages (at 13 pages/min), scraped 1322 items (at 12 items/min)
2018-11-11 03:00:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://taurx.com/uploads/press%20releases/Alzheimer%20candidate%20LMTX%C2%AE%20inhibits%20%CE%B1-sync%20aggregation%20in%20pre-clinical%20Parkinson%E2%80%99s%20Disease%20study,%20published%20in%20the%20Frontiers%20in%20Molecular%20Neuroscience.pdf> (referer: http://taurx.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 81, in replace
    return cls(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 22, in __init__
    self._set_body(body)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 57, in _set_body
    "Response body must be bytes. "
TypeError: Response body must be bytes. If you want to pass unicode body use TextResponse or HtmlResponse.
2018-11-11 03:00:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://taurx.com/uploads/press%20releases/JAD_005_Press%20Release_website.pdf> (referer: http://taurx.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 81, in replace
    return cls(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 22, in __init__
    self._set_body(body)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 57, in _set_body
    "Response body must be bytes. "
TypeError: Response body must be bytes. If you want to pass unicode body use TextResponse or HtmlResponse.
2018-11-11 03:00:22 [scrapy.extensions.logstats] INFO: Crawled 1517 pages (at 10 pages/min), scraped 1326 items (at 4 items/min)
2018-11-11 03:01:22 [root] ERROR: Unable to find match for url: https://thetranslationalscientist.com/issues/august-18/bringing-alzheimers-in-from-the-cold/
2018-11-11 03:01:45 [scrapy.extensions.logstats] INFO: Crawled 1522 pages (at 5 pages/min), scraped 1339 items (at 13 items/min)
2018-11-11 03:02:24 [scrapy.extensions.logstats] INFO: Crawled 1536 pages (at 14 pages/min), scraped 1345 items (at 6 items/min)
2018-11-11 03:03:30 [scrapy.extensions.logstats] INFO: Crawled 1547 pages (at 11 pages/min), scraped 1356 items (at 11 items/min)
2018-11-11 03:04:41 [scrapy.extensions.logstats] INFO: Crawled 1551 pages (at 4 pages/min), scraped 1368 items (at 12 items/min)
2018-11-11 03:05:41 [scrapy.extensions.logstats] INFO: Crawled 1565 pages (at 14 pages/min), scraped 1378 items (at 10 items/min)
2018-11-11 03:06:29 [scrapy.extensions.logstats] INFO: Crawled 1576 pages (at 11 pages/min), scraped 1386 items (at 8 items/min)
valid
Crawling page: http://taurx.com/taurx-in-the-news/       valid
Crawling page: http://taurx.com/       valid
Crawling page: http://taurx.com/clinical-trials/       valid
Crawling page: http://taurx.com/product-pipeline/       valid
Crawling page: http://www.rimaenterprises.in/Billing_Soft.aspx       valid
Crawling page: http://elementonescreens.com/de/       valid
Crawling page: http://www.rimaenterprises.in/Meter_Testing_Soft.aspx       valid
Crawling page: http://elementonescreens.com/save-date-april/       valid
Crawling page: http://elementonescreens.com/new-socket-x-desktop-connection-panel/       valid
Crawling page: http://elementonescreens.com/small-nice-town-hall-integrated-monitor/       valid
Crawling page: http://elementonescreens.com/10x-synchronized-retractable-monitors-in-a-board-room/       valid
Crawling page: http://elementonescreens.com/explained-in-60-seconds-integration/       valid
Crawling page: http://elementonescreens.com/de/datenschutz/       valid
Crawling page: http://taurx.com/press-releases/       valid
Crawling page: http://taurx.com/jobs/       valid
Crawling page: http://taurx.com/science/       valid
Crawling page: http://elementonescreens.com/privacy_policy/       valid
Crawling page: http://elementonescreens.com/agb/       valid
Crawling page: http://elementonescreens.com/this-is-a-post/       valid
Crawling page: http://elementonescreens.com/fold-2/       valid
Crawling page: http://taurx.com/uploads/press%20releases/Alzheimer%20candidate%20LMTX%C2%AE%20inhibits%20%CE%B1-sync%20aggregation%20in%20pre-clinical%20Parkinson%E2%80%99s%20Disease%20study,%20published%20in%20the%20Frontiers%20in%20Molecular%20Neuroscience.pdf       Crawling page: http://taurx.com/uploads/press%20releases/JAD_005_Press%20Release_website.pdf       Crawling page: http://elementonescreens.com/this-is-another-news-post/       valid
Crawling page: http://elementonescreens.com/integrated-systems-europe-2015/       valid
Crawling page: http://elementonescreens.com/design-directory-get-now/       valid
Crawling page: http://elementonescreens.com/manufaktur-fur-versenkbare-monitore-ist-umgezogen/       valid
Crawling page: http://elementonescreens.com/neue-versenkbare-monitore-mikrofone-auf-der-ise-2015/       valid
Crawling page: http://elementonescreens.com/retractable-monitors-at-infocomm-connected-2015/       valid
Crawling page: http://elementonescreens.com/stencils-table-design/       valid
Crawling page: http://elementonescreens.com/see-touch-and-interact-with-the-latest-innovations-in-audio-audiovisual-lighting-and-event-technologies-at-westburys-imagine-technology-showcase/       valid
Crawling page: https://thetranslationalscientist.com/issues/august-18/bringing-alzheimers-in-from-the-cold/       valid
Crawling page: http://elementonescreens.com/imagine-by-westbury-toronto/       valid
Crawling page: http://elementonescreens.com/plus-punkt/       valid
Crawling page: http://elementonescreens.com/element-one-at-index-dubai-18-21-may/       valid
Crawling page: http://elementonescreens.com/retractable-monitors-at-infocomm-2015-orlando-17-19-june/       valid
Crawling page: http://elementonescreens.com/retractable-monitor-consulting-bank-hanau/       valid
Crawling page: http://elementonescreens.com/review-infocomm-2015-orlando/       valid
Crawling page: http://elementonescreens.com/2x-integrated-usb-sockets-as-standard/       valid
Crawling page: http://elementonescreens.com/retractable-monitor-explained-in-60-seconds/       valid
Crawling page: http://elementonescreens.com/senat-angola-retractable-monitor/       valid
Crawling page: http://elementonescreens.com/download-of-stencils-available/       valid
Crawling page: http://elementonescreens.com/element-one-is-finalist-for-2016-inavation-awards/       valid
Crawling page: http://elementonescreens.com/retractable-monitors-in-the-new-national-defense-center-of-russia/       valid
Crawling page: http://elementonescreens.com/neue-preisliste-verfuegbar/       valid
Crawling page: http://elementonescreens.com/frohe-weihnachten/       valid
Crawling page: http://elementonescreens.com/integrated-systems-europe-ise-2016-review/       valid
Crawling page: http://elementonescreens.com/cebit-2016-element-one-and-new-work/       valid
Crawling page: http://elementonescreens.com/element-one-wuenscht-frohe-ostern/       valid
Crawling page: http://elementonescreens.com/modis-22ts10-ausgezeichnet-2/       valid
Crawling page: http://elementonescreens.com/digimic-lean-vision-konferenz-loesung-im-perfekten-zusammenspiel-mit-dem-versenkbaren-monitor-convers/       valid
Crawling page: http://elementonescreens.com/13-multi-media-messe-in-wismar-25-05-2016-2/       valid
Crawling page: http://elementonescreens.com/infocomm-show-08-10-june-las-vegas/       valid
Crawling page: http://elementonescreens.com/versenkbare-monitore-raeume-part-i/       valid
Crawling page: http://elementonescreens.com/versenkbare-monitore-raeume-teil-ii/       valid
Crawling page: http://elementonescreens.com/element-one-on-tour-muenchen/       valid
Crawling page: http://elementonescreens.com/versenkbare-monitore-raeume-teil-iii/       valid
Crawling page: http://elementonescreens.com/retractable-monitors-rooms-part-iv/       valid
Crawling page: http://elementonescreens.com/treffen-sie-integrierte-bildschirme-auf-dem-tag-der-offenen-tuer-bei-smartmetals/       valid
Crawling page: http://elementonescreens.com/visulutionary-day-16-15-09-2016-2/       valid
Crawling page: http://elementonescreens.com/convis-125-im-8mm-blade-design/       valid
Crawling page: http://elementonescreens.com/frohe-weihnachten-und-ein-guten-rutsch/       valid
Crawling page: http://elementonescreens.com/2017-year-of-the-blade/       valid
Crawling page: http://elementonescreens.com/ratsaal-der-stadt-guetersloh/       valid
Crawling page: http://elementonescreens.com/av-focus-event-kasan/       valid
Crawling page: http://elementonescreens.com/av-focus-event-krasnodar/       valid
Crawling page: http://elementonescreens.com/usb-am-monitor-kleiner-stecker-grosse-wirkung/       valid
Crawling page: http://elementonescreens.com/custom-colour/       valid
Crawling page: http://elementonescreens.com/best-of-2017-versis-vesa-industriepreis/       valid
Crawling page: http://elementonescreens.com/av-focus-event-novosibirsk/       valid
Crawling page: http://elementonescreens.com/konferenzraum-landwehr/       valid
Crawling page: http://elementonescreens.com/8-mm-is-the-benchmark/       valid
Crawling page: http://elementonescreens.com/unser-vertriebsteam-sucht-verstaerkung/       valid
Crawling page: http://elementonescreens.com/2nd-system-day-am-12-07-2017/       valid
Crawling page: http://elementonescreens.com/county_osnabrueck/       valid
Crawling page: http://elementonescreens.com/versis-vesa-is-finalist-at-inavation-awards-2018/       valid
Crawling page: http://elementonescreens.com/convers-and-modis-retractable-monitors-on-the-31st-floor-of-the-etihad-towers/       valid
Crawling page: http://elementonescreens.com/customized-black-retractable-monitors-in-the-heart-of-moscow/       valid
Crawling page: http://elementonescreens.com/aluminum-leather/       valid
Crawling page: http://elementonescreens.com/fold_robotic_like_retractable_monitor/       valid
Crawling page: http://elementonescreens.com/flexible-kompakte-vorschau-monitore-fuer-den-kreistagssaal-im-landratsamt-waldshut/       valid
Crawling page: http://elementonescreens.com/neu-convers-one-serie-versenkbarer-monitor-mit-vielen-varianten/       valid
Crawling page: http://elementonescreens.com/retractable-monitors-on-ise-2018/       valid
Crawling page: http://elementonescreens.com/product/customization/       valid
Crawling page: http://elementonescreens.com/product/product-6/       valid
Crawling page: http://elementonescreens.com/product/rotatis/       valid
Crawling page: http://elementonescreens.com/product/product-5/       valid
Crawling page: http://elementonescreens.com/product/convis-125/       valid
Crawling page: http://elementonescreens.com/product/convers-digimic-lean-vision/       valid
Crawling page: http://elementonescreens.com/product/socket-x-170/       valid2018-11-11 03:07:32 [scrapy.extensions.logstats] INFO: Crawled 1580 pages (at 4 pages/min), scraped 1393 items (at 7 items/min)
2018-11-11 03:08:41 [scrapy.extensions.logstats] INFO: Crawled 1592 pages (at 12 pages/min), scraped 1402 items (at 9 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 03:09:27 [scrapy.extensions.logstats] INFO: Crawled 1592 pages (at 0 pages/min), scraped 1409 items (at 7 items/min)
2018-11-11 03:10:52 [scrapy.extensions.logstats] INFO: Crawled 1611 pages (at 19 pages/min), scraped 1426 items (at 17 items/min)
2018-11-11 03:12:02 [scrapy.extensions.logstats] INFO: Crawled 1625 pages (at 14 pages/min), scraped 1438 items (at 12 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 03:12:32 [scrapy.extensions.logstats] INFO: Crawled 1644 pages (at 19 pages/min), scraped 1444 items (at 6 items/min)
2018-11-11 03:13:29 [scrapy.extensions.logstats] INFO: Crawled 1647 pages (at 3 pages/min), scraped 1453 items (at 9 items/min)
2018-11-11 03:14:41 [scrapy.extensions.logstats] INFO: Crawled 1661 pages (at 14 pages/min), scraped 1463 items (at 10 items/min)
2018-11-11 03:15:25 [scrapy.extensions.logstats] INFO: Crawled 1662 pages (at 1 pages/min), scraped 1469 items (at 6 items/min)
2018-11-11 03:16:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.sierrasci.com?p=home>: HTTP status code is not handled or not allowed
2018-11-11 03:16:35 [scrapy.extensions.logstats] INFO: Crawled 1682 pages (at 20 pages/min), scraped 1480 items (at 11 items/min)
2018-11-11 03:17:36 [scrapy.extensions.logstats] INFO: Crawled 1690 pages (at 8 pages/min), scraped 1493 items (at 13 items/min)

Crawling page: http://elementonescreens.com/product/modis-220/       valid
Crawling page: http://elementonescreens.com/product/versis-173/       valid
Crawling page: http://elementonescreens.com/product/convers-173/       valid
Crawling page: http://elementonescreens.com/handbetrieb/       valid
Crawling page: http://elementonescreens.com/s-campus-innovative-sparkassen-filiale-mit-integrierten-monitoren-auf-dem-campus-der-universitaet-kassel/       valid
Crawling page: http://elementonescreens.com/verwaltungsratsraum-mittelbrandenburgische-sparkasse/       valid
Crawling page: http://elementonescreens.com/product/fold/       valid
Crawling page: http://elementonescreens.com/de/contact-page/newsletter_de/       valid
Crawling page: http://elementonescreens.com/element-one/vision/       valid
Crawling page: http://elementonescreens.com/element-one/quality/       valid
Crawling page: http://elementonescreens.com/element-one/team/       valid
Crawling page: http://elementonescreens.com/       valid
Crawling page: http://elementonescreens.com/products/versis-75-en/       valid
Crawling page: http://elementonescreens.com/products/convers-double-en/       valid
Crawling page: http://elementonescreens.com/products/rotatis-en/       valid
Crawling page: http://elementonescreens.com/products/modis-en/       valid
Crawling page: http://www.rimaenterprises.in/SMS_App.aspx       valid
Crawling page: http://www.rimaenterprises.in/Support.aspx       valid
Crawling page: http://www.rimaenterprises.in/Web_Admin_Module.aspx       valid
Crawling page: http://www.rimaenterprises.in/Mobile_App.aspx       valid
Crawling page: http://www.rimaenterprises.in/SEO.aspx       valid
Crawling page: http://www.rimaenterprises.in/Digital_Mark.aspx       valid
Crawling page: http://www.rimaenterprises.in/Domain_Hosting.aspx       valid
Crawling page: http://elementonescreens.com/products/versis-en/       valid
Crawling page: http://elementonescreens.com/products/convers-blade-en-en/       valid
Crawling page: http://elementonescreens.com/products/convers-one-de/       valid
Crawling page: http://elementonescreens.com/products/convers-en/       valid
Crawling page: http://elementonescreens.com/impressum/       valid
Crawling page: http://elementonescreens.com/contact-page/       valid
Crawling page: http://elementonescreens.com/downloads/       valid
Crawling page: http://elementonescreens.com/frequently-asked-questions/       valid
Crawling page: http://www.rimaenterprises.in/website_dev.aspx       valid
Crawling page: http://www.rimaenterprises.in/updates.aspx       valid
Crawling page: http://www.rimaenterprises.in/Default.aspx       valid
Crawling page: http://www.rimaenterprises.in/whatsappform.aspx       valid
Crawling page: http://cnri.reston.va.us/index.html       valid
Crawling page: http://cnri.reston.va.us/about_cnri.html       valid
Crawling page: http://elementonescreens.com/products/       valid
Crawling page: http://elementonescreens.com/monitor-news/       valid
Crawling page: http://elementonescreens.com/monitor-references/       valid
Crawling page: http://elementonescreens.com/monitors-and-rooms/       valid
Crawling page: http://taurx.com/about-us/       valid
Crawling page: http://taurx.com/the-importance-of-ongoing-research-in-alzheimer%E2%80%99s-disease.html       valid
Crawling page: http://www.rimaenterprises.in/Referrals.aspx       valid
Crawling page: http://www.rimaenterprises.in/career.aspx       valid
Crawling page: http://elementonescreens.com/contact-page/newsletter_en/       valid
Crawling page: http://elementonescreens.com/element-one/       valid
Crawling page: http://polyplus.com/contact/       valid
Crawling page: http://polyplus.com/privacy-policy/       valid
Crawling page: http://polyplus.com/company/       valid
Crawling page: http://polyplus.com/       valid
Crawling page: https://www.pentron.com/sitemap       valid
Crawling page: http://polyplus.com/product-pipeline/       valid
Crawling page: http://polyplus.com/terms-and-conditions/       valid
Crawling page: https://www.pentron.com/composites/simile-nano       valid
Crawling page: http://polyplus.com/lead-product-glass-protected-lithium-battery/       valid
Crawling page: http://www.nutechventures.org       valid
Crawling page: http://www.nutechventures.org/terms-and-conditions-of-use/       valid
Crawling page: http://www.nutechventures.org/privacy-policy/       valid
Crawling page: http://www.nutechventures.org/for-campus/       valid
Crawling page: https://www.pentron.com/european-middle-east-and-africa-dealers       valid
Crawling page: https://www.pentron.com/contact-us       valid
Crawling page: https://www.pentron.com/europe-sales-team       valid
Crawling page: https://www.pentron.com/about-us-0       valid
Crawling page: https://www.bosch.com/data-protection-policy/       valid
Crawling page: https://www.bosch.com/legal-notice/       valid
Crawling page: https://www.pentron.com/dental-procedures/pentron-systems-solution       valid
Crawling page: https://www.pentron.com/infection-control/depural-neo-prophylaxis       valid
Crawling page: https://www.pentron.com/download-0       valid
Crawling page: https://www.pentron.com/contact-us-1       valid
Crawling page: https://www.pentron.com/infection-control/disinfection       valid
Crawling page: https://www.pentron.com/infection-control/prophylaxis       valid
Crawling page: https://www.pentron.com/temporary-materials/tempspan-temporary-cb-material-temporary-cb       valid
Crawling page: https://www.pentron.com/temporary-materials/optitemp-automix-temporary-cb       valid
Crawling page: https://www.pentron.com/temporary-materials/temporary-cement       valid
Crawling page: https://www.bosch.com/research/meet-bosch-research/collaboration/       valid
Crawling page: https://www.bosch.com/research/meet-bosch-research/events/       valid
Crawling page: https://www.bosch.com/research/about-research/       valid
Crawling page: https://www.sierrasci.com/get_involved?p=home       valid
Crawling page: https://www.sierrasci.com/contact?p=home       valid
Crawling page: https://www.sierrasci.com/cure-for-diseases?p=home       valid
Crawling page: https://www.sierrasci.com/news?p=home       valid
Crawling page: https://www.bosch.com/research/know-how/open-and-inner-source/       valid
Crawling page: https://www.bosch.com/research/about-research/purpose/       valid
Crawling page: https://www.bosch.com/research/about-research/roots/       valid
Crawling page: https://www.bosch.com/research/meet-bosch-research/       valid
Crawling page: https://www.sierrasci.com/about_us?p=home       valid
Crawling page: https://www.sierrasci.com/projects?p=home       valid
Crawling page: https://www.bosch.com/research/know-how/success-stories/       valid
Crawling page: https://www.bosch.com/research/know-how/publications/       valid
Crawling page: https://www.bosch.com/research/know-how/research-experts/       valid
Crawling page: https://www.bosch.com/research/know-how/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/user-centric-computing/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/fully-autonomous-systems/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/future-of-healthcare-solutions/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/disruptive-materials/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/quantum-technologies/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/clean-air-water-and-food-supplies/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/energy-conversion-and-infrastructure/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/electric-mobility/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/connected-and-intelligent-systems/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/self-aware-and-self-developing-systems/       valid
Crawling page: https://www.bosch.com/research/fields-of-innovation/       valid
Crawling page: https://www.bosch.com/research/2018-11-11 03:18:22 [scrapy.extensions.logstats] INFO: Crawled 1698 pages (at 8 pages/min), scraped 1501 items (at 8 items/min)
2018-11-11 03:19:37 [scrapy.extensions.logstats] INFO: Crawled 1710 pages (at 12 pages/min), scraped 1513 items (at 12 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 03:20:36 [scrapy.extensions.logstats] INFO: Crawled 1718 pages (at 8 pages/min), scraped 1525 items (at 12 items/min)
2018-11-11 03:20:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://ambature.com/what-we-could-do/>: HTTP status code is not handled or not allowed
2018-11-11 03:21:46 [scrapy.extensions.logstats] INFO: Crawled 1734 pages (at 16 pages/min), scraped 1536 items (at 11 items/min)
2018-11-11 03:22:34 [scrapy.extensions.logstats] INFO: Crawled 1750 pages (at 16 pages/min), scraped 1544 items (at 8 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 03:23:32 [scrapy.extensions.logstats] INFO: Crawled 1761 pages (at 11 pages/min), scraped 1556 items (at 12 items/min)
2018-11-11 03:24:31 [scrapy.extensions.logstats] INFO: Crawled 1766 pages (at 5 pages/min), scraped 1567 items (at 11 items/min)
2018-11-11 03:25:37 [scrapy.extensions.logstats] INFO: Crawled 1777 pages (at 11 pages/min), scraped 1579 items (at 12 items/min)
2018-11-11 03:26:31 [scrapy.extensions.logstats] INFO: Crawled 1792 pages (at 15 pages/min), scraped 1589 items (at 10 items/min)
       valid
Crawling page: https://www.bosch.com/our-company/sustainability/strategy/vision-and-targets/       valid
Crawling page: https://www.bosch.com/our-company/sustainability/reporting-and-data/       valid
Crawling page: https://www.bosch.com/our-company/sustainability/sustainability-report-2017/       valid
Crawling page: https://www.bosch.com/our-company/sustainability/gri-content-index/       valid
Crawling page: https://www.bosch.com/our-company/sustainability/       valid
Crawling page: https://www.bosch.com/our-company/our-history/       valid
Crawling page: https://www.bosch.com/our-company/our-people/       valid
Crawling page: https://www.bosch.com/our-company/our-figures/       valid
Crawling page: https://www.bosch.com/our-company/       valid
Crawling page: https://www.bosch.com/explore-and-experience/       valid
Crawling page: https://www.bosch.com/explore-and-experience/internet-of-things/       valid
Crawling page: https://www.bosch.com/explore-and-experience/annual-report/       valid
Crawling page: https://www.bosch.com/products-and-services/market-specific-solutions/       valid
Crawling page: https://www.bosch.com/products-and-services/connected-products-and-services/software-solutions/       valid
Crawling page: https://www.bosch.com/products-and-services/connected-products-and-services/smart-cities/       valid
Crawling page: https://www.bosch.com/products-and-services/connected-products-and-services/industry-4-0/       valid
Crawling page: https://www.bosch.com/products-and-services/connected-products-and-services/       valid
Crawling page: https://www.bosch.com/products-and-services/industry-and-trades/       valid
Crawling page: https://www.bosch.com/products-and-services/connected-products-and-services/smart-home/       valid
Crawling page: https://www.bosch.com/products-and-services/connected-products-and-services/connected-mobility/       valid
Crawling page: https://www.bosch.com/products-and-services/       valid
Crawling page: https://www.bosch.com/products-and-services/mobility/       valid
Crawling page: https://www.bosch.com/products-and-services/at-home/       valid
Crawling page: https://www.bosch.com/de/       valid
Crawling page: https://www.bosch.com/       valid
Crawling page: https://www.bosch.com/websites-worldwide/       valid
Crawling page: https://www.bosch.com/contact/       valid
Crawling page: https://www.bosch.com/corporate-information/       valid
Crawling page: https://litronlabs.com/Products/In-Vivo-Micronucleus       valid
Crawling page: https://litronlabs.com/Products/In-Vivo-Pig-a-Gene-Mutation       valid
Crawling page: https://litronlabs.com/Products/In-Vitro-Micronucleus       valid
Crawling page: https://litronlabs.com/Products/In-Vivo-Human-Micronucleus       valid
Crawling page: http://ambature.com/articles/       valid
Crawling page: http://ambature.com/contact-us/       valid
Crawling page: http://ambature.com/html-sitemap/       valid
Crawling page: http://ambature.com/licensing-our-intellectual-property/description-of-our-intellectual-property/       valid
Crawling page: http://ambature.com/licensing-our-intellectual-property/texas-intellectual-property-law-journal-article/       valid
Crawling page: http://ambature.com/invest-with-us/       valid
Crawling page: http://ambature.com/licensing-our-intellectual-property/patent-assets/       valid
Crawling page: http://ambature.com/licensing-our-intellectual-property/       valid
Crawling page: http://ambature.com/meet-us/technical-advisors/adam-kablanian/       valid
Crawling page: http://ambature.com/meet-us/technical-advisors/ron-strich/       valid
Crawling page: http://ambature.com/meet-us/technical-advisors/craig-changstrom/       valid
Crawling page: http://ambature.com/meet-us/outside-legal/rick-toering/       valid
Crawling page: http://ambature.com/meet-us/technical-advisors/       valid
Crawling page: http://ambature.com/meet-us/outside-legal/       valid
Crawling page: http://ambature.com/meet-us/our-science-team/michael-lebby/       valid
Crawling page: https://www.roche.com/sustainability/access-to-healthcare/ath_diabetes.htm       valid
Crawling page: https://www.roche.com/research_and_development/what_we_are_working_on/cardiovascular_and_metabolism/taking_on_the_global_rise_of_diabetes.htm       valid
Crawling page: https://www.roche.com/legal_statement.htm       valid
Crawling page: https://www.roche.com/partnering/get_in_touch_with_us/partnering_contact_us_dia_diabetes.htm       valid
Crawling page: http://ambature.com/meet-us/board-of-directors/michael-strasser/       valid
Crawling page: http://ambature.com/meet-us/our-science-team/richard-tucker/       valid
Crawling page: http://ambature.com/meet-us/our-science-team/       valid
Crawling page: http://ambature.com/meet-us/our-science-team/davis-hartman/       valid
Crawling page: https://www.roche.com/partnering/diagnostics-areas-of-interest/automation-analytics-decision-support.htm       valid
Crawling page: https://www.roche.com/partnering/diagnostics-areas-of-interest/tissue-haematology-urine.htm       valid
Crawling page: https://www.roche.com/partnering/diagnostics-areas-of-interest/molecular-diagnostics.htm       valid
Crawling page: https://www.roche.com/partnering/diagnostics-areas-of-interest/diabetes-management.htm       valid
Crawling page: https://www.roche.com/partnering/diagnostics-areas-of-interest/point-of-care-and-self-testing.htm       valid
Crawling page: https://www.roche.com/partnering/diagnostics-areas-of-interest/clinical-immunochemistry.htm       valid
Crawling page: https://www.roche.com/partnering/diagnostics-areas-of-interest/new-biomarker-testing.htm       valid
Crawling page: https://www.roche.com/partnering/pharma-areas-of-interest.htm       valid
Crawling page: https://www.roche.com/partnering/case_studies.htm       valid
Crawling page: https://www.roche.com/careers.htm       valid
Crawling page: https://www.roche.com/investors.htm       valid
Crawling page: http://ambature.com/meet-us/board-of-directors/patrick-murphy/       valid
Crawling page: http://ambature.com/meet-us/board-of-directors/bruce-barnhill/       valid
Crawling page: http://ambature.com/meet-us/technical-advisors/davis-hartman/       valid
Crawling page: http://ambature.com/meet-us/board-of-directors/       valid
Crawling page: https://www.roche.com/media.htm       valid
Crawling page: https://www.roche.com/research_and_development.htm       valid
Crawling page: https://www.roche.com/sustainability.htm       valid
Crawling page: https://litronlabs.com/Support       valid
Crawling page: https://litronlabs.com/Resources       valid
Crawling page: https://www.roche.com/about.htm       valid
Crawling page: https://www.roche.com/       valid
Crawling page: https://www.roche.com/partnering/get_in_touch_with_us/partnering_contact_us_pharma_dia_diabetes.htm       valid
Crawling page: http://ambature.com/meet-us/our-executive-team/geoff-williamson/       valid
Crawling page: http://ambature.com/meet-us/our-executive-team/peter-kastelic/       valid
Crawling page: http://ambature.com/meet-us/our-executive-team/ron-kelly/       valid
Crawling page: http://ambature.com/meet-us/our-executive-team/ketan-patel/       valid
Crawling page: https://www.roche.com/privacy_policy.htm       valid
Crawling page: https://www.roche.com/partnering/diagnostics-areas-of-interest.htm       valid
Crawling page: https://www.roche.com/products/products-us.htm       valid
Crawling page: https://www.roche.com/partnering.htm       valid
Crawling page: http://ambature.com/corporate-info/       valid
Crawling page: http://ambature.com/meet-us/       valid
Crawling page: http://ambature.com/meet-us/our-executive-team/       valid
Crawling page: http://ambature.com/meet-us/board-of-directors/william-langer/       valid
Crawling page: https://www.pentron.com/post-core/fibrekleer-4x-fiber-post       valid
Crawling page: https://www.pentron.com/post-core/fibrekor-fiber-post-fiber-post       valid
Crawling page: https://www.pentron.com/cements/mojo-veneer-cement       valid
Crawling page: https://www.pentron.com/permanent-dental-cements-and-liners/miscellaneous       valid
Crawling page: http://ambature.com2018-11-11 03:27:41 [scrapy.extensions.logstats] INFO: Crawled 1799 pages (at 7 pages/min), scraped 1598 items (at 9 items/min)
2018-11-11 03:28:29 [scrapy.extensions.logstats] INFO: Crawled 1800 pages (at 1 pages/min), scraped 1605 items (at 7 items/min)
2018-11-11 03:29:37 [scrapy.extensions.logstats] INFO: Crawled 1814 pages (at 14 pages/min), scraped 1613 items (at 8 items/min)
2018-11-11 03:30:30 [scrapy.extensions.logstats] INFO: Crawled 1816 pages (at 2 pages/min), scraped 1620 items (at 7 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 03:31:52 [scrapy.extensions.logstats] INFO: Crawled 1828 pages (at 12 pages/min), scraped 1634 items (at 14 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 03:32:37 [scrapy.extensions.logstats] INFO: Crawled 1839 pages (at 11 pages/min), scraped 1643 items (at 9 items/min)
2018-11-11 03:33:32 [scrapy.extensions.logstats] INFO: Crawled 1853 pages (at 14 pages/min), scraped 1651 items (at 8 items/min)
2018-11-11 03:34:23 [scrapy.extensions.logstats] INFO: Crawled 1865 pages (at 12 pages/min), scraped 1660 items (at 9 items/min)
2018-11-11 03:35:25 [scrapy.extensions.logstats] INFO: Crawled 1875 pages (at 10 pages/min), scraped 1671 items (at 11 items/min)
2018-11-11 03:36:40 [scrapy.extensions.logstats] INFO: Crawled 1875 pages (at 0 pages/min), scraped 1680 items (at 9 items/min)
2018-11-11 03:37:26 [scrapy.extensions.logstats] INFO: Crawled 1888 pages (at 13 pages/min), scraped 1685 items (at 5 items/min)
/bin/sh: 1: kill: No such process

       valid
Crawling page: https://www.pentron.com/permanent-dental-cements-and-liners/glass-ionomer-cement       valid
Crawling page: https://www.pentron.com/permanent-dental-cements-and-liners/polycarboxylate-cement       valid
Crawling page: https://www.pentron.com/permanent-dental-cements-and-liners/phosphate-cement       valid
Crawling page: https://www.pentron.com/permanent-dental-cements-and-liners/resin-cement       valid
Crawling page: https://www.pentron.com/permanent-dental-cements-and-liners/veneer-cement       valid
Crawling page: https://www.pentron.com/dental-bonding-agents/etching-gel-dental-bonding-agents       valid
Crawling page: https://www.pentron.com/bonding-agents/bond-it-bonding-agents       valid
Crawling page: https://www.pentron.com/bonding-agents/bond-1-sf-bonding-agents-0       valid
Crawling page: https://www.pentron.com/dental-bonding-agents/bond-1-bonding-system-dental-bonding-agents       valid
Crawling page: https://www.pentron.com/dental-bonding-agents/dental-bonding-agents       valid
Crawling page: https://www.pentron.com/composites/opticor-flow-flowable       valid
Crawling page: https://www.pentron.com/composites/fusio-flowable       valid
Crawling page: https://www.pentron.com/composites/flow-it-alc-flowable       valid
Crawling page: https://www.pentron.com/impression/correct-vps-putty-addition-silicone-impression-material       valid
Crawling page: https://www.pentron.com/impression/others       valid
Crawling page: https://www.pentron.com/impression/correct-plus-and-correct-quick-bite-registration-material-sillicones       valid
Crawling page: https://www.pentron.com/impression/correct-plus-fast-set-sillicones       valid
Crawling page: https://www.pentron.com/impression/correct-plus-sillicones-4       valid
Crawling page: https://www.pentron.com/impression/sillicones       valid
Crawling page: https://www.pentron.com/infection-control       valid
Crawling page: https://www.pentron.com/impression/c-silicones       valid
Crawling page: https://www.pentron.com/dental-bonding-agents       valid
Crawling page: https://www.pentron.com/temporary-materials       valid
Crawling page: https://www.pentron.com/post-core       valid
Crawling page: https://www.pentron.com/permanent-dental-cements-and-liners       valid
Crawling page: https://www.pentron.com/dental-composites       valid
Crawling page: https://www.pentron.com/impression       valid
Crawling page: https://www.pentron.com/search       valid
Crawling page: http://aicchile.com/en/control-y-automatizacion-de-procesos/       valid
Crawling page: http://aicchile.com/en/tecnologia-en-base-a-plasma/       valid
Crawling page: https://www.pentron.com/       valid
Crawling page: https://www.pentron.com/fr-fr/       valid
Crawling page: https://www.pentron.com/de-de/       valid
Crawling page: https://www.pentron.com/pl-pl/       valid
Crawling page: https://www.pentron.com/es-es/       valid
Crawling page: https://www.pentron.com/it-it/       valid
Crawling page: http://aicchile.com/en/tratamiento-y-reutilizacion-de-aguas/       valid
Crawling page: http://aicchile.com/en/estimulacion-con-microondas/       valid
Crawling page: http://aicchile.com/en/pwss       valid
Crawling page: http://aicchile.com/en/electromagnetismo-y-aplicaciones/       valid
Crawling page: https://www.pentron.com/en-us/       valid
Crawling page: https://www.pentron.com/cs-cz/       valid
Crawling page: http://aicchile.com/en/       valid
Crawling page: http://aicchile.com/en       valid
Crawling page: http://aicchile.com/       valid
Crawling page: http://aicchile.com/en/nosotros/       valid
Crawling page: http://aicchile.com/en/modelo/       valid
Crawling page: http://www.nutechventures.org/new-faculty-mixer-draws-researchers-across-campus/       valid
Crawling page: http://www.nutechventures.org/jyot-helps-organize-crop-productivity-forum/       valid
Crawling page: http://www.nutechventures.org/paden-leads-education-session-on-patent-review/       valid
Crawling page: http://www.nutechventures.org/intern-qa-with-weiya-wang/       valid
Crawling page: http://www.nutechventures.org/intern-qa-with-max-qiu/       valid
Crawling page: http://www.nutechventures.org/contact-us/       valid
Crawling page: http://aicchile.com/en/modelo       valid
Crawling page: http://aicchile.com/en/rms/       valid
Crawling page: http://www.nutechventures.org/innovators/       valid
Crawling page: http://www.nutechventures.org/about-us/       valid
Crawling page: http://www.nutechventures.org/2017-innovator-celebration/       valid
Crawling page: http://www.nutechventures.org/2016-innovator-celebration/       valid
Crawling page: http://www.nutechventures.org/newsevents/       valid
Crawling page: http://www.nutechventures.org/plant-germplasm/       valid
Crawling page: http://www.nutechventures.org/campusfaq/       valid
Crawling page: http://www.nutechventures.org/resources/       valid
Crawling page: http://www.nutechventures.org/understanding-ip/       valid
Crawling page: http://www.nutechventures.org/licensing/       valid
Crawling page: http://www.nutechventures.org/marketing/       valid
Crawling page: http://www.nutechventures.org/recruitment/       valid
Crawling page: https://litronlabs.com/Resources/Events-and-Announcements       valid
Crawling page: https://litronlabs.com/Resources/Publications/In-Vivo-MicroFlow-Kits/Flow-cytometric-method-for-scoring-rat-liver-micro       valid
Crawling page: https://www.bosch.com/careers/       valid
Crawling page: https://litronlabs.com/Resources/Publications       valid
Crawling page: https://litronlabs.com/Resources/Publications/In-Vivo-Micronucleus/Oral-exposure-to-commercially-available-coal-tar-b       valid
Crawling page: https://www.bosch.com/licenses-and-patents/       valid
Crawling page: https://litronlabs.com/Resources/Downloads       valid
Crawling page: http://www.nutechventures.org/intern-program/       valid
Crawling page: http://www.nutechventures.org/disclosures/       valid
Crawling page: http://www.nutechventures.org/a-system-to-support-innovation/       valid
Crawling page: http://www.nutechventures.org/evaluation/       valid
Crawling page: https://litronlabs.com/cdn-cgi/l/email-protection       valid
Crawling page: https://litronlabs.com/Resources/Featured-Publications       valid
Crawling page: http://calysta.com/terms-and-conditions/       valid
Crawling page: http://www.nutechventures.org/college-contacts/       valid
Crawling page: http://www.nutechventures.org/inventors-and-innovators-handbook/       valid
Crawling page: http://calysta.com/calystas-feedkind-protein-approved-as-ingredient-in-organic-systems-for-animal-feed/       valid
Crawling page: http://calysta.com/calysta-and-uk-partners-win-icheme-global-team-award-for-excellence-from-institution-of-chemical-engineers/       valid
Crawling page: http://calysta.com/calysta-partners-with-nofima-for-trials-to-promote-sustainable-seafood/       valid
Crawling page: http://calysta.com/media/newsletter/       valid
Crawling page: https://litronlabs.com/Login?returnurl=%2fResources%2fVideos       valid
Crawling page: http://calysta.com/media/tech-papers/       valid
Crawling page: http://calysta.com/media/media-resources/       valid
Crawling page: http://calysta.com/media/videos/       valid
Crawling page: http://calysta.com/media/media-downloads/       valid
Crawling page: http://calysta.com/media/media-coverage/       valid
Crawling page: http://calysta.com/sustainability/carbon-trust-report/       valid
Crawling page: http://calysta.com/sustainability/       valid
Crawling page: http://calysta.com/media/       valid
Crawling page: http://calysta.com/commercialization/us-manufacturing/       valid
Crawling page: http://calysta.com/commercialization/partners/       valid
Crawling page: http://calysta.com/commercialization/market-introduction-facility/       valid
Crawling page: http://calysta.com/commercialization/       valid
Crawling page: https://www.bosch.com/explore-and-experience/motorcycle-rider-safety/       valid
Crawling page: https://litronlabs.com/Products       valid
Crawling page: https://litronlabs.com/       valid
Crawling page: https://litronlabs.com/Ordering2018-11-11 03:38:41 [scrapy.extensions.logstats] INFO: Crawled 1900 pages (at 12 pages/min), scraped 1697 items (at 12 items/min)
2018-11-11 03:39:40 [scrapy.extensions.logstats] INFO: Crawled 1902 pages (at 2 pages/min), scraped 1705 items (at 8 items/min)
2018-11-11 03:39:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://research.synaptic.co.uk/SynapticResearch/login.asp?t=64024&page=/Default.asp?>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 03:39:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://formulaplastics.com/single-project.html>: HTTP status code is not handled or not allowed
/bin/sh: 1: kill: No such process

/bin/sh: 1: kill: No such process

2018-11-11 03:40:30 [scrapy.extensions.logstats] INFO: Crawled 1921 pages (at 19 pages/min), scraped 1711 items (at 6 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 03:42:03 [scrapy.extensions.logstats] INFO: Crawled 1938 pages (at 17 pages/min), scraped 1722 items (at 11 items/min)
2018-11-11 03:42:24 [scrapy.extensions.logstats] INFO: Crawled 1938 pages (at 0 pages/min), scraped 1726 items (at 4 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 03:43:28 [scrapy.extensions.logstats] INFO: Crawled 1953 pages (at 15 pages/min), scraped 1736 items (at 10 items/min)
2018-11-11 03:44:22 [scrapy.extensions.logstats] INFO: Crawled 1957 pages (at 4 pages/min), scraped 1746 items (at 10 items/min)
2018-11-11 03:45:26 [scrapy.extensions.logstats] INFO: Crawled 1969 pages (at 12 pages/min), scraped 1758 items (at 12 items/min)
2018-11-11 03:46:23 [scrapy.extensions.logstats] INFO: Crawled 1980 pages (at 11 pages/min), scraped 1769 items (at 11 items/min)
2018-11-11 03:47:27 [scrapy.extensions.logstats] INFO: Crawled 1996 pages (at 16 pages/min), scraped 1781 items (at 12 items/min)
2018-11-11 03:48:27 [scrapy.extensions.logstats] INFO: Crawled 1999 pages (at 3 pages/min), scraped 1789 items (at 8 items/min)
2018-11-11 03:49:32 [scrapy.extensions.logstats] INFO: Crawled 2014 pages (at 15 pages/min), scraped 1801 items (at 12 items/min)
       valid
Crawling page: https://litronlabs.com/About-Us       valid
Crawling page: https://litronlabs.com/Resources/Publications/In-Vitro-MultiFlow-Kits/Comparative-Genotoxicity-of-TEMPO-and-3-of-Its-Der       valid
Crawling page: https://litronlabs.com/Contact       valid
Crawling page: https://litronlabs.com/Products/In-Vitro-High-Content-Assays       valid
Crawling page: https://litronlabs.com/Services/In-Vivo-Micronucleus-Scoring       valid
Crawling page: http://calysta.com/feedkind/       valid
Crawling page: http://calysta.com/company/locations/       valid
Crawling page: http://calysta.com/company/investors/       valid
Crawling page: http://calysta.com/platform/       valid
Crawling page: https://litronlabs.com/Services/In-Vivo-Pig-a-Gene-Mutation-Scoring       valid
Crawling page: https://litronlabs.com/Services       valid
Crawling page: https://www.smartplanettech.com/artwork       valid
Crawling page: http://www.dexerials.jp/en/       valid
Crawling page: https://www.smartplanettech.com/artwork/       valid
Crawling page: http://calysta.com/       valid
Crawling page: https://www.ndeg.com/privacy-policy       valid
Crawling page: https://www.smartplanettech.com/preferred-vendors/       valid
Crawling page: https://www.smartplanettech.com/repulping-and-recyclability-report-for-paperboard-with-earthcoating/       valid
Crawling page: https://www.ndeg.com       valid
Crawling page: https://www.cerionadvancedmaterials.com       valid
Crawling page: http://www.ansunbiopharma.com/careers/       valid
Crawling page: http://www.ansunbiopharma.com/contact-us/       valid
Crawling page: https://www.ndeg.com/shop       valid
Crawling page: https://global.canon/en/corporate/information/group/gr01.html       valid
Crawling page: https://www.ndeg.com/about       valid
Crawling page: https://www.ndeg.com/contact       valid
Crawling page: https://global.canon/en/terms/       valid
Crawling page: https://global.canon/en/sitemap/       valid
Crawling page: https://global.canon/en/privacy/       valid
Crawling page: https://global.canon/en/corporate/information/group/       valid
Crawling page: https://www.tok.co.jp/eng       valid
Crawling page: https://global.canon/en/socialmedia/       valid
Crawling page: https://global.canon/en/rssfeed/       valid
Crawling page: https://global.canon/en/event/rwc2019/index.html       valid
Crawling page: https://global.canon/en/product/       valid
Crawling page: http://calysta.com/company/advisory-board/       valid
Crawling page: https://global.canon/en/news/2018/20181109a.html       valid
Crawling page: https://global.canon/en/news/2018/20181105.html       valid
Crawling page: https://global.canon/en/environment/       valid
Crawling page: https://global.canon/en/technology/interview/eos-kiss/       valid
Crawling page: https://global.canon/en/procurement/contact.html       valid
Crawling page: https://global.canon/en.html       valid
Crawling page: https://global.canon/en/ad/eosrsystem/index.html       valid
Crawling page: https://global.canon/en/news/2018/20181109-2a.html       valid
Crawling page: http://calysta.com/contacts/       valid
Crawling page: http://calysta.com/careers/       valid
Crawling page: https://global.canon/en/procurement/edi.html       valid
Crawling page: https://global.canon/en/procurement/green04.html       valid
Crawling page: https://global.canon/en/procurement/green03.html       valid
Crawling page: https://global.canon/en/procurement/green02.html       valid
Crawling page: https://global.canon/en/procurement/green.html       valid
Crawling page: https://global.canon/en/procurement/social.html       valid
Crawling page: https://global.canon/en/procurement/procedure.html       valid
Crawling page: https://global.canon/en/procurement/policy.html       valid
Crawling page: https://global.canon/en/design/ud/guide/feelings.html       valid
Crawling page: https://global.canon/en/design/ud/approach.html       valid
Crawling page: https://global.canon/en/design/award/       valid
Crawling page: https://global.canon/en/design/ud/guide/recognition.html       valid
Crawling page: https://global.canon/en/design/ud/guide/       valid
Crawling page: https://global.canon/en/design/ud/guide/operation.html       valid
Crawling page: https://global.canon/en/design/ud/idea.html       valid
Crawling page: https://global.canon/en/design/ud/guide/audiovisual.html       valid
Crawling page: https://global.canon/en/design/ud/message.html       valid
Crawling page: https://global.canon/en/design/frontline/eos-c300-04.html       valid
Crawling page: https://global.canon/en/design/frontline/eos-c300-05.html       valid
Crawling page: https://global.canon/en/design/ud/       valid
Crawling page: https://global.canon/en/design/frontline/eos-c300-01.html       valid
Crawling page: https://global.canon/en/design/frontline/eos-c300-03.html       valid
Crawling page: https://global.canon/en/design/frontline/       valid
Crawling page: https://global.canon/en/design/frontline/eos-c300-02.html       valid
Crawling page: https://global.canon/en/ir/share/name.html       valid
Crawling page: https://global.canon/en/ir/menseki.html       valid
Crawling page: https://global.canon/en/design/philosophy/       valid
Crawling page: https://global.canon/en/ir/news/       valid
Crawling page: https://global.canon/en/ir/share/dividend.html       valid
Crawling page: https://global.canon/en/ir/share/analyst.html       valid
Crawling page: https://global.canon/en/ir/share/meeting.html       valid
Crawling page: https://global.canon/en/ir/calendar/       valid
Crawling page: https://global.canon/en/ir/library/rating.html       valid
Crawling page: https://global.canon/en/ir/library/form_sd.html       valid
Crawling page: https://global.canon/en/ir/share/       valid
Crawling page: https://global.canon/en/ir/library/report.html       valid
Crawling page: https://global.canon/en/ir/library/annual.html       valid
Crawling page: https://global.canon/en/ir/library/form20f.html       valid
Crawling page: https://global.canon/en/ir/library/results.html       valid
Crawling page: https://global.canon/en/ir/finance/expenses.html       valid
Crawling page: https://global.canon/en/ir/finance/historical.html       valid
Crawling page: https://global.canon/en/ir/finance/cash-flows.html       valid
Crawling page: https://global.canon/en/ir/library/       valid
Crawling page: https://global.canon/en/ir/finance/assets-liabilities.html       valid
Crawling page: https://global.canon/en/ir/finance/area.html       valid
Crawling page: https://global.canon/en/ir/finance/business-unit.html       valid
Crawling page: https://global.canon/en/ir/finance/indicators.html       valid
Crawling page: https://global.canon/en/ir/finance/       valid
Crawling page: https://global.canon/en/ir/esg.html       valid
Crawling page: https://global.canon/en/ir/finance/highlight.html       valid
Crawling page: https://global.canon/en/ir/business.html       valid
Crawling page: https://global.canon/en/corporate/logo/       valid
Crawling page: https://global.canon/en/ir/strategies/       valid
Crawling page: https://global.canon/en/ir/strategies/governance.html       valid
Crawling page: https://global.canon/en/ir/strategies/risk.html       valid
Crawling page: https://global.canon/en/corporate/pdf/       valid
Crawling page: https://global.canon/en/corporate/history/04.html       valid
Crawling page: https://global.canon/en/corporate/history/03.html       valid
Crawling page: https://global.canon/en/corporate/history/05.html       valid
Crawling page: https://global.canon/en/corporate/history/02.html       valid
Crawling page: https://global.canon/en/corporate/history/01.html       valid
Crawling page: https://global.canon/en/corporate/history/       valid
Crawling page: https://global.canon/en/corporate/result/summary.html       valid
Crawling page: https://global.canon/en/corporate/result/       valid
Crawling page: https://global.canon/en/corporate/result/10years_group.html       valid
Crawling page: https://global.canon/en/corporate/information/group/gr04.html       valid
Crawling page: https://global.canon/en/corporate/information/location.html       2018-11-11 03:50:29 [scrapy.extensions.logstats] INFO: Crawled 2024 pages (at 10 pages/min), scraped 1812 items (at 11 items/min)
2018-11-11 03:51:32 [scrapy.extensions.logstats] INFO: Crawled 2036 pages (at 12 pages/min), scraped 1824 items (at 12 items/min)
2018-11-11 03:52:24 [scrapy.extensions.logstats] INFO: Crawled 2046 pages (at 10 pages/min), scraped 1834 items (at 10 items/min)
2018-11-11 03:53:28 [scrapy.extensions.logstats] INFO: Crawled 2057 pages (at 11 pages/min), scraped 1846 items (at 12 items/min)
2018-11-11 03:54:23 [scrapy.extensions.logstats] INFO: Crawled 2061 pages (at 4 pages/min), scraped 1854 items (at 8 items/min)
2018-11-11 03:55:25 [scrapy.extensions.logstats] INFO: Crawled 2073 pages (at 12 pages/min), scraped 1862 items (at 8 items/min)
2018-11-11 03:56:35 [scrapy.extensions.logstats] INFO: Crawled 2084 pages (at 11 pages/min), scraped 1873 items (at 11 items/min)
2018-11-11 03:57:24 [scrapy.extensions.logstats] INFO: Crawled 2095 pages (at 11 pages/min), scraped 1882 items (at 9 items/min)
2018-11-11 03:58:41 [scrapy.extensions.logstats] INFO: Crawled 2107 pages (at 12 pages/min), scraped 1896 items (at 14 items/min)
2018-11-11 03:59:45 [scrapy.extensions.logstats] INFO: Crawled 2114 pages (at 7 pages/min), scraped 1907 items (at 11 items/min)
2018-11-11 04:00:22 [scrapy.extensions.logstats] INFO: Crawled 2120 pages (at 6 pages/min), scraped 1912 items (at 5 items/min)
valid
Crawling page: https://global.canon/en/corporate/information/group/gr02.html       valid
Crawling page: https://global.canon/en/corporate/information/organization.html       valid
Crawling page: https://global.canon/en/corporate/information/group/gr03.html       valid
Crawling page: https://global.canon/en/corporate/information/executive.html       valid
Crawling page: https://global.canon/en/corporate/information/profile.html       valid
Crawling page: https://global.canon/en/contact/environment/environment-form-e.html       valid
Crawling page: https://global.canon/en/corporate/information/       valid
Crawling page: https://global.canon/en/environment/sitemap.html       valid
Crawling page: https://global.canon/en/environment/lca/index.html       valid
Crawling page: https://global.canon/ctc/       valid
Crawling page: https://global.canon/en/environment/news/       valid
Crawling page: https://global.canon/en/environment/products/index.html       valid
Crawling page: https://global.canon/en/environment/bird-branch/       valid
Crawling page: https://global.canon/en/environment/cartridge-sp/index.html       valid
Crawling page: https://global.canon/en/environment/action-for-green/index.html       valid
Crawling page: https://global.canon/en/environment/data/index.html       valid
Crawling page: https://global.canon/en/environment/awards/index.html       valid
Crawling page: https://global.canon/en/environment/global/earthhour/2016/index.html       valid
Crawling page: https://global.canon/en/environment/global/earthhour/2017/index.html       valid
Crawling page: https://global.canon/en/environment/global/earthhour/2018/index.html       valid
Crawling page: https://global.canon/en/environment/global/earthday/2015/index.html       valid
Crawling page: https://global.canon/en/environment/global/earthday/2016/index.html       valid
Crawling page: https://global.canon/en/environment/global/earthday/2017/index.html       valid
Crawling page: https://global.canon/en/environment/global/earthday/2018/index.html       valid
Crawling page: https://global.canon/en/environment/global/       valid
Crawling page: https://global.canon/en/environment/biodiversity/activities.html       valid
Crawling page: https://global.canon/en/environment/biodiversity/policy.html       valid
Crawling page: https://global.canon/en/environment/biodiversity/       valid
Crawling page: https://global.canon/en/environment/chemical-substance/production.html       valid
Crawling page: https://global.canon/en/environment/chemical-substance/product.html       valid
Crawling page: https://global.canon/en/environment/chemical-substance/       valid
Crawling page: https://global.canon/en/environment/circulation/production.html       valid
Crawling page: https://global.canon/en/environment/circulation/recycle.html       valid
Crawling page: https://global.canon/en/environment/circulation/remanufacturing.html       valid
Crawling page: https://global.canon/en/environment/circulation/policy.html       valid
Crawling page: https://global.canon/en/environment/circulation/       valid
Crawling page: https://global.canon/en/environment/low-carbon/production.html       valid
Crawling page: https://global.canon/en/environment/low-carbon/product.html       valid
Crawling page: https://global.canon/en/environment/low-carbon/       valid
Crawling page: https://global.canon/en/environment/sdgs/       valid
Crawling page: https://global.canon/en/environment/materiality/       valid
Crawling page: https://www.tok.co.jp/eng/csr/investors.html       valid
Crawling page: https://www.tok.co.jp/eng/csr/message.html       valid
Crawling page: https://www.tok.co.jp/eng/ir/1       valid
Crawling page: https://www.tok.co.jp/eng/csr/philosophy.html       valid
Crawling page: https://www.tok.co.jp/eng/ir/calender       valid
Crawling page: https://www.tok.co.jp/eng/ir/library       valid
Crawling page: https://www.tok.co.jp/eng/ir/movie       valid
Crawling page: https://www.tok.co.jp/eng/ir/investor.html       valid
Crawling page: https://www.tok.co.jp/eng/csr/env-activity/policy.html       valid
Crawling page: https://www.tok.co.jp/eng/tech/nanoimprint.html       valid
Crawling page: https://www.tok.co.jp/eng/csr/community/social.html       valid
Crawling page: https://www.tok.co.jp/eng/csr/employees/rights.html       valid
Crawling page: https://global.canon/en/environment/lifecycle/       valid
Crawling page: https://global.canon/en/environment/vision/       valid
Crawling page: https://global.canon/en/environment/index.html       valid
Crawling page: https://global.canon/en/contact/csr/csr-form-e.html       valid
Crawling page: https://global.canon/en/csr/news/       valid
Crawling page: https://global.canon/en/csr/search/sitemap.html       valid
Crawling page: https://www.tok.co.jp/eng/ir/contact/faq       valid
Crawling page: https://www.tok.co.jp/eng/ir/shareholders/shm.html       valid
Crawling page: https://www.tok.co.jp/eng/company/access       valid
Crawling page: https://www.tok.co.jp/eng/company/associate.html       valid
Crawling page: https://www.sanken-ele.co.jp/en/privacy/privacy.htm       valid
Crawling page: https://global.canon/en/csr/search/rba.html       valid
Crawling page: https://global.canon/en/csr/search/gri.html       valid
Crawling page: https://global.canon/en/csr/conflict/policy.html       valid
Crawling page: https://global.canon/en/csr/search/stakeholder.html       valid
Crawling page: https://global.canon/en/csr/search/keyword.html       valid
Crawling page: https://global.canon/en/csr/management/intellectual-property.html       valid
Crawling page: https://global.canon/en/csr/management/brand.html       valid
Crawling page: https://global.canon/en/csr/conflict/       valid
Crawling page: https://global.canon/en/csr/management/stakeholder.html       valid
Crawling page: https://www.tok.co.jp/eng/ir/irnews/2016       valid
Crawling page: https://www.tok.co.jp/eng/ir/f-data/year-c.html       valid
Crawling page: https://global.canon/en/csr/management/       valid
Crawling page: https://global.canon/en/csr/management/risk.html       valid
Crawling page: https://global.canon/en/csr/management/supply-chain.html       valid
Crawling page: https://global.canon/en/csr/management/governance.html       valid
Crawling page: https://global.canon/en/csr/product/quality.html       valid
Crawling page: https://global.canon/en/csr/product/       valid
Crawling page: https://global.canon/en/csr/product/usability.html       valid
Crawling page: https://global.canon/en/csr/product/safety.html       valid
Crawling page: https://global.canon/en/csr/society/art-culture-sports.html       valid
Crawling page: https://global.canon/en/csr/society/education.html       valid
Crawling page: https://global.canon/en/csr/society/community.html       valid
Crawling page: https://global.canon/en/csr/society/welfare-community.html       valid
Crawling page: https://global.canon/en/csr/society/environment.html       valid
Crawling page: https://global.canon/en/csr/society/aid-relief.html       valid
Crawling page: https://global.canon/en/csr/society/       valid
Crawling page: https://global.canon/en/csr/labor/data.html       valid
Crawling page: https://www.tok.co.jp/eng/company/organization.html       valid
Crawling page: https://www.tok.co.jp/eng/ir/info/stock.html       valid
Crawling page: https://www.tok.co.jp/eng/company/director.html       valid
Crawling page: https://www.tok.co.jp/eng/company/history.html       valid
Crawling page: https://global.canon/en/csr/labor/growth-development.html       valid
Crawling page: https://global.canon/en/csr/labor/safety-health.html       valid
Crawling page: https://global.canon/en/csr/labor/diversity.html       valid
Crawling page: https://www.tok.co.jp/eng/company/outline.html       valid
Crawling page: https://www.tok.co.jp/eng/company/governance/corporate-governance.html       valid
Crawling page: https://www.tok.co.jp/eng/company/network/internal.html       valid
Crawling page: https://www.tok.co.jp/eng/company/greeting.html       valid
Crawling page: https://www.tok.co.jp/speng       valid
Crawling page: https://www.tok.co.jp/eng/company/movie.html2018-11-11 04:01:34 [scrapy.extensions.logstats] INFO: Crawled 2130 pages (at 10 pages/min), scraped 1922 items (at 10 items/min)
2018-11-11 04:02:26 [scrapy.extensions.logstats] INFO: Crawled 2136 pages (at 6 pages/min), scraped 1929 items (at 7 items/min)
2018-11-11 04:03:28 [scrapy.extensions.logstats] INFO: Crawled 2152 pages (at 16 pages/min), scraped 1937 items (at 8 items/min)
2018-11-11 04:04:29 [scrapy.extensions.logstats] INFO: Crawled 2161 pages (at 9 pages/min), scraped 1945 items (at 8 items/min)
2018-11-11 04:05:39 [scrapy.extensions.logstats] INFO: Crawled 2165 pages (at 4 pages/min), scraped 1954 items (at 9 items/min)
2018-11-11 04:06:25 [scrapy.extensions.logstats] INFO: Crawled 2174 pages (at 9 pages/min), scraped 1960 items (at 6 items/min)
2018-11-11 04:07:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.sanken-ele.co.jp/en/prod/powersp/sw/index.htm> (referer: https://www.sanken-ele.co.jp/en/index.php)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 54, in replace
    return Response.replace(self, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 81, in replace
    return cls(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 22, in __init__
    self._set_body(body)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
  File "/usr/lib/python3.6/encodings/cp1252.py", line 12, in encode
    return codecs.charmap_encode(input,errors,encoding_table)
UnicodeEncodeError: 'charmap' codec can't encode character '\u25ef' in position 7105: character maps to <undefined>
2018-11-11 04:07:25 [scrapy.extensions.logstats] INFO: Crawled 2178 pages (at 4 pages/min), scraped 1969 items (at 9 items/min)
2018-11-11 04:07:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.sanken-ele.co.jp/en/tousika/overview.htm> (referer: https://www.sanken-ele.co.jp/en/index.php)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 54, in replace
    return Response.replace(self, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 81, in replace
    return cls(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 22, in __init__
    self._set_body(body)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
  File "/usr/lib/python3.6/encodings/cp1252.py", line 12, in encode
    return codecs.charmap_encode(input,errors,encoding_table)
UnicodeEncodeError: 'charmap' codec can't encode character '\x8f' in position 4346: character maps to <undefined>
2018-11-11 04:08:37 [scrapy.extensions.logstats] INFO: Crawled 2190 pages (at 12 pages/min), scraped 1980 items (at 11 items/min)
2018-11-11 04:08:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tok.co.jp> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 04:09:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.sanken-ele.co.jp/en/prod/library/lib_sw.htm>: HTTP status code is not handled or not allowed
2018-11-11 04:09:29 [scrapy.extensions.logstats] INFO: Crawled 2203 pages (at 13 pages/min), scraped 1987 items (at 7 items/min)
2018-11-11 04:11:24 [scrapy.extensions.logstats] INFO: Crawled 2207 pages (at 4 pages/min), scraped 1991 items (at 4 items/min)
2018-11-11 04:13:39 [scrapy.extensions.logstats] INFO: Crawled 2213 pages (at 6 pages/min), scraped 1996 items (at 5 items/min)
2018-11-11 04:14:23 [scrapy.extensions.logstats] INFO: Crawled 2213 pages (at 0 pages/min), scraped 1999 items (at 3 items/min)
2018-11-11 04:15:35 [scrapy.extensions.logstats] INFO: Crawled 2232 pages (at 19 pages/min), scraped 2006 items (at 7 items/min)
       valid
Crawling page: https://www.tok.co.jp/eng/products/venture.html       valid
Crawling page: https://www.tok.co.jp/eng/products/newfield/list       valid
Crawling page: https://www.tok.co.jp/eng/products/newfield/equipment       valid
Crawling page: https://www.tok.co.jp/eng/products/display/equipment       valid
Crawling page: https://www.tok.co.jp/eng/products/display/list       valid
Crawling page: https://www.tok.co.jp/eng/products/3d/equipment       valid
Crawling page: https://www.tok.co.jp/eng/products/3d/list       valid
Crawling page: https://www.tok.co.jp/eng/products/display       valid
Crawling page: https://www.tok.co.jp/eng/products/3d       valid
Crawling page: https://www.tok.co.jp/eng/products/semiconductor/equipment       valid
Crawling page: https://www.tok.co.jp/eng/products/package/list       valid
Crawling page: https://www.tok.co.jp/eng/products/semiconductor/list       valid
Crawling page: https://www.tok.co.jp/eng/products/package       valid
Crawling page: https://www.tok.co.jp/eng/products/package/equipment       valid
Crawling page: https://www.tok.co.jp/eng/products/semiconductor       valid
Crawling page: https://www.tok.co.jp/eng/ir/library/account       valid
Crawling page: https://www.tok.co.jp/eng/products/photolithography       valid
Crawling page: https://www.tok.co.jp/eng/ir/library/annual       valid
Crawling page: https://www.tok.co.jp/eng/ir/library/note       valid
Crawling page: https://www.tok.co.jp/eng/csr/report/report2018       valid
Crawling page: https://www.tok.co.jp/eng/exhibition/2013       valid
Crawling page: https://www.tok.co.jp/eng/business/technology.html       valid
Crawling page: https://www.tok.co.jp/eng/business/future.html       valid
Crawling page: https://www.tok.co.jp/eng/products/newfield       valid
Crawling page: https://www.cerionadvancedmaterials.com/national-nanotechnology-initiative-webinar-technology-pathways-toward-commercializing-nanotechnology/       valid
Crawling page: https://www.tok.co.jp/eng/business/nanometre.html       valid
Crawling page: https://www.cerionadvancedmaterials.com/advances-in-nanotherapeutics-spotlight-on-cerium-dioxide/       valid
Crawling page: https://www.cerionadvancedmaterials.com/optical-coatings/       valid
Crawling page: https://www.cerionadvancedmaterials.com/specialty-fabrics-review-magazine-nonwovens-in-the-automotive-industry/       valid
Crawling page: https://www.tok.co.jp/eng/inquiry       valid
Crawling page: https://www.tok.co.jp/eng/csr       valid
Crawling page: https://www.tok.co.jp/eng/rss.xml       valid
Crawling page: https://www.tok.co.jp/eng/company       valid
Crawling page: https://www.cerionadvancedmaterials.com/trend-reports/       valid
Crawling page: https://www.cerionadvancedmaterials.com/contact/       valid
Crawling page: https://www.cerionadvancedmaterials.com/materials/nanocatalyst/       valid
Crawling page: https://www.cerionadvancedmaterials.com/industrial-scale-manufacturing/       valid
Crawling page: https://www.cerionadvancedmaterials.com/custom-rd/       valid
Crawling page: https://www.cerionadvancedmaterials.com/materials/       valid
Crawling page: https://www.cerionadvancedmaterials.com/technology/       valid
Crawling page: https://www.cerionadvancedmaterials.com/about/news/       valid
Crawling page: https://www.cerionadvancedmaterials.com/about/published-papers/       valid
Crawling page: https://www.cerionadvancedmaterials.com/about/our-team/board/       valid
Crawling page: https://www.cerionadvancedmaterials.com/about/our-team/management/       valid
Crawling page: https://www.cerionadvancedmaterials.com/work/       valid
Crawling page: https://www.cerionadvancedmaterials.com/about/       valid
Crawling page: https://www.sanken-ele.co.jp/en/sitemap/sitemap.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/sitepolicy/sitepolicy.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/contact/note_1504.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/library/index.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/powersp/filt/index.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/powersp/strob/index.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/powersp/invert/index.htm       valid
Crawling page: https://www.tok.co.jp/eng/news/2018       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/powersp/ups/index.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/powersp/sw/index.htm       Crawling page: https://www.sanken-ele.co.jp/en/tousika/contact/index.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/powersp/ch/index.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/tousika/hi_light01.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/tousika/calendar01.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/news/ir.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/tousika/overview.htm       Crawling page: https://www.sanken-ele.co.jp/en/kankyo/00.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/corp/success.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/fina/library.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/corp/map.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/corp/corp03.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/corp/corp08.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/corp/corp02.htm       valid
Crawling page: https://www.tok.co.jp       Crawling page: https://www.sanken-ele.co.jp/en/corp/corp07.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/library/lib_dc.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/library/lib_strob.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/library/lib_filt.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/library/lib_invert.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/library/lib_etca.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/corp/corp01.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/library/lib_adp.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/library/lib_ups.htm       valid
Crawling page: https://www.sanken-ele.co.jp/ch/       valid
Crawling page: http://in.bgu.ac.il/en/Pages/accessibility.aspx       valid
Crawling page: https://www.sanken-ele.co.jp/en/csr/index.htm       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/Intellectual-Property-Patenting-Basics.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/Research-Funds.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/Chief-Scientist-Programs-.aspx       valid
Crawling page: http://in.bgu.ac.il/en/Pages/news/PayPal.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/pages/news/Dojo%20by%20BullGuard%20and%20BGN%20Technologies%20partner%20to%20create%20advanced%20IoT%20security%20tech.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/pages/news/Orgenesis%20Announces%20Collaboration%20with%20Ben-Gurion%20University.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/pages/news/Researchers%20from%20Ben-Gurion%20University%20and%20Cincinnati%20Children's%20Hospital%20Introduce%20Novel%20Digital%20Health%20Platform%20for%20Predicting%20Hemodynamic%20Instability%20in%20Intensive%20Care%20Patients.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/ContactUs.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/researchers.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/industry.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/Entrepreneurship.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/technologies.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/Innovation-Hubs.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/Startups.aspx       valid
Crawling page: https://global.canon/en/csr/labor/       valid
Crawling page: https://global.canon/en/csr/labor/human-rights.html       valid
Crawling page: 2018-11-11 04:17:11 [scrapy.extensions.logstats] INFO: Crawled 2237 pages (at 5 pages/min), scraped 2014 items (at 8 items/min)
2018-11-11 04:18:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <401 http://in.bgu.ac.il/en/bgn/_layouts/15/Authenticate.aspx?Source=%2Fen%2Fbgn%2FPages%2Fdefault%2Easpx>: HTTP status code is not handled or not allowed
2018-11-11 04:18:21 [scrapy.extensions.logstats] INFO: Crawled 2239 pages (at 2 pages/min), scraped 2021 items (at 7 items/min)
2018-11-11 04:18:44 [scrapy.extensions.logstats] INFO: Crawled 2241 pages (at 2 pages/min), scraped 2025 items (at 4 items/min)
2018-11-11 04:19:30 [scrapy.extensions.logstats] INFO: Crawled 2249 pages (at 8 pages/min), scraped 2033 items (at 8 items/min)
2018-11-11 04:20:33 [scrapy.extensions.logstats] INFO: Crawled 2263 pages (at 14 pages/min), scraped 2045 items (at 12 items/min)
2018-11-11 04:21:41 [scrapy.extensions.logstats] INFO: Crawled 2276 pages (at 13 pages/min), scraped 2057 items (at 12 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 04:23:03 [scrapy.extensions.logstats] INFO: Crawled 2289 pages (at 13 pages/min), scraped 2070 items (at 13 items/min)
2018-11-11 04:23:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <418 http://www.ansunbiopharma.com/development/>: HTTP status code is not handled or not allowed
2018-11-11 04:23:42 [scrapy.extensions.logstats] INFO: Crawled 2292 pages (at 3 pages/min), scraped 2076 items (at 6 items/min)
2018-11-11 04:24:34 [scrapy.extensions.logstats] INFO: Crawled 2302 pages (at 10 pages/min), scraped 2085 items (at 9 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 04:25:29 [scrapy.extensions.logstats] INFO: Crawled 2310 pages (at 8 pages/min), scraped 2094 items (at 9 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 04:26:37 [scrapy.extensions.logstats] INFO: Crawled 2324 pages (at 14 pages/min), scraped 2107 items (at 13 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 04:27:24 [scrapy.extensions.logstats] INFO: Crawled 2337 pages (at 13 pages/min), scraped 2117 items (at 10 items/min)
https://global.canon/en/csr/new-value/innovation.html       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/News-.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/about-bgu.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/news.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/pages/news-list.aspx       valid
Crawling page: https://global.canon/en/csr/environment/       valid
Crawling page: https://global.canon/en/csr/new-value/health.html       valid
Crawling page: https://global.canon/en/csr/new-value/safe-and-secure.html       valid
Crawling page: https://global.canon/en/csr/new-value/       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/staff.aspx       valid
Crawling page: http://in.bgu.ac.il/en/BGN/Pages/default.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/board.aspx       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/about.aspx       valid
Crawling page: https://global.canon/en/csr/for-earth/low-carbon.html       valid
Crawling page: https://global.canon/en/csr/for-society/health.html       valid
Crawling page: https://global.canon/en/csr/for-society/secure.html       valid
Crawling page: https://global.canon/en/csr/for-earth/circulation.html       valid
Crawling page: https://global.canon/en/csr/strategy/       valid
Crawling page: https://global.canon/en/csr/message/       valid
Crawling page: https://global.canon/en/csr/sdgs/       valid
Crawling page: https://global.canon/en/csr/policy/       valid
Crawling page: https://global.canon/en/product/indtech/fpd/spe813.html       valid
Crawling page: https://global.canon/en/product/indtech/fpd/sph803h763.html       valid
Crawling page: https://global.canon/en/csr/report/?csr-mobile-nv       valid
Crawling page: https://global.canon/en/csr/       valid
Crawling page: https://global.canon/en/product/indtech/semicon/fpa5510iv.html       valid
Crawling page: https://global.canon/en/product/indtech/fpd/index.html       valid
Crawling page: https://global.canon/en/product/indtech/semicon/fpa3030i5.html       valid
Crawling page: https://global.canon/en/product/indtech/semicon/fpa5520iv.html       valid
Crawling page: https://global.canon/en/product/indtech/semicon/fpa3030ex6.html       valid
Crawling page: https://global.canon/en/product/indtech/semicon/fpa5550iz2.html       valid
Crawling page: https://global.canon/en/product/indtech/semicon/fpa6300esw.html       valid
Crawling page: https://global.canon/en/product/indtech/semicon/fpa5510ix.html       valid
Crawling page: https://global.canon/en/product/indtech/semicon/index.html       valid
Crawling page: https://global.canon/en/vision/new-business/commercial-printing.html       valid
Crawling page: https://global.canon/en/vision/new-business/industry.html       valid
Crawling page: https://global.canon/en/vision/new-business/nvs.html       valid
Crawling page: http://www.ansunbiopharma.com/news/       valid
Crawling page: https://global.canon/en/vision/new-business/healthcare.html       valid
Crawling page: https://global.canon/en/c-museum/gallery/2018.html?gnavi-pup       valid
Crawling page: https://global.canon/en/eflens/       valid
Crawling page: http://www.ansunbiopharma.com/our-team/       valid
Crawling page: http://www.ansunbiopharma.com/meet-the-team/       valid
Crawling page: https://global.canon/en/ad/wild/       valid
Crawling page: https://global.canon/en/procurement/       valid
Crawling page: http://www.ansunbiopharma.com/publications/       valid
Crawling page: https://global.canon/en/imaging/       valid
Crawling page: https://global.canon/en/v-square/       valid
Crawling page: https://global.canon/en/c-museum/index.html?gnavi-rec       valid
Crawling page: http://www.ansunbiopharma.com/paradase-treatment/       valid
Crawling page: http://www.ansunbiopharma.com/fludase-treatment/       valid
Crawling page: http://www.ansunbiopharma.com/inactivate-viral-receptor/       valid
Crawling page: https://global.canon/en/mfg-quality/       valid
Crawling page: https://global.canon/en/design/       valid
Crawling page: https://global.canon/en/ir/       valid
Crawling page: https://global.canon/en/corporate/       valid
Crawling page: http://www.ansunbiopharma.com/fludase-and-paradase/       valid
Crawling page: https://global.canon/en/newcosmos/index.html?gnavi-rec       valid
Crawling page: https://global.canon/en/jr-photographers/index.html?gnavi-rec       valid
Crawling page: http://in.bgu.ac.il/en/bgn/Pages/default.aspx       valid
Crawling page: https://global.canon/en/about/       valid
Crawling page: https://global.canon/en/csr/report/index.html?gnavi-pup       valid
Crawling page: http://www.ansunbiopharma.com/clinical-development/       valid
Crawling page: https://global.canon/en/tsuzuri/index.html?gnavi-rec       valid
Crawling page: https://global.canon/en/environment/bird-branch/index.html?gnavi-rec       valid
Crawling page: https://global.canon/en/environment/action-for-green/index.html?gnavi-rec       valid
Crawling page: https://global.canon/en/v-square/index03.html?gnavi-rec       valid
Crawling page: http://www.ansunbiopharma.com/compassionate-use-policy/       valid
Crawling page: https://global.canon/en/csr/report/index.html?gnavi-rec       valid
Crawling page: https://global.canon/en/csr/index.html?gnavi       valid
Crawling page: https://global.canon/en/environment/index.html?gnavi       valid
Crawling page: https://global.canon/en/news/       valid
Crawling page: https://global.canon/en/business/professional.html       valid
Crawling page: http://www.ansunbiopharma.com       valid
Crawling page: https://global.canon/en/business/personal.html       valid
Crawling page: https://global.canon/en/business/global-marketing.html       valid
Crawling page: https://global.canon/en/product/indtech/       valid
Crawling page: https://global.canon/en/business/office.html       valid
Crawling page: https://global.canon/en/business/industry.html       valid
Crawling page: https://global.canon/en/business/       valid
Crawling page: https://global.canon/en/vision/new-business/       valid
Crawling page: https://global.canon/en/vision/greeting.html       valid
Crawling page: https://www.sanken-ele.co.jp/en/index.php       valid
Crawling page: https://global.canon/en/vision/philosophy.html       valid
Crawling page: https://global.canon/en/vision/       valid
Crawling page: https://global.canon/en/vision/strategies.html       valid
Crawling page: https://global.canon/en/sustainability/       valid
Crawling page: https://global.canon/en/business/index.html       valid
Crawling page: https://global.canon/en/about/index.html       valid
Crawling page: https://global.canon/en/news/index.html       valid
Crawling page: https://global.canon/en/       valid
Crawling page: http://formulaplastics.com/contact.html       valid
Crawling page: https://global.canon/en/support/       valid
Crawling page: https://global.canon/en/vision/index.html       valid
Crawling page: https://global.canon/en/index.html       valid
Crawling page: http://formulaplastics.com/qualitypolicy.html       valid
Crawling page: http://formulaplastics.com/environmentalpolicy.html       valid
Crawling page: http://formulaplastics.com/gallery.html       valid
Crawling page: http://formulaplastics.com/about.html       valid
Crawling page: http://formulaplastics.com/quality.html       valid
Crawling page: http://formulaplastics.com/toolingmaintenance.html       valid
Crawling page: http://formulaplastics.com/secondaryoperations.html       valid
Crawling page: http://formulaplastics.com/highprecisionmolding.html       valid
Crawling page: http://formulaplastics.com/index.html       valid
Crawling page: http://formulaplastics.com/       valid
Crawling page: http://ngksparkplugs.com/home-sp       valid
Crawling page: http://ngksparkplugs.com/about-ngk       valid
Crawling page: http://ngksparkplugs.com/part-finder       valid
Crawling page: http://ngksparkplugs.com/privacy-policy       valid
Crawling page: http://ngksparkplugs.com/worldwide       valid
Crawling page: http://ngksparkplugs.com/where-to-buy       valid
Crawling page: http://ngksparkplugs.com/contact-us       valid
Crawling page:2018-11-11 04:28:39 [scrapy.extensions.logstats] INFO: Crawled 2349 pages (at 12 pages/min), scraped 2129 items (at 12 items/min)
2018-11-11 04:29:37 [scrapy.extensions.logstats] INFO: Crawled 2351 pages (at 2 pages/min), scraped 2137 items (at 8 items/min)
2018-11-11 04:30:54 [scrapy.extensions.logstats] INFO: Crawled 2363 pages (at 12 pages/min), scraped 2146 items (at 9 items/min)
2018-11-11 04:31:43 [scrapy.extensions.logstats] INFO: Crawled 2363 pages (at 0 pages/min), scraped 2150 items (at 4 items/min)
2018-11-11 04:32:48 [scrapy.extensions.logstats] INFO: Crawled 2370 pages (at 7 pages/min), scraped 2157 items (at 7 items/min)
2018-11-11 04:33:24 [scrapy.extensions.logstats] INFO: Crawled 2382 pages (at 12 pages/min), scraped 2161 items (at 4 items/min)
2018-11-11 04:35:03 [scrapy.extensions.logstats] INFO: Crawled 2382 pages (at 0 pages/min), scraped 2169 items (at 8 items/min)
2018-11-11 04:35:41 [scrapy.extensions.logstats] INFO: Crawled 2390 pages (at 8 pages/min), scraped 2173 items (at 4 items/min)
2018-11-11 04:36:27 [scrapy.extensions.logstats] INFO: Crawled 2397 pages (at 7 pages/min), scraped 2178 items (at 5 items/min)
2018-11-11 04:38:18 [scrapy.extensions.logstats] INFO: Crawled 2409 pages (at 12 pages/min), scraped 2192 items (at 14 items/min)
2018-11-11 04:38:58 [scrapy.extensions.logstats] INFO: Crawled 2409 pages (at 0 pages/min), scraped 2196 items (at 4 items/min)
2018-11-11 04:40:35 [scrapy.extensions.logstats] INFO: Crawled 2427 pages (at 18 pages/min), scraped 2210 items (at 14 items/min)
2018-11-11 04:40:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.smartplanettech.com/search>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 04:40:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cerionadvancedmaterials.com/nonwoven-textiles/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 04:40:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cerionadvancedmaterials.com/the-chemical-engineer-magazine-creating-scalable-nanomaterials-for-industry/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 04:40:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://search.global.canon/en_all/search.x>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 04:40:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://search.global.canon/en_all/search.x?q=&ie=utf8>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
/bin/sh: 1: kill: No such process

2018-11-11 04:41:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.smartplanettech.com/technology#environment>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 04:41:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.smartplanettech.com/repulping-and-recyclability-report-for-paperboard-with-earthcoating>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
/bin/sh: 1: kill: No such process

2018-11-11 04:41:31 [scrapy.extensions.logstats] INFO: Crawled 2451 pages (at 24 pages/min), scraped 2218 items (at 8 items/min)
/bin/sh: 1: kill: No such process

/bin/sh: 1: kill: No such process

2018-11-11 04:42:40 [scrapy.extensions.logstats] INFO: Crawled 2463 pages (at 12 pages/min), scraped 2229 items (at 11 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 04:43:42 [scrapy.extensions.logstats] INFO: Crawled 2472 pages (at 9 pages/min), scraped 2238 items (at 9 items/min)
 http://www.dexerials.jp/en/legal/       valid
Crawling page: http://www.dexerials.jp/en/privacy/       valid
Crawling page: http://www.dexerials.jp/en/news/2018/news18007.html       valid
Crawling page: http://www.dexerials.jp/en/news/2018/news18010.html       valid
Crawling page: http://ngksparkplugs.com/careers       valid
Crawling page: http://ngksparkplugs.com/sensor-products       valid
Crawling page: http://ngksparkplugs.com/products       valid
Crawling page: http://ngksparkplugs.com/videos       valid
Crawling page: http://www.dexerials.jp/en/news/2018/news18009.html       valid
Crawling page: http://www.dexerials.jp/en/news/       valid
Crawling page: http://www.dexerials.jp/en/sitemap.html       valid
Crawling page: http://www.dexerials.jp/en/contact/privacy.html       valid
Crawling page: http://www.dexerials.jp/en/contact/p_prem.html       valid
Crawling page: http://www.dexerials.jp/en/ir/disclaimer/       valid
Crawling page: http://www.dexerials.jp/en/ir/disclosure/       valid
Crawling page: http://ngksparkplugs.com/racing       valid
Crawling page: http://ngksparkplugs.com/ignition-products       valid
Crawling page: http://www.dexerials.jp/en/contact/e_prem.html       valid
Crawling page: http://www.dexerials.jp/en/ir/talk/       valid
Crawling page: http://www.dexerials.jp/en/ir/ir_news/       valid
Crawling page: http://www.dexerials.jp/en/ir/library/report.html       valid
Crawling page: http://www.dexerials.jp/en/ir/library/shareholders.html       valid
Crawling page: http://www.dexerials.jp/en/ir/library/index.html       valid
Crawling page: http://www.dexerials.jp/en/ir/management/risk.html       valid
Crawling page: http://www.dexerials.jp/en/ir/management/plan.html       valid
Crawling page: http://www.dexerials.jp/en/ir/management/       valid
Crawling page: http://www.dexerials.jp/en/csr/social/       valid
Crawling page: http://www.dexerials.jp/en/csr/safety/       valid
Crawling page: http://www.dexerials.jp/en/csr/social/afforest.html       valid
Crawling page: http://www.dexerials.jp/en/csr/envi/prize.html       valid
Crawling page: http://www.dexerials.jp/en/csr/envi/certificate.html       valid
Crawling page: http://www.dexerials.jp/en/csr/envi/structure.html       valid
Crawling page: http://www.dexerials.jp/en/csr/envi/products.html       valid
Crawling page: http://www.dexerials.jp/en/csr/envi/active.html       valid
Crawling page: http://www.dexerials.jp/en/csr/envi/manage.html       valid
Crawling page: http://www.dexerials.jp/en/csr/envi/vision.html       valid
Crawling page: http://www.dexerials.jp/en/csr/procure/green.html       valid
Crawling page: http://www.dexerials.jp/en/csr/procure/       valid
Crawling page: http://www.dexerials.jp/en/csr/download/       valid
Crawling page: http://www.dexerials.jp/en/csr/governance/group.html       valid
Crawling page: http://www.dexerials.jp/en/csr/top_message/       valid
Crawling page: http://www.dexerials.jp/en/profile/history.html       valid
Crawling page: http://www.dexerials.jp/en/profile/o_office.html       valid
Crawling page: http://www.dexerials.jp/en/profile/d_office.html       valid
Crawling page: http://www.dexerials.jp/en/profile/governance.html       valid
Crawling page: http://www.dexerials.jp/en/profile/message.html       valid
Crawling page: http://www.dexerials.jp/en/profile/vision.html       valid
Crawling page: http://www.dexerials.jp/en/profile/organization.html       valid
Crawling page: http://www.dexerials.jp/en/profile/profile.html       valid
Crawling page: http://www.dexerials.jp/en/products/c3/       valid
Crawling page: http://www.dexerials.jp/en/products/b4/       valid
Crawling page: http://www.dexerials.jp/en/products/c9/       valid
Crawling page: http://www.dexerials.jp/en/products/b5/       valid
Crawling page: http://www.dexerials.jp/en/products/b2/       valid
Crawling page: http://www.dexerials.jp/en/products/b1/       valid
Crawling page: http://www.dexerials.jp/en/products/b3/       valid
Crawling page: http://www.dexerials.jp/en/products/a6/       valid
Crawling page: https://www.smartplanettech.com/about-us/       valid
Crawling page: https://www.smartplanettech.com/technology/       valid
Crawling page: https://www.smartplanettech.com/applications/       valid
Crawling page: http://www.dexerials.jp/en/products/a1/       valid
Crawling page: http://www.dexerials.jp/en/products/a2/       valid
Crawling page: http://www.dexerials.jp/en/products/a3/       valid
Crawling page: http://www.dexerials.jp/en/products/a5/       valid
Crawling page: https://www.smartplanettech.com/contact/       valid
Crawling page: http://www.dexerials.jp/en/ir/       valid
Crawling page: http://www.dexerials.jp/en/contact/       valid
Crawling page: http://www.dexerials.jp/en/products/a7/       valid
Crawling page: http://www.dexerials.jp/en/csr/       valid
Crawling page: https://www.smartplanettech.com/news/       valid
Crawling page: http://www.ansunbiopharma.com/about-ansun-biopharma/       valid
Crawling page: https://global.canon/en/csr/labor/employ.html       valid
Crawling page: http://www.dexerials.jp/en/profile/       valid
Crawling page: http://www.dexerials.jp/en/products/       valid
Crawling page: http://www.dexerials.jp/kr/       valid
Crawling page: http://www.dexerials.jp/cn/       valid
Crawling page: https://www.smartplanettech.com/vendors/       valid
Crawling page: https://www.sanken-ele.co.jp/en/corp/index.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/prod/index.htm       valid
Crawling page: https://www.smartplanettech.com/retailer-form/       valid
Crawling page: http://www.dexerials.jp/       valid
Crawling page: https://www.sanken-ele.co.jp/en/tousika/index.htm       valid
Crawling page: https://www.sanken-ele.co.jp/en/contact/index.htm       valid
Crawling page: https://www.tok.co.jp/eng/sitemap.html       valid
Crawling page: http://calysta.com/company/       valid
Crawling page: http://calysta.com/company/management/       valid
Crawling page: http://calysta.com/company/board/       valid
Crawling page: https://www.tok.co.jp/eng/tech       valid
Crawling page: https://www.tok.co.jp/eng/ir       valid
Crawling page: https://www.tok.co.jp/eng/products       valid
Crawling page: https://www.sanken-ele.co.jp/en/news/index.htm       valid
Crawling page: https://www.sanken-ele.co.jp/index.php       valid
Crawling page: https://www.smartplanettech.com/spt-patents/       valid
Crawling page: https://www.smartplanettech.com/       valid
Crawling page: https://www.quanterix.com/       valid
Crawling page: http://novon.com/dynamic_citrus_juicer-dynajuicer.html       valid
Crawling page: https://www.quanterix.com/terms-and-conditions       valid
Crawling page: http://novon.com/specials.htm       valid
Crawling page: http://www.parion.com       valid
Crawling page: https://www.tok.co.jp/eng/condition.html       valid
Crawling page: https://www.tok.co.jp/eng/csr/report       valid
Crawling page: https://www.kronos.com/why-kronos/engaged-employees       valid
Crawling page: http://novon.com/about.htm       valid
Crawling page: http://www.novon.com/novon_store.php?crn=100       valid
Crawling page: http://novon.com/repairs.htm       valid
Crawling page: http://novon.com/contact.htm       valid
Crawling page: https://www.nh2.com/       valid
Crawling page: http://www.deltaww.com/       valid
Crawling page: http://novon.com/dynamic_mixer_accessories.php       valid
Crawling page: http://novon.com/dynamic_vegetable_cutters.php       valid
Crawling page: http://novon.com/dynamic_salad_spinners.php       valid
Crawling page: http://novon.com/dynamic_mixers.php       valid
Crawling page: http://www.deltaww.com/about/brand.aspx?secID=5&pid=2&tid=0&hl=en-US       valid
Crawling page: http://novon.com/       valid
Crawling page: http://www.deltaww.com/ir/agent.aspx?secID=4&pid=9&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/services.aspx?secID=4&pid=10&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/about/leadership.aspx?secID=5&pid=1&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/about/company.aspx?secID=5&pid=0&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/events.aspx?secID=4&pid=8&cateID=2&Year=&tid=0&live=1&hl=en-US2018-11-11 04:44:35 [scrapy.extensions.logstats] INFO: Crawled 2476 pages (at 4 pages/min), scraped 2244 items (at 6 items/min)
2018-11-11 04:45:22 [scrapy.extensions.logstats] INFO: Crawled 2485 pages (at 9 pages/min), scraped 2250 items (at 6 items/min)
2018-11-11 04:47:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.microsoft.com/en-us/locale.aspx> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 04:47:04 [scrapy.extensions.logstats] INFO: Crawled 2497 pages (at 12 pages/min), scraped 2262 items (at 12 items/min)
2018-11-11 04:47:41 [scrapy.extensions.logstats] INFO: Crawled 2501 pages (at 4 pages/min), scraped 2267 items (at 5 items/min)
2018-11-11 04:48:56 [scrapy.extensions.logstats] INFO: Crawled 2510 pages (at 9 pages/min), scraped 2276 items (at 9 items/min)
2018-11-11 04:49:35 [scrapy.extensions.logstats] INFO: Crawled 2516 pages (at 6 pages/min), scraped 2280 items (at 4 items/min)
2018-11-11 04:50:45 [scrapy.extensions.logstats] INFO: Crawled 2522 pages (at 6 pages/min), scraped 2288 items (at 8 items/min)
2018-11-11 04:52:02 [scrapy.extensions.logstats] INFO: Crawled 2531 pages (at 9 pages/min), scraped 2297 items (at 9 items/min)
2018-11-11 04:52:37 [scrapy.extensions.logstats] INFO: Crawled 2532 pages (at 1 pages/min), scraped 2301 items (at 4 items/min)
2018-11-11 04:53:25 [scrapy.extensions.logstats] INFO: Crawled 2538 pages (at 6 pages/min), scraped 2307 items (at 6 items/min)
2018-11-11 04:54:47 [scrapy.extensions.logstats] INFO: Crawled 2553 pages (at 15 pages/min), scraped 2316 items (at 9 items/min)
       valid
Crawling page: http://www.deltaww.com/services/customerService.aspx?secID=8&pid=2&tid=0&typeid=5&hl=en-US       valid
Crawling page: http://www.deltaww.com/information/DataCollection.aspx?secID=6&pid=3&tid=0&hl=en-US       valid
Crawling page: http://www.novon.com/novon_store.php       valid
Crawling page: http://www.deltaww.com/information/privacy.aspx?secID=6&pid=1&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/about/csr_Report.aspx?secID=5&pid=6&tid=9&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/pressDetail.aspx?secID=3&pID=1&typeID=3&itemID=8431&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/rss/ISNewsRSSFeeder.aspx?lanID=1       valid
Crawling page: http://www.deltaww.com/news/pressDetail.aspx?secID=3&pID=1&typeID=2&itemID=8479&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/pressDetail.aspx?secID=3&pID=1&itemID=8430&typeID=1;2&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/pressDetail.aspx?secID=3&pID=1&typeID=3&itemID=8496&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/pressDetail.aspx?secID=3&pID=1&typeID=1;2&itemID=6079&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/pressDetail.aspx?secID=3&pID=1&itemID=6154&typeID=2&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/pressDetail.aspx?secID=3&pID=1&typeID=1;4;5&itemID=7601&tid=0&hl=en-US       valid
Crawling page: https://www.microsoft.com/en-us/devices/safety-and-eco       valid
Crawling page: http://www.deltaww.com/news/pressDetail.aspx?secID=3&pID=1&typeID=4;5&itemID=7726&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/smartmanufacturing/index.html       valid
Crawling page: http://www.deltaww.com/news/pressDetail.aspx?secID=3&pID=1&typeID=1;3;4;5&itemID=8361&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/hr/Recruit.aspx?secID=7&pid=2&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/hr/benefit.aspx?secID=7&pid=1&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/hr/hr_feature.aspx?secID=7&pid=0&tid=0&hl=en-US       valid
Crawling page: https://www.microsoft.com/en-us/accessibility       valid
Crawling page: http://www.deltaww.com/rss/NewsRSSFeeder.aspx?lanID=1       valid
Crawling page: http://www.deltaww.com/about/grouplink.aspx?secID=5&pid=7&tid=0&hl=en-US       valid
Crawling page: http://www.microsoft.com/en-us/locale.aspx       Crawling page: http://www.deltaww.com/about/csr_features_eng.aspx?secID=5&pid=6&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/about/milestone.aspx?secID=5&pid=5&tid=0&hl=en-US       valid
Crawling page: https://www.microsoft.com/en-us/diversity/       valid
Crawling page: http://www.deltaww.com/about/innovation2.aspx?secID=5&pid=4&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/about/operations.aspx?secID=5&pid=3&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/analyst.aspx?secID=4&pid=7&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/governance.aspx?secID=4&pid=6&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/dividendInfo.aspx?secID=4&pid=5&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/stock.aspx?secID=4&pid=4&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/financialReport.aspx?secID=4&pid=3&cateID=3&Year=&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/annualReport.aspx?secID=4&pid=2&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/chairman.aspx?secID=4&pid=1&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/ir/index.aspx?secID=4&pid=0&tid=0&verify=&vn=&ve=&vd=&hl=en-US       valid
Crawling page: https://www.microsoft.com/en-us/sitemap.aspx       valid
Crawling page: http://www.deltaww.com/news/pressContact2.aspx?secID=3&pID=4&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/eventCalendars.aspx?secID=3&pID=3&year=&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/photos.aspx?secID=3&pID=2&typeID=1&page=1&tid=0&mode=thumb&order=desc&videoID=&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/press.aspx?secID=3&pID=1&typeID=0&page=1&tid=0&hl=en-US       valid
Crawling page: http://www.deltaww.com/news/feature.aspx?secID=3&pID=0&tid=0&verify=&vn=&ve=&vd=&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=060103&PID=ALL&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=05&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=18&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=08&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=21&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=07&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=13&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=09&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=20&hl=en-US       valid
Crawling page: http://www.deltaww.com/Solutions/CategoryListT1.aspx?CID=0511&SID=ALL&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=10&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=2301&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=23&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=06&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=1702&hl=en-US       valid
Crawling page: https://www.microsoft.com/en-us/about       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=1701&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=02&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=12&hl=en-US       valid
Crawling page: https://www.microsoft.com/en-us/education/products/office/default.aspx       valid
Crawling page: https://www.microsoft.com/en-us/education       valid
Crawling page: https://www.microsoft.com/en-us/windows/windows-10-apps       valid
Crawling page: https://www.microsoft.com/en-us/download       valid
Crawling page: https://www.microsoft.com/en-us/store/b/buy-online-pick-up-in-store?icid=uhf_footer_bopuis       valid
Crawling page: https://www.microsoft.com/en-us/store/locations/find-a-store       valid
Crawling page: https://www.microsoft.com/en-us/store/b/virtualreality       valid
Crawling page: https://www.microsoft.com/en-us/store/buy       valid
Crawling page: https://www.microsoft.com/en-us/p/surface-pro-6/8ZCNC665SLQ5       valid
Crawling page: https://www.microsoft.com/en-us/p/surface-laptop-2/8XQJKK3DD91B       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/rdp-licensing.aspx       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/technology-licensing-process.aspx       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/eas-licensing.aspx       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/smb-licensing.aspx       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/connected-car.aspx       valid
Crawling page: https://www.microsoft.com/en-us/p/surface-go/8v9dp4lnknsz?rtc=1       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/internet-of-things.aspx       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/business-technology-solutions.aspx       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/exfat-licensing.aspx       valid
Crawling page: https://www.microsoft.com/en-us/legal/intellectualproperty/mtl/onlinedisclaimer.aspx       valid2018-11-11 04:55:37 [scrapy.extensions.logstats] INFO: Crawled 2557 pages (at 4 pages/min), scraped 2323 items (at 7 items/min)
2018-11-11 04:55:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.microsoft.com/en-US/legal/intellectualproperty/mtl/default.aspx> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 04:56:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/wan-fang-opens-their-doors-to-share-hyperthermia> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:56:25 [scrapy.extensions.logstats] INFO: Crawled 2564 pages (at 7 pages/min), scraped 2327 items (at 4 items/min)
2018-11-11 04:56:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pyrexar.com/clinical/clinical-trials> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:56:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.pyrexar.com/hyperthermia/bsd-2000-3d-mr> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:56:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/2018-website-update> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:56:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/new-study-supporting-focus-and-steering> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:56:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/visit-us-at-astro-2018> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/hyperthermia-proton-beam> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/about-us/distributor-login> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/sarcoma-patients-living-longer-with-hyperthermia> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/astro-2018-in-review> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/about-us/contact-us> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:27 [scrapy.extensions.logstats] INFO: Crawled 2572 pages (at 8 pages/min), scraped 2327 items (at 0 items/min)
2018-11-11 04:57:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/about-us/in-the-news> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/about-us/featured-event> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/about-us/how-to-buy> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/about-us/our-team> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:57:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/knowledgebase/treatment-centers> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:58:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/about-us> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:58:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/hyperthermia-blog> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:58:29 [scrapy.extensions.logstats] INFO: Crawled 2589 pages (at 17 pages/min), scraped 2329 items (at 2 items/min)
2018-11-11 04:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/clinical/clinical-trials> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:59:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/hyperthermia/bsd-2000-3d-mr> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:59:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/clinical/bsd-2000-clinical-studies> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:59:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/clinical> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 04:59:50 [scrapy.extensions.logstats] INFO: Crawled 2597 pages (at 8 pages/min), scraped 2336 items (at 7 items/min)
2018-11-11 05:00:24 [scrapy.extensions.logstats] INFO: Crawled 2597 pages (at 0 pages/min), scraped 2340 items (at 4 items/min)
2018-11-11 05:01:37 [scrapy.extensions.logstats] INFO: Crawled 2605 pages (at 8 pages/min), scraped 2348 items (at 8 items/min)
2018-11-11 05:02:46 [scrapy.extensions.logstats] INFO: Crawled 2612 pages (at 7 pages/min), scraped 2356 items (at 8 items/min)
2018-11-11 05:03:36 [scrapy.extensions.logstats] INFO: Crawled 2617 pages (at 5 pages/min), scraped 2362 items (at 6 items/min)
2018-11-11 05:04:35 [scrapy.extensions.logstats] INFO: Crawled 2627 pages (at 10 pages/min), scraped 2368 items (at 6 items/min)
2018-11-11 05:05:35 [scrapy.extensions.logstats] INFO: Crawled 2631 pages (at 4 pages/min), scraped 2374 items (at 6 items/min)
2018-11-11 05:06:46 [scrapy.extensions.logstats] INFO: Crawled 2639 pages (at 8 pages/min), scraped 2381 items (at 7 items/min)
2018-11-11 05:07:29 [scrapy.extensions.logstats] INFO: Crawled 2639 pages (at 0 pages/min), scraped 2386 items (at 5 items/min)
2018-11-11 05:07:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 


Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/mobile-tablet.aspx       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/mtl/wearables.aspx       valid
Crawling page: https://www.microsoft.com/en-US/legal/intellectualproperty/iplicensing/default.aspx       valid
Crawling page: https://www.microsoft.com/en-us/legal/intellectualproperty/mtl/policy.aspx       valid
Crawling page: http://www.microsoft.com/en-US/legal/intellectualproperty/mtl/default.aspx       Crawling page: https://www.microsoft.com/en-us/legal       valid
Crawling page: https://www.microsoft.com/en-us/legal/       valid
Crawling page: https://www.microsoft.com/en-us/       valid
Crawling page: https://pyrexar.com/wan-fang-opens-their-doors-to-share-hyperthermia       Crawling page: https://www.pyrexar.com/clinical/clinical-trials       Crawling page: https://www.pyrexar.com/hyperthermia/bsd-2000-3d-mr       Crawling page: https://pyrexar.com/2018-website-update       Crawling page: https://pyrexar.com/new-study-supporting-focus-and-steering       Crawling page: https://pyrexar.com/visit-us-at-astro-2018       Crawling page: https://pyrexar.com/hyperthermia-proton-beam       Crawling page: https://pyrexar.com/about-us/distributor-login       Crawling page: https://pyrexar.com/sarcoma-patients-living-longer-with-hyperthermia       Crawling page: https://pyrexar.com/astro-2018-in-review       Crawling page: https://pyrexar.com/about-us/contact-us       Crawling page: https://pyrexar.com/about-us/in-the-news       Crawling page: https://pyrexar.com/about-us/featured-event       Crawling page: https://pyrexar.com/about-us/how-to-buy       Crawling page: https://pyrexar.com/about-us/our-team       Crawling page: https://pyrexar.com/knowledgebase/treatment-centers       Crawling page: https://pyrexar.com/about-us       Crawling page: https://pyrexar.com/hyperthermia-blog       Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=11&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=03&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=19&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=22&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=01&hl=en-US       valid
Crawling page: https://pyrexar.com/clinical/clinical-trials       Crawling page: https://pyrexar.com/hyperthermia/bsd-2000-3d-mr       Crawling page: https://pyrexar.com/clinical/bsd-2000-clinical-studies       Crawling page: https://pyrexar.com/clinical       Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=04&hl=en-US       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=060103&PID=ALL&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=18&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=05&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=08&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=21&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=07&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=13&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=09&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=20&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Solutions/CategoryListT1.aspx?CID=0511&SID=ALL&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=10&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=06&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=2301&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=1702&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=23&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=11&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=02&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=12&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=1701&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=01&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=19&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=03&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=22&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Products/CategoryListT1.aspx?CID=04&hl=zh-TW       valid
Crawling page: http://www.deltaww.com/Solutions/CategoryListT1.aspx?CID=06&hl=en-US       valid
Crawling page: http://www.deltaww.com/Solutions/CategoryListT1.aspx?CID=01&hl=en-US       valid
Crawling page: http://www.deltaww.com/Solutions/CategoryListT1.aspx?CID=02&hl=en-US       valid
Crawling page: http://www.deltaww.com/Solutions/CategoryListT1.aspx?CID=04&SID=ALL&hl=en-US       valid
Crawling page: http://www.deltaww.com/Solutions/CategoryListT1.aspx?CID=05&hl=en-US       valid
Crawling page: http://www.deltaww.com/Solutions/CategoryListT1.aspx?CID=03&SID=4&hl=en-US&Name=EV%20Charging%20Solutions       valid
Crawling page: http://www.deltaww.com/Solutions/CategoryListT1.aspx?CID=07&SID=102&hl=en-US&Name=Datacenter%20Solutions       valid
Crawling page: https://www.kronos.com/industry-solutions/retail/retail-action       valid
Crawling page: https://www.kronos.com/industry-solutions/convenience-stores/convenience-stores-action       valid
Crawling page: https://www.kronos.com/industry-solutions/grocery/grocery-action       valid
Crawling page: https://www.kronos.com/industry-solutions/aerospace-defense/aerospace-defense-action       valid
Crawling page: https://www.kronos.com/industry-solutions/manufacturing/manufacturing-action       valid
Crawling page: https://www.kronos.com/industry-solutions/life-sciences/life-sciences-action       valid
Crawling page: https://www.kronos.com/industry-solutions/energy/energy-action       valid
Crawling page: https://www.kronos.com/industry-solutions/non-acute-care-settings/non-acute-care-settings-action       valid
Crawling page: https://www.kronos.com/industry-solutions/clinician-providers/clinician-providers-action       valid
Crawling page: https://www.kronos.com/industry-solutions/post-acute-and-senior-living/post-acute-senior-living-action       valid
Crawling page: https://www.kronos.com/industry-solutions/acute-care-hospitals/acute-care-hospitals-action       valid
Crawling page: https://www.kronos.com/industry-solutions/health-systems/health-systems-action       valid
Crawling page: https://www.kronos.com/products/human-capital-management/hcm-experience       valid
Crawling page: http://www.em-techinc.com/job-opportunities/       valid
Crawling page: https://www.kronos.com/about-us/kronos-corporate-social-responsibility-csr       valid
Crawling page: https://www.kronos.com/customers/christus-health       valid
Crawling page: https://www.kronos.com/customers/mgm-resorts       valid
Crawling page: http://www.em-techinc.com/site-map/       valid
Crawling page: http://www.em-techinc.com/photos/warehouse-grand-opening/       valid
Crawling page: https://www.kronos.com/resources?industry=state%20%26%20local%20government       valid
Crawling page: https://www.kronos.com/resources/kronos-partner-network-brochure       valid
Crawling page: https://www.kronos.com/kronos-partner-network/become-partner       valid
Crawling page: https://pyrexar.com/       Crawling page: https://www.energysolutions.com/ken-robuck-named-president-and-ceo-of-energysolutions/       valid
Crawling page: https://www.energysolutions.com/energysolutions-clive-disposal-facility-recognized-by-utah-occupational-safety-and-health-uosh-as-a-voluntary-protection-program-vpp-facility-2//bin/sh: 1: kill: No such process

2018-11-11 05:08:26 [scrapy.extensions.logstats] INFO: Crawled 2652 pages (at 13 pages/min), scraped 2394 items (at 8 items/min)
2018-11-11 05:08:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.energysolutions.com/526>: HTTP status code is not handled or not allowed
/bin/sh: 1: kill: No such process

2018-11-11 05:09:29 [scrapy.extensions.logstats] INFO: Crawled 2670 pages (at 18 pages/min), scraped 2404 items (at 10 items/min)
2018-11-11 05:10:48 [scrapy.extensions.logstats] INFO: Crawled 2677 pages (at 7 pages/min), scraped 2416 items (at 12 items/min)
2018-11-11 05:11:32 [scrapy.extensions.logstats] INFO: Crawled 2680 pages (at 3 pages/min), scraped 2422 items (at 6 items/min)
2018-11-11 05:12:31 [scrapy.extensions.logstats] INFO: Crawled 2686 pages (at 6 pages/min), scraped 2428 items (at 6 items/min)
2018-11-11 05:13:47 [scrapy.extensions.logstats] INFO: Crawled 2694 pages (at 8 pages/min), scraped 2436 items (at 8 items/min)
2018-11-11 05:14:45 [scrapy.extensions.logstats] INFO: Crawled 2700 pages (at 6 pages/min), scraped 2442 items (at 6 items/min)
2018-11-11 05:15:38 [scrapy.extensions.logstats] INFO: Crawled 2707 pages (at 7 pages/min), scraped 2448 items (at 6 items/min)
2018-11-11 05:16:40 [scrapy.extensions.logstats] INFO: Crawled 2712 pages (at 5 pages/min), scraped 2454 items (at 6 items/min)
2018-11-11 05:17:33 [scrapy.extensions.logstats] INFO: Crawled 2719 pages (at 7 pages/min), scraped 2460 items (at 6 items/min)
2018-11-11 05:18:31 [scrapy.extensions.logstats] INFO: Crawled 2725 pages (at 6 pages/min), scraped 2466 items (at 6 items/min)
2018-11-11 05:21:03 [scrapy.extensions.logstats] INFO: Crawled 2731 pages (at 6 pages/min), scraped 2472 items (at 6 items/min)
2018-11-11 05:21:37 [scrapy.extensions.logstats] INFO: Crawled 2731 pages (at 0 pages/min), scraped 2475 items (at 3 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 05:22:36 [scrapy.extensions.logstats] INFO: Crawled 2746 pages (at 15 pages/min), scraped 2487 items (at 12 items/min)
       valid
Crawling page: https://www.energysolutions.com/energysolutions-clive-disposal-facility-recognized-by-utah-occupational-safety-and-health-uosh-as-a-voluntary-protection-program-vpp-facility/       valid
Crawling page: https://www.microsoft.com/en-us/legal/intellectualproperty/mtl/default.aspx       valid
Crawling page: https://www.energysolutions.com/projects/zionsolutions/       valid
Crawling page: http://www.em-techinc.com/inventory/       valid
Crawling page: http://www.em-techinc.com/photos/       valid
Crawling page: http://www.em-techinc.com/stand-by-power-rental/       valid
Crawling page: http://www.em-techinc.com/services/       valid
Crawling page: http://www.em-techinc.com/support/       valid
Crawling page: http://www.em-techinc.com/products/       valid
Crawling page: https://www.energysolutions.com/nuclear-plant-services-2/       valid
Crawling page: https://www.energysolutions.com/decommissioning-decontamination/u-s-international-experience/       valid
Crawling page: https://www.energysolutions.com/waste-transportation/cask/       valid
Crawling page: http://www.em-techinc.com/generators/       valid
Crawling page: http://www.em-techinc.com/about/       valid
Crawling page: http://www.em-techinc.com/contact/       valid
Crawling page: http://www.em-techinc.com/       valid
Crawling page: https://www.energysolutions.com/waste-transportation/mhf-services/       valid
Crawling page: http://www.em-techinc.com/pumps/       valid
Crawling page: http://www.em-techinc.com/motors/       valid
Crawling page: http://www.em-techinc.com/emergency-button/       valid
Crawling page: https://www.energysolutions.com/decommissioning-decontamination/proven-experience-at-zion/       valid
Crawling page: https://www.energysolutions.com/decommissioning-decontamination/       valid
Crawling page: https://www.energysolutions.com/decommissioning-decontamination/unique-extensive-owned-assets/       valid
Crawling page: https://www.energysolutions.com/waste-transportation/hittman-transport-services-inc/       valid
Crawling page: https://www.kronos.com/kronos-partner-network/find-partner?partner_type=reseller       valid
Crawling page: https://www.kronos.com/resources/customer-success       valid
Crawling page: https://www.kronos.com/kronos-services/workforce-central-services       valid
Crawling page: https://www.energysolutions.com/waste-processing/erwin-resin-processing/       valid
Crawling page: https://www.energysolutions.com/waste-processing/bear-creek-processing-facility/       valid
Crawling page: https://www.energysolutions.com/barnwell-disposal-facility/       valid
Crawling page: https://www.kronos.com/kronos-services/workforce-dimensions-services       valid
Crawling page: https://www.kronos.com/customers/hannaford-supermarkets       valid
Crawling page: https://www.kronos.com/customers/ymca-greater-boston       valid
Crawling page: https://www.energysolutions.com/clive-disposal-facility/       valid
Crawling page: https://www.kronos.com/customers?industry=state%20%26%20local%20government       valid
Crawling page: https://www.kronos.com/about-us/events       valid
Crawling page: https://www.kronos.com/about-us/newsroom       valid
Crawling page: https://www.kronos.com/about-us/our-culture       valid
Crawling page: https://www.kronos.com/about-us/leadership       valid
Crawling page: https://www.kronos.com/about-us/kronos-history       valid
Crawling page: https://www.kronos.com/resources?industry=retail       valid
Crawling page: https://www.kronos.com/resources?industry=police%20and%20corrections       valid
Crawling page: https://www.kronos.com/resources?industry=state/local%20government       valid
Crawling page: https://www.kronos.com/resources?industry=manufacturing       valid
Crawling page: https://www.kronos.com/resources?industry=higher%20education       valid
Crawling page: https://www.kronos.com/resources?industry=distribution       valid
Crawling page: https://www.kronos.com/resources?industry=contract%20services       valid
Crawling page: https://www.kronos.com/resources?industry=banking       valid
Crawling page: https://www.kronos.com/resources       valid
Crawling page: https://www.kronos.com/kronos-services       valid
Crawling page: https://www.kronos.com/customers?industry=state/local%20government       valid
Crawling page: https://www.kronos.com/customers?industry=retail       valid
Crawling page: https://www.kronos.com/customers?industry=police%20and%20corrections       valid
Crawling page: https://www.kronos.com/customers?industry=manufacturing       valid
Crawling page: https://www.kronos.com/customers?industry=health%20systems       valid
Crawling page: https://www.kronos.com/customers?industry=distribution       valid
Crawling page: https://www.kronos.com/customers?industry=contract%20services       valid
Crawling page: https://www.kronos.com/customers?industry=banking       valid
Crawling page: https://www.kronos.com/why-kronos/continual-innovation       valid
Crawling page: https://www.kronos.com/why-kronos/customer-first       valid
Crawling page: https://www.kronos.com/why-kronos       valid
Crawling page: https://www.kronos.com/industry-solutions/banking       valid
Crawling page: https://www.kronos.com/industry-solutions/contract-services       valid
Crawling page: https://www.kronos.com/industry-solutions/police-and-corrections       valid
Crawling page: https://www.kronos.com/industry-solutions/state-and-local-government       valid
Crawling page: https://www.kronos.com/industry-solutions/higher-education       valid
Crawling page: https://www.kronos.com/industry-solutions/retail       valid
Crawling page: https://www.kronos.com/industry-solutions/health-systems       valid
Crawling page: https://www.kronos.com/industry-solutions       valid
Crawling page: https://www.kronos.com/products/workforce-central-suite       valid
Crawling page: https://www.kronos.com/products/workforce-ready-suite       valid
Crawling page: https://www.kronos.com/products/workforce-dimensions-suite       valid
Crawling page: https://www.kronos.com/products/small-and-medium-sized-businesses       valid
Crawling page: https://www.kronos.com/products/payroll       valid
Crawling page: https://www.kronos.com/products/talent-management       valid
Crawling page: https://www.kronos.com/products/human-resources       valid
Crawling page: https://www.kronos.com/products/talent-acquisition       valid
Crawling page: https://www.kronos.com/products/human-capital-management       valid
Crawling page: https://www.kronos.com/products/analytics       valid
Crawling page: https://www.kronos.com/products/labor-activities       valid
Crawling page: https://www.kronos.com/products/absence-management       valid
Crawling page: https://www.kronos.com/products/time-and-attendance       valid
Crawling page: https://www.kronos.com/products/workforce-management       valid
Crawling page: https://www.kronos.com/products       valid
Crawling page: https://www.kronos.com/contact/en-us/form       valid
Crawling page: https://www.kronos.com/about-us/careers       valid
Crawling page: https://www.kronos.com/about-us/locations-and-global-reach       valid
Crawling page: https://www.kronos.com/       valid
Crawling page: http://novon.com/index.htm       valid
Crawling page: http://www.molecularrebar.com/technology-molecular-rebar/lead-acid-batteries/       valid
Crawling page: http://parion.com/2014/05/       valid
Crawling page: http://parion.com/2013/11/       valid
Crawling page: http://parion.com/2014/04/       valid
Crawling page: http://parion.com/category/news-and-events/       valid
Crawling page: http://www.molecularrebar.com/technology-molecular-rebar/       valid
Crawling page: http://parion.com/2014/10/       valid
Crawling page: http://parion.com/2014/11/       valid
Crawling page: http://parion.com/2014/06/       valid
Crawling page: http://parion.com/2014/09/       valid
Crawling page: http://parion.com/2015/02/       valid
Crawling page: http://parion.com/2015/05/       valid
Crawling page: http://parion.com/2015/06/       valid
Crawling page: http://parion.com/2015/09/       valid
Crawling page: http://parion.com/2015/10/       2018-11-11 05:23:27 [scrapy.extensions.logstats] INFO: Crawled 2758 pages (at 12 pages/min), scraped 2499 items (at 12 items/min)
2018-11-11 05:24:37 [scrapy.extensions.logstats] INFO: Crawled 2778 pages (at 20 pages/min), scraped 2515 items (at 16 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 05:25:44 [scrapy.extensions.logstats] INFO: Crawled 2786 pages (at 8 pages/min), scraped 2527 items (at 12 items/min)
2018-11-11 05:27:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.dss-space.com/products>: HTTP status code is not handled or not allowed
2018-11-11 05:27:09 [scrapy.extensions.logstats] INFO: Crawled 2813 pages (at 27 pages/min), scraped 2539 items (at 12 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 05:28:08 [scrapy.extensions.logstats] INFO: Crawled 2813 pages (at 0 pages/min), scraped 2549 items (at 10 items/min)
2018-11-11 05:29:04 [scrapy.extensions.logstats] INFO: Crawled 2818 pages (at 5 pages/min), scraped 2557 items (at 8 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 05:29:41 [scrapy.extensions.logstats] INFO: Crawled 2822 pages (at 4 pages/min), scraped 2562 items (at 5 items/min)
2018-11-11 05:30:31 [scrapy.extensions.logstats] INFO: Crawled 2830 pages (at 8 pages/min), scraped 2568 items (at 6 items/min)
2018-11-11 05:31:38 [scrapy.extensions.logstats] INFO: Crawled 2834 pages (at 4 pages/min), scraped 2576 items (at 8 items/min)
2018-11-11 05:32:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <406 http://courtagen.com/2017/12/>: HTTP status code is not handled or not allowed
2018-11-11 05:33:04 [scrapy.extensions.logstats] INFO: Crawled 2854 pages (at 20 pages/min), scraped 2585 items (at 9 items/min)
/bin/sh: 1: kill: No such process

valid
Crawling page: http://parion.com/2016/05/       valid
Crawling page: http://parion.com/2016/01/       valid
Crawling page: http://parion.com/2016/07/       valid
Crawling page: http://parion.com/2017/05/       valid
Crawling page: http://parion.com/2016/10/       valid
Crawling page: http://parion.com/news-and-events/parion-sciences-receives-2015-life-sciences-award-as-best-late-stage-product-development-company/       valid
Crawling page: http://parion.com/2016/11/       valid
Crawling page: http://parion.com/news-and-events/vertex-and-parion-sciences-establish-collaboration-to-develop-epithelial-sodium-channel-enac-inhibitors-in-cystic-fibrosis-and-other-pulmonary-diseases/       valid
Crawling page: http://parion.com/news-and-events/clean-cf-clinical-trial-expanded-to-include-pediatric-cystic-fibrosis-population/       valid
Crawling page: http://parion.com/news-and-events/parion-sciences-announces-upcoming-presentations-of-data-at-the-north-american-cystic-fibrosis-conference-being-held-october-8-through-10-2015/       valid
Crawling page: http://parion.com/news-and-events/ceva-and-zoion-pharma-announce-collaboration-to-develop-epithelial-sodium-channel-blockers-to-treat-veterinary-ocular-surface-diseases/       valid
Crawling page: http://parion.com/news-and-events/presentation-of-clinical-data-on-p-321-ophthalmic-solution-for-dry-eye/       valid
Crawling page: http://parion.com/news-and-events/parion-sciences-announces-presentation-of-clinical-data-with-novel-pulmonary-delivery-device-at-the-2016-north-american-cystic-fibrosis-conference/       valid
Crawling page: http://parion.com/news-and-events/parion-sciences-announces-initiation-of-phase-2-clinical-trial-of-p-321-for-the-treatment-of-dry-eye-disease/       valid
Crawling page: http://parion.com/news-and-events/topical-enac-blocker-serves-as-novel-approach-to-tear-film/       valid
Crawling page: http://parion.com/partnership/       valid
Crawling page: http://parion.com/careers/       valid
Crawling page: http://parion.com/uncategorized/shire-and-parion-sciences-enter-into-a-collaborative-license-agreement-to-advance-p-321-for-ophthalmic-indications/       valid
Crawling page: http://parion.com/contact/       valid
Crawling page: http://parion.com/news-and-events/       valid
Crawling page: http://parion.com/pipeline/clinical-trials/       valid
Crawling page: http://parion.com/pipeline/p-321-dry-eye/       valid
Crawling page: http://parion.com/pipeline/cftr-corrector-program/       valid
Crawling page: http://parion.com/pipeline/mucolytic-agents/       valid
Crawling page: http://parion.com/pipeline/tpad/       valid
Crawling page: http://parion.com/pipeline/enac-pulmonary-vx371-p1037/       valid
Crawling page: http://parion.com/pipeline/       valid
Crawling page: http://parion.com/about/board-of-directors/       valid
Crawling page: http://parion.com/about/our-team/       valid
Crawling page: http://parion.com/about/       valid
Crawling page: http://parion.com/       valid
Crawling page: https://www.quanterix.com/privacy-policy       valid
Crawling page: https://www.quanterix.com/resources/news/quanterix-q3-revenues-85-percent       valid
Crawling page: https://www.quanterix.com/resources/news/quanterix-targets-oncology-research-market-new-platform       valid
Crawling page: https://www.quanterix.com/resources/publications-posters/serum-neurofilament-light-chain-prognosis-outcome-after-cardiac       valid
Crawling page: https://www.dss-space.com/products-boom-systems       valid
Crawling page: https://www.dss-space.com/news       valid
Crawling page: https://www.dss-space.com/contact       valid
Crawling page: https://www.quanterix.com/resources/publications-posters/no-change-plasma-tau-and-serum-neurofilament-light-concentrations       valid
Crawling page: https://www.dss-space.com/products-rigid-panel       valid
Crawling page: https://www.quanterix.com/neurology-toolkit       valid
Crawling page: https://www.quanterix.com/safety-data-sheets       valid
Crawling page: https://www.dss-space.com/about-facilities       valid
Crawling page: https://www.quanterix.com/coa       valid
Crawling page: https://www.quanterix.com/quanterix-service-and-support       valid
Crawling page: https://www.dss-space.com/about-capabilities       valid
Crawling page: https://www.quanterix.com/resources/product-brochures       valid
Crawling page: https://genisphere.com/partnering-contact       valid
Crawling page: https://www.quanterix.com/resources/publications-posters       valid
Crawling page: https://genisphere.com/news-events       valid
Crawling page: https://www.quanterix.com/resources/webinars       valid
Crawling page: https://www.dss-space.com/about-company-profile       valid
Crawling page: https://genisphere.com/pipeline       valid
Crawling page: https://genisphere.com/publications       valid
Crawling page: https://www.dss-space.com/products-flex-blanket       valid
Crawling page: https://www.dss-space.com/       valid
Crawling page: https://www.quanterix.com/resources/whitepapers       valid
Crawling page: https://genisphere.com/targeted-therapeutics       valid
Crawling page: https://genisphere.com/our-technology       valid
Crawling page: https://genisphere.com/about-us       valid
Crawling page: https://genisphere.com/search/node       valid
Crawling page: https://www.quanterix.com/resources/conferences       valid
Crawling page: https://www.quanterix.com/resources/press-releases       valid
Crawling page: https://www.quanterix.com/resources/news       valid
Crawling page: https://www.quanterix.com/resources       valid
Crawling page: https://genisphere.com/       valid
Crawling page: https://www.quanterix.com/products-technology/instruments/2470-arrayer       valid
Crawling page: https://www.quanterix.com/srx       valid
Crawling page: https://www.quanterix.com/SP-X       valid
Crawling page: https://www.quanterix.com/products-technology/instruments/hd-1       valid
Crawling page: https://www.quanterix.com/products-technology/homebrew       valid
Crawling page: https://www.quanterix.com/products-technology/simoa-assay-kits       valid
Crawling page: https://www.quanterix.com/planar-array-technology       valid
Crawling page: https://www.quanterix.com/simoa-bead-technology       valid
Crawling page: https://www.quanterix.com/products-technology       valid
Crawling page: https://www.quanterix.com/simoa-accelerator-laboratory       valid
Crawling page: https://www.quanterix.com/therapeutic-areas/infectious-disease       valid
Crawling page: https://www.quanterix.com/therapeutic-areas/inflammation       valid
Crawling page: https://www.quanterix.com/therapeutic-areas/cardiology       valid
Crawling page: https://www.quanterix.com/therapeutic-areas/cns-biomarkers       valid
Crawling page: https://www.quanterix.com/therapeutic-areas/oncology       valid
Crawling page: https://www.quanterix.com/therapeutic-areas       valid
Crawling page: https://www.quanterix.com/contact       valid
Crawling page: https://www.quanterix.com/forums-preview?destination=forums       valid
Crawling page: https://www.quanterix.com/blog       valid
Crawling page: https://www.quanterix.com/about       valid
Crawling page: https://www.kronos.com/industry-solutions/manufacturing       valid
Crawling page: https://www.kronos.com/customers       valid
Crawling page: https://www.kronos.com/customers?industry=higher%20education       valid
Crawling page: https://www.kronos.com/kronos-partner-network       valid
Crawling page: https://www.kronos.com/industry-solutions/distribution       valid
Crawling page: https://www.kronos.com/about-us       valid
Crawling page: https://www.kronos.com/about-us/awards-and-recognition       valid
Crawling page: https://www.kronos.com/kronos-services/workforce-ready-services       valid
Crawling page: https://www.kronos.com/resources?industry=health%20systems       valid
Crawling page: http://courtagen.com/       valid
Crawling page: http://courtagen.com/category/uncategorized/       valid
Crawling page: http://courtagen.com/2017/12/11/hello-world/       valid
Crawling page: http://www.molecularrebar.com/login/       valid
Crawling page: http://www.molecularrebar.com/news-molecular-rebar/2018-11-11 05:33:51 [scrapy.extensions.logstats] INFO: Crawled 2854 pages (at 0 pages/min), scraped 2593 items (at 8 items/min)
2018-11-11 05:34:35 [scrapy.extensions.logstats] INFO: Crawled 2858 pages (at 4 pages/min), scraped 2597 items (at 4 items/min)
2018-11-11 05:35:50 [scrapy.extensions.logstats] INFO: Crawled 2866 pages (at 8 pages/min), scraped 2605 items (at 8 items/min)
2018-11-11 05:36:26 [scrapy.extensions.logstats] INFO: Crawled 2870 pages (at 4 pages/min), scraped 2609 items (at 4 items/min)
2018-11-11 05:37:37 [scrapy.extensions.logstats] INFO: Crawled 2876 pages (at 6 pages/min), scraped 2616 items (at 7 items/min)
2018-11-11 05:38:48 [scrapy.extensions.logstats] INFO: Crawled 2883 pages (at 7 pages/min), scraped 2624 items (at 8 items/min)
2018-11-11 05:39:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.microsoft.com/en-us/solution-providers>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 05:39:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://gold.tanaka.co.jp/english/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:39:28 [scrapy.extensions.logstats] INFO: Crawled 2898 pages (at 15 pages/min), scraped 2628 items (at 4 items/min)
2018-11-11 05:39:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://pyrexar.com/?Itemid=185>: HTTP status code is not handled or not allowed
2018-11-11 05:40:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/knowledgebase/organizations> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 05:40:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/pyrexar-adds-thailand-distributor> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 05:40:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/privacy-policy> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 05:40:50 [scrapy.extensions.logstats] INFO: Crawled 2899 pages (at 1 pages/min), scraped 2636 items (at 8 items/min)
2018-11-11 05:40:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://pyrexar.com/knowledgebase/pyrexar-video>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:40:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://pyrexar.com/clinical/by-indication>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:40:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://pyrexar.com/pyrexar-signs-with-viet-nam>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:40:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://pyrexar.com/knowledgebase/hyperthermia-faq>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:40:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://marketing.pyrexar.com/acton/form/15060/0027:d-0001/1/-/-/-/-/index.htm>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 05:40:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.energysolutions.com/495>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:40:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.energysolutions.com/518>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:40:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.energysolutions.com/decommissioning-decontamination/approaches-options-for-safstor-prompt-decon/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:40:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.energysolutions.com/decommissioning-decontamination>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:40:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://courtagen.com/feed/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 05:40:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://courtagen.com/comments/feed/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 05:40:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.energysolutions.com/about/careers/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 05:40:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.energysolutions.com/decommissioning-decontamination/pre-shutdown-support-early-site-activities/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 05:41:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.energysolutions.com/waste-processing/high-activity-filter-processing/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 05:41:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/hyperthermia> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 05:41:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/hyperthermia/bsd-2000-3d> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 05:41:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/hyperthermia/bsd-2000> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 05:42:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pyrexar.com/hyperthermia/bsd-500> (referer: https://pyrexar.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 05:42:01 [scrapy.extensions.logstats] INFO: Crawled 2908 pages (at 9 pages/min), scraped 2642 items (at 6 items/min)
2018-11-11 05:42:24 [scrapy.extensions.logstats] INFO: Crawled 2913 pages (at 5 pages/min), scraped 2644 items (at 2 items/min)
2018-11-11 05:43:40 [scrapy.extensions.logstats] INFO: Crawled 2918 pages (at 5 pages/min), scraped 2652 items (at 8 items/min)
2018-11-11 05:44:36 [scrapy.extensions.logstats] INFO: Crawled 2923 pages (at 5 pages/min), scraped 2657 items (at 5 items/min)
2018-11-11 05:45:36 [scrapy.extensions.logstats] INFO: Crawled 2929 pages (at 6 pages/min), scraped 2662 items (at 5 items/min)
2018-11-11 05:46:29 [scrapy.extensions.logstats] INFO: Crawled 2933 pages (at 4 pages/min), scraped 2667 items (at 5 items/min)
2018-11-11 05:47:39 [scrapy.extensions.logstats] INFO: Crawled 2939 pages (at 6 pages/min), scraped 2673 items (at 6 items/min)
2018-11-11 05:48:23 [scrapy.extensions.logstats] INFO: Crawled 2944 pages (at 5 pages/min), scraped 2677 items (at 4 items/min)
       valid
Crawling page: http://courtagen.com/wp-login.php       valid
Crawling page: https://www.kronos.com/kronos-partner-network/find-partner?partner_type=technology       valid
Crawling page: https://www.kronos.com/about-us/1-100-million       valid
Crawling page: https://www.kronos.com/industry-solutions/food-service/food-service-action       valid
Crawling page: https://www.kronos.com/industry-solutions/casino-resorts/casino-resorts-action       valid
Crawling page: https://www.kronos.com/industry-solutions/lodging/lodging-action       valid
Crawling page: https://www.kronos.com/industry-solutions/state-and-local-government/statelocal-government-action       valid
Crawling page: https://www.kronos.com/industry-solutions/federal-government/federal-government-action       valid
Crawling page: https://www.kronos.com/industry-solutions/distribution/distribution-action       valid
Crawling page: https://www.kronos.com/industry-solutions/third-party-logistics/third-party-logistics-action       valid
Crawling page: https://www.kronos.com/industry-solutions/trucking/trucking-action       valid
Crawling page: https://www.kronos.com/industry-solutions/higher-education/higher-education-action       valid
Crawling page: https://www.kronos.com/industry-solutions/k-12/k-12-action       valid
Crawling page: https://www.kronos.com/industry-solutions/contract-services/contract-services-action       valid
Crawling page: https://www.kronos.com/industry-solutions/nonprofits/nonprofits-action       valid
Crawling page: https://www.kronos.com/industry-solutions/field-services/field-services-action       valid
Crawling page: https://www.kronos.com/industry-solutions/staffing/staffing-action       valid
Crawling page: https://www.kronos.com/industry-solutions/contact-centers/contact-centers-action       valid
Crawling page: https://www.kronos.com/industry-solutions/banking/banking-action       valid
Crawling page: https://www.kronos.com/industry-solutions/credit-unions/credit-unions-action       valid
Crawling page: https://www.kronos.com/industry-solutions/police-and-corrections/police-action       valid
Crawling page: https://www.kronos.com/industry-solutions/insurance/insurance-action       valid
Crawling page: https://www.kronos.com/industry-solutions/fire-and-ems/fireems-action       valid
Crawling page: https://www.kronos.com/products/ai/aimee       valid
Crawling page: https://www.kronos.com/about-us/events/kronos-hr-payroll-esymposium       valid
Crawling page: https://www.kronos.com/blogs/what-works/automating-time-and-attendance-getting-it-right-first-time       valid
Crawling page: https://www.kronos.com/resources/prepare-yourself-future-workforce-management-report       valid
Crawling page: https://www.kronos.com/workinspired       valid
Crawling page: https://www.kronos.com/security       valid
Crawling page: https://www.kronos.com/terms-of-use       valid
Crawling page: https://www.kronos.com/kronos.xml       valid
Crawling page: https://www.kronos.com/trademarks       valid
Crawling page: https://www.kronos.com/privacy-policy       valid
Crawling page: https://www.kronos.com/kronos-partner-network/find-partner?partner_type=services       valid
Crawling page: http://www.deltaww.com/information/terms.aspx?secID=6&pid=2&tid=0&hl=en-US       valid
Crawling page: https://www.microsoft.com/en-us/security/default.aspx       valid
Crawling page: https://www.nh2.com/contact-us       valid
Crawling page: https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/en-us.aspx       valid
Crawling page: https://www.nh2.com/team       valid
Crawling page: https://www.microsoft.com/en-us/investor       valid
Crawling page: https://www.microsoft.com/en-us/sql-server/       valid
Crawling page: https://www.nh2.com/investors/signin       valid
Crawling page: https://www.nh2.com/news       valid
Crawling page: https://pyrexar.com/knowledgebase/organizations       Crawling page: https://pyrexar.com/pyrexar-adds-thailand-distributor       Crawling page: https://pyrexar.com/privacy-policy       Crawling page: https://www.microsoft.com/en-us/store/b/education?icid=CNavfooter_Studentsandeducation       valid
Crawling page: https://www.nh2.com/about       valid
Crawling page: https://www.energysolutions.com/news-and-information/       valid
Crawling page: https://www.energysolutions.com/canada/       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/schools.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/stadiums-sports-fields.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/maintenance.html       valid
Crawling page: https://pyrexar.com/hyperthermia       Crawling page: https://pyrexar.com/hyperthermia/bsd-2000-3d       Crawling page: https://pyrexar.com/hyperthermia/bsd-2000       Crawling page: https://pyrexar.com/hyperthermia/bsd-500       Crawling page: https://www.birdbgone.com/choose-by-industry/hospitals.html       valid
Crawling page: https://www.birdbgone.com/privacy.html       valid
Crawling page: https://www.birdbgone.com/catalog/seo_sitemap/category/       valid
Crawling page: https://www.birdbgone.com/terms-of-service.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/retrofit-remodels.html       valid
Crawling page: https://www.birdbgone.com/microcide-sq.html       valid
Crawling page: https://www.birdbgone.com/super-talon-net-launcher.html       valid
Crawling page: https://www.birdbgone.com/products/bird-control-hazers-and-thermal-foggers/hazer-hardware.html       valid
Crawling page: https://www.birdbgone.com/products/bird-control-hazers-and-thermal-foggers.html       valid
Crawling page: https://www.birdbgone.com/avian-control-goose-repellents.html       valid
Crawling page: https://www.birdbgone.com/bat-netting.html       valid
Crawling page: https://www.birdbgone.com/no-knot-bird-netting.html       valid
Crawling page: https://www.birdbgone.com/bird-netting-birdnet-2-inch-mesh.html       valid
Crawling page: https://www.birdbgone.com/bird-netting-birdnet-1-1-8-inch-mesh.html       valid
Crawling page: https://www.birdbgone.com/bird-netting-birdnet-3-4-inch-mesh.html       valid
Crawling page: https://www.birdbgone.com/local/west-virginia-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/wisconsin-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/washington-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/wyoming-bird-control.html       valid
Crawling page: https://www.birdbgone.com/plastic-bird-spikes.html       valid
Crawling page: https://www.birdbgone.com/local/utah-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/texas-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/south-carolina-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/tennessee-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/south-dakota-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/oregon-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/oklahoma-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/north-carolina-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/ohio-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/north-dakota-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/pennsylvania-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/new-hampshire-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/new-mexico-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/nevada-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/new-jersey-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/nebraska-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/maryland-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/minnesota-bird-control.html       valid2018-11-11 05:49:29 [scrapy.extensions.logstats] INFO: Crawled 2949 pages (at 5 pages/min), scraped 2683 items (at 6 items/min)
2018-11-11 05:50:34 [scrapy.extensions.logstats] INFO: Crawled 2955 pages (at 6 pages/min), scraped 2689 items (at 6 items/min)
2018-11-11 05:51:30 [scrapy.extensions.logstats] INFO: Crawled 2962 pages (at 7 pages/min), scraped 2694 items (at 5 items/min)
2018-11-11 05:52:25 [scrapy.extensions.logstats] INFO: Crawled 2967 pages (at 5 pages/min), scraped 2700 items (at 6 items/min)
2018-11-11 05:53:45 [scrapy.extensions.logstats] INFO: Crawled 2974 pages (at 7 pages/min), scraped 2708 items (at 8 items/min)
2018-11-11 05:54:29 [scrapy.extensions.logstats] INFO: Crawled 2979 pages (at 5 pages/min), scraped 2713 items (at 5 items/min)
2018-11-11 05:55:26 [scrapy.extensions.logstats] INFO: Crawled 2985 pages (at 6 pages/min), scraped 2719 items (at 6 items/min)
2018-11-11 05:56:23 [scrapy.extensions.logstats] INFO: Crawled 2996 pages (at 11 pages/min), scraped 2725 items (at 6 items/min)
2018-11-11 05:57:24 [scrapy.extensions.logstats] INFO: Crawled 3001 pages (at 5 pages/min), scraped 2732 items (at 7 items/min)
2018-11-11 05:58:43 [scrapy.extensions.logstats] INFO: Crawled 3006 pages (at 5 pages/min), scraped 2740 items (at 8 items/min)
2018-11-11 05:59:29 [scrapy.extensions.logstats] INFO: Crawled 3011 pages (at 5 pages/min), scraped 2744 items (at 4 items/min)
2018-11-11 06:00:25 [scrapy.extensions.logstats] INFO: Crawled 3016 pages (at 5 pages/min), scraped 2749 items (at 5 items/min)
2018-11-11 06:01:22 [scrapy.extensions.logstats] INFO: Crawled 3022 pages (at 6 pages/min), scraped 2755 items (at 6 items/min)
2018-11-11 06:02:24 [scrapy.extensions.logstats] INFO: Crawled 3025 pages (at 3 pages/min), scraped 2759 items (at 4 items/min)
2018-11-11 06:03:22 [scrapy.extensions.logstats] INFO: Crawled 3030 pages (at 5 pages/min), scraped 2764 items (at 5 items/min)

Crawling page: https://www.birdbgone.com/local/michigan-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/maine-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/massachusetts-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/illinois-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/indiana-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/hawaii-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/florida-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/georgia-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/idaho-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/california-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/delaware-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/colorado-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/arizona-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/arkansas-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local.html       valid
Crawling page: https://www.birdbgone.com/local/connecticut-bird-control.html       valid
Crawling page: https://www.birdbgone.com/ask-an-expert/bryan-donoho-bird-control-expert.html       valid
Crawling page: https://www.birdbgone.com/contact-bird-b-gone.html       valid
Crawling page: https://www.birdbgone.com/ask-an-expert/alan-roniss-bird-control-expert.html       valid
Crawling page: https://www.birdbgone.com/authorized-installers.html       valid
Crawling page: https://www.birdbgone.com/ask-an-expert/mark-gist-bird-control-expert.html       valid
Crawling page: https://www.birdbgone.com/products/laser-bird-deterrents.html       valid
Crawling page: https://www.birdbgone.com/products/woodpecker-deterrents.html       valid
Crawling page: https://www.birdbgone.com/products/swallow-deterrents.html       valid
Crawling page: https://www.birdbgone.com/products/goose-control-products.html       valid
Crawling page: https://www.birdbgone.com/products/visual-bird-deterrents.html       valid
Crawling page: https://www.birdbgone.com/products/bird-trapping-capture-nets/net-launcher.html       valid
Crawling page: https://www.birdbgone.com/products/cleaners.html       valid
Crawling page: https://www.birdbgone.com/products/sound-bird-deterrents.html       valid
Crawling page: https://www.birdbgone.com/products/bird-repellents/bird-off-gel.html       valid
Crawling page: https://www.birdbgone.com/products/bird-trapping-capture-nets/professional-live-bird-traps.html       valid
Crawling page: https://www.birdbgone.com/products/bird-trapping-capture-nets.html       valid
Crawling page: https://www.birdbgone.com/products/bird-trapping-capture-nets/capture-bird-netting.html       valid
Crawling page: https://www.birdbgone.com/products/bird-deterrents/solar-bird-repeller.html       valid
Crawling page: https://www.birdbgone.com/products/bird-deterrents/repeller-360.html       valid
Crawling page: https://www.birdbgone.com/products/bird-deterrents/vinyl-strip-door-products.html       valid
Crawling page: https://www.birdbgone.com/products/bird-repellents.html       valid
Crawling page: https://www.birdbgone.com/products/bird-deterrents/bird-slope.html       valid
Crawling page: https://www.birdbgone.com/products/bird-deterrents/bird-spiders.html       valid
Crawling page: https://www.birdbgone.com/products/bird-deterrents/bird-wire.html       valid
Crawling page: https://www.birdbgone.com/products/electric-track/electric-track-install-components.html       valid
Crawling page: https://www.birdbgone.com/products/bird-deterrents.html       valid
Crawling page: https://www.birdbgone.com/products/electric-track/bird-jolt-flat-track.html       valid
Crawling page: https://www.birdbgone.com/products/electric-track.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/bird-net-hardware/accessories.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/bird-net-hardware/bird-netting-tools.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/industrial-pond-bird-netting.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/garden-netting-products.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/bird-net-hardware/intermediate-attachments.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/bird-net-hardware/cable-fasteners.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/heavy-duty-bird-net/8-bird-netting.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/heavy-duty-bird-net/2-bird-netting.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/heavy-duty-bird-net/4-bird-netting.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/heavy-duty-bird-net.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting.html       valid
Crawling page: https://www.birdbgone.com/authorized-installers/your-partner-in-bird-control.html       valid
Crawling page: https://www.birdbgone.com/bird-control-product-catalog.html       valid
Crawling page: https://www.birdbgone.com/authorized-installers/authorized-installer-resources.html       valid
Crawling page: https://www.birdbgone.com/ask-an-expert.html       valid
Crawling page: https://www.birdbgone.com/authorized-installers/i-need-an-authorized-installer.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/window-cleaners.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/food-production.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/boating.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/residential.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/roofing.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/property-management.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/pest-control.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/signs.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/construction.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/architects.html       valid
Crawling page: https://www.birdbgone.com/resource-center/case-studies.html       valid
Crawling page: https://www.birdbgone.com/resource-center/product-literature.html       valid
Crawling page: https://www.birdbgone.com/resource-center/bim-objects.html       valid
Crawling page: https://www.birdbgone.com/resource-center/product-cad-details.html       valid
Crawling page: https://www.birdbgone.com/resource-center/installation-instructions.html       valid
Crawling page: https://www.birdbgone.com/resource-center/bird-control-two-minute-tuesday.html       valid
Crawling page: https://www.birdbgone.com/catalogsearch/result/?q=plastic+bird+spikes       valid
Crawling page: https://www.birdbgone.com/catalogsearch/result/?q=Enter+keywords+to+search...       valid
Crawling page: https://www.birdbgone.com/pest-bird-profiles.html       valid
Crawling page: https://www.birdbgone.com/resource-center/marketing-bird-control.html       valid
Crawling page: https://www.birdbgone.com/resource-center/pest-bird-diseases.html       valid
Crawling page: https://www.birdbgone.com/checkout/cart/       valid
Crawling page: https://www.birdbgone.com/resource-center/bird-control-videos.html       valid
Crawling page: https://www.birdbgone.com/resource-center/product-specifications.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/government.html       valid
Crawling page: https://www.birdbgone.com/catalogsearch/result/?q=bird+spikes       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/bird-control-grain-millers.html       valid
Crawling page:2018-11-11 06:04:27 [scrapy.extensions.logstats] INFO: Crawled 3035 pages (at 5 pages/min), scraped 2769 items (at 5 items/min)
2018-11-11 06:05:24 [scrapy.extensions.logstats] INFO: Crawled 3041 pages (at 6 pages/min), scraped 2775 items (at 6 items/min)
2018-11-11 06:06:31 [scrapy.extensions.logstats] INFO: Crawled 3048 pages (at 7 pages/min), scraped 2782 items (at 7 items/min)
2018-11-11 06:07:32 [scrapy.extensions.logstats] INFO: Crawled 3057 pages (at 9 pages/min), scraped 2788 items (at 6 items/min)
2018-11-11 06:08:32 [scrapy.extensions.logstats] INFO: Crawled 3062 pages (at 5 pages/min), scraped 2793 items (at 5 items/min)
2018-11-11 06:09:29 [scrapy.extensions.logstats] INFO: Crawled 3070 pages (at 8 pages/min), scraped 2799 items (at 6 items/min)
2018-11-11 06:09:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.energysolutions.com>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
/bin/sh: 1: kill: No such process

2018-11-11 06:10:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.molecularrebar.com/patents/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 06:10:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.molecularrebar.com/our-partners/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 06:10:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.birdbgone.com/authorized-installers/bird-b-gone-university.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:10:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.kronos.com/products/onboarding>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:10:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.kronos.com/products/labor-laws-and-issues>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:10:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.molecularrebar.com/contact-us-molecular-rebar/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 06:10:23 [scrapy.extensions.logstats] INFO: Crawled 3071 pages (at 1 pages/min), scraped 2805 items (at 6 items/min)
2018-11-11 06:11:48 [scrapy.extensions.logstats] INFO: Crawled 3088 pages (at 17 pages/min), scraped 2818 items (at 13 items/min)
2018-11-11 06:11:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://parion.com/wp-login.php> (referer: http://parion.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 54, in replace
    return Response.replace(self, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 81, in replace
    return cls(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 22, in __init__
    self._set_body(body)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
  File "/usr/lib/python3.6/encodings/cp1252.py", line 12, in encode
    return codecs.charmap_encode(input,errors,encoding_table)
UnicodeEncodeError: 'charmap' codec can't encode character '\u2190' in position 3370: character maps to <undefined>
2018-11-11 06:12:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dss-space.com/products-concentrators>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:12:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.birdbgone.com/beak-guard-woodpecker-deterrent.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:12:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.birdbgone.com/waste-digester.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:12:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.birdbgone.com/vinyl-strip-doors.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:12:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.birdbgone.com/checkout/onepage/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:12:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.molecularrebar.com>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 06:12:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://newfieldthera.com/tel:7049535597>: HTTP status code is not handled or not allowed
/bin/sh: 1: kill: No such process

2018-11-11 06:12:56 [scrapy.extensions.logstats] INFO: Crawled 3117 pages (at 29 pages/min), scraped 2829 items (at 11 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 06:13:28 [scrapy.extensions.logstats] INFO: Crawled 3122 pages (at 5 pages/min), scraped 2834 items (at 5 items/min)
2018-11-11 06:14:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Foodservice> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:14:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/customers/dealers/terms-conditions-sale> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:14:34 [scrapy.extensions.logstats] INFO: Crawled 3136 pages (at 14 pages/min), scraped 2842 items (at 8 items/min)
2018-11-11 06:14:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/calprop65> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:14:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Parts-Support/Service-Agencies.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:15:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Terms-of-Use.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:15:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Parts-Support/Parts-Search.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:15:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Privacy-Policy.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:15:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Contact-Us/Website-Feedback> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:15:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Contact-Us/Vollrath-Email-Signup> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:15:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Customers/Dealers/Customer-Self-Service.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:15:56 [scrapy.extensions.logstats] INFO: Crawled 3143 pages (at 7 pages/min), scraped 2845 items (at 3 items/min)
2018-11-11 06:16:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Contact-Us/Contact-Lookup> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

/bin/sh: 1: kill: No such process

2018-11-11 06:16:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Parts-Support/FAQ-and-Reference.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:16:26 [scrapy.extensions.logstats] INFO: Crawled 3148 pages (at 5 pages/min), scraped 2846 items (at 1 items/min)
2018-11-11 06:16:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Resource-Library/Price-Lists.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:16:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Parts-Support/Product-Registration.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:16:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Resource-Library/Catalogs.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:16:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Parts-Support/Warranty-Information.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:17:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Parts-Support/TSR-and-CSR-Contact.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:17:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Resource-Library.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:17:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/vollrathUniversity/Culinary-Support/Guides-Reference.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:17:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Resource-Library/New-Product-Brochure.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:17:29 [scrapy.extensions.logstats] INFO: Crawled 3156 pages (at 8 pages/min), scraped 2846 items (at 0 items/min)
2018-11-11 06:17:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/vollrathUniversity/Product-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:17:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/VollrathUniversity/About.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:17:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/warewashingconfigurator> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

 https://www.birdbgone.com/customer/account/login/       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/oil-gas.html       valid
Crawling page: https://www.birdbgone.com/products.html       valid
Crawling page: https://www.birdbgone.com/authorized-installers/become-an-authorized-installer.html       valid
Crawling page: https://www.birdbgone.com/products/bird-spikes/c-stainless-steel-bird-spikes.html       valid
Crawling page: https://www.birdbgone.com/products/bird-spikes.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/solar-panel-industry.html       valid
Crawling page: https://www.birdbgone.com/products/bird-spikes/c-plastic-bird-spikes.html       valid
Crawling page: https://www.birdbgone.com/products/bird-netting/bird-net-hardware.html       valid
Crawling page: https://www.birdbgone.com/products/bird-repellents/goose-repellent-products.html       valid
Crawling page: https://www.birdbgone.com/products/bird-repellents/bird-repellent.html       valid
Crawling page: https://www.birdbgone.com/products/solar-panel-bird-deterrent.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry.html       valid
Crawling page: https://www.birdbgone.com/products/bird-repellents/transparent-bird-gel-products.html       valid
Crawling page: https://www.birdbgone.com/local/iowa-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/alabama-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/louisiana-bird-control.html       valid
Crawling page: https://www.birdbgone.com/resource-center.html       valid
Crawling page: https://www.birdbgone.com/local/alaska-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/kansas-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/kentucky-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/montana-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/mississippi-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/missouri-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/new-york-bird-control.html       valid
Crawling page: https://www.birdbgone.com/gutter-bird-spikes.html       valid
Crawling page: https://www.birdbgone.com/transparent-bird-gel.html       valid
Crawling page: https://www.birdbgone.com/mega-bird-spikes.html       valid
Crawling page: https://www.birdbgone.com/girder-bird-spikes.html       valid
Crawling page: https://www.birdbgone.com/stainless-steel-pigeon-spikes.html       valid
Crawling page: https://www.birdbgone.com/products/bird-repellents/avian-control-goose-repellent.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/aviation.html       valid
Crawling page: https://www.birdbgone.com/blog/       valid
Crawling page: https://www.birdbgone.com/local/rhode-island-bird-control.html       valid
Crawling page: https://www.birdbgone.com/       valid
Crawling page: https://www.birdbgone.com/local/virginia-bird-control.html       valid
Crawling page: https://www.birdbgone.com/local/vermont-bird-control.html       valid
Crawling page: https://www.energysolutions.com/about/       valid
Crawling page: https://www.kronos.com/products/employee-scheduling       valid
Crawling page: https://www.kronos.com/blogs       valid
Crawling page: http://www.molecularrebar.com/technology-molecular-rebar/coatings/       valid
Crawling page: http://www.molecularrebar.com/technology-molecular-rebar/rubber-molecular-rebar/       valid
Crawling page: http://parion.com/category/uncategorized/       valid
Crawling page: http://parion.com/feed/       valid
Crawling page: http://parion.com/comments/feed/       valid
Crawling page: http://www.molecularrebar.com/mrd-quick-faq/       valid
Crawling page: http://www.molecularrebar.com/our-team-molecular-rebar/       valid
Crawling page: https://www.birdbgone.com/resource-center/why-bird-control.html       valid
Crawling page: https://www.birdbgone.com/choose-by-industry/agriculture.html       valid
Crawling page: https://www.birdbgone.com/about.html       valid
Crawling page: https://www.birdbgone.com/resource-center/product-msds.html       valid
Crawling page: http://www.molecularrebar.com/technology-molecular-rebar/lithium-molecular-rebar/       valid
Crawling page: http://parion.com/wp-login.php       Crawling page: http://www.molecularrebar.com/technology-molecular-rebar/medical-applications-molecular-rebar/       valid
Crawling page: http://www.molecularrebar.com/technology-molecular-rebar/composites-molecular-rebar/       valid
Crawling page: https://newfieldthera.com/       valid
Crawling page: http://www.unity-sc.com/products/       valid
Crawling page: https://www.echogen.com/our-solution/applications/oil-gas/       valid
Crawling page: https://gemex.com/privacy-policy/       valid
Crawling page: https://quantapore.com/?s=       valid
Crawling page: https://quantapore.com/board/       valid
Crawling page: https://quantapore.com/contact/       valid
Crawling page: https://quantapore.com/sab/       valid
Crawling page: https://www.echogen.com/our-solution/applications/powergen/       valid
Crawling page: http://wisys.org/       valid
Crawling page: https://gemex.com/find-a-jeweler/united-kingdom/       valid
Crawling page: https://gemex.com/find-a-jeweler/china/       valid
Crawling page: https://alcotek.com/what-we-do/manufacturing/       valid
Crawling page: https://gemex.com/find-a-jeweler/canada/       valid
Crawling page: https://gemex.com/about/       valid
Crawling page: https://gemex.com/certified-diamonds/certificate/       valid
Crawling page: https://gemex.com/find-a-jeweler/       valid
Crawling page: https://vollrath.com/Foodservice       Crawling page: https://gemex.com/frequently-asked-questions/       valid
Crawling page: https://gemex.com/find-a-jeweler/aruba/       valid
Crawling page: https://gemex.com/certified-diamonds/understanding-light-performance/       valid
Crawling page: https://vollrath.com/customers/dealers/terms-conditions-sale       Crawling page: https://www.pulsetherapeutics.com/wp-login.php       valid
Crawling page: https://vollrath.com/calprop65       Crawling page: https://www.pulsetherapeutics.com/contact/       valid
Crawling page: https://vollrath.com/Vollrath/Parts-Support/Service-Agencies.htm       Crawling page: https://vollrath.com/Vollrath/Terms-of-Use.htm       Crawling page: https://vollrath.com/Vollrath/Parts-Support/Parts-Search.htm       Crawling page: https://www.pulsetherapeutics.com/news/       valid
Crawling page: https://vollrath.com/Vollrath/Privacy-Policy.htm       Crawling page: https://vollrath.com/Contact-Us/Website-Feedback       Crawling page: https://vollrath.com/Contact-Us/Vollrath-Email-Signup       Crawling page: https://www.pulsetherapeutics.com/stroke/       valid
Crawling page: https://vollrath.com/Vollrath/Customers/Dealers/Customer-Self-Service.htm       Crawling page: https://vollrath.com/Contact-Us/Contact-Lookup       Crawling page: https://www.pulsetherapeutics.com/       valid
Crawling page: https://vollrath.com/Vollrath/Parts-Support/FAQ-and-Reference.htm       Crawling page: https://vollrath.com/Vollrath/Resource-Library/Price-Lists.htm       Crawling page: https://vollrath.com/Vollrath/Parts-Support/Product-Registration.htm       Crawling page: https://vollrath.com/Vollrath/Resource-Library/Catalogs.htm       Crawling page: https://vollrath.com/Vollrath/Parts-Support/Warranty-Information.htm       Crawling page: https://vollrath.com/Vollrath/Parts-Support/TSR-and-CSR-Contact.htm       Crawling page: https://vollrath.com/Vollrath/Resource-Library.htm       Crawling page: https://vollrath.com/vollrathUniversity/Culinary-Support/Guides-Reference.htm       Crawling page: https://vollrath.com/Vollrath/Resource-Library/New-Product-Brochure.htm       Crawling page: https://vollrath.com/vollrathUniversity/Product-Training.htm       Crawling page: https://vollrath.com/VollrathUniversity/About.htm       Crawling page: https://vollrath.com/warewashingconfigurator       Crawling page: https://vollrath.com/Warewashing-Handling-and-Dispensers/How-To-Order-Traex-Imprinted-Racks.htm2018-11-11 06:18:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Warewashing-Handling-and-Dispensers/How-To-Order-Traex-Imprinted-Racks.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:18:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://vollrath.com/inductiondrywell/> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:18:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Products/Warewashing-Handling-and-Dispensers/Signature-Dishrack-Component-Parts-Guide.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:18:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Warewashing-Handling-and-Dispensers/How-To-Order-Traex-Color-Racks.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:18:32 [scrapy.extensions.logstats] INFO: Crawled 3161 pages (at 5 pages/min), scraped 2846 items (at 0 items/min)
2018-11-11 06:18:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://vollrath.com/induction/> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:18:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Contact-Us> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:18:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Contact-Us/Contact-Sales> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:19:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Cookware-Bakeware-Products.htm?FB_Values=F2_C84_A5!&F2_ajaxEnabled=1&F2_DocID=189&F2_keywordFilter=&&&> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:19:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Cooking-Equipment-Products.htm?FB_Values=F2_C146_A49!&F2_ajaxEnabled=1&F2_DocID=184&F2_keywordFilter=&&&> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:19:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Fabricator-Components-Products.htm?FB_Values=F2_C146_A568!F2_C146_A517!&F2_ajaxEnabled=1&F2_DocID=186&F2_keywordFilter=&&&> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:19:24 [scrapy.extensions.logstats] INFO: Crawled 3176 pages (at 15 pages/min), scraped 2846 items (at 0 items/min)
2018-11-11 06:19:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Contact-Us/Locations> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:19:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Fabricator-Components/Fabricator-Components-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:20:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Warming-Equipment-Products.htm?FB_Values=F2_C129_A100!&F2_ajaxEnabled=1&F2_DocID=185&F2_keywordFilter=&&&> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:20:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Induction-Products> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:20:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Fabricator-Components> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:20:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Fabricator-Components-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:20:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Serving-System-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:20:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath-Serving-Systems> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:20:52 [scrapy.extensions.logstats] INFO: Crawled 3178 pages (at 2 pages/min), scraped 2849 items (at 3 items/min)
2018-11-11 06:20:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Mobile-Food-Serving-Equipment/Serving-Systems-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:21:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Products/Serving-Systems--Components.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:21:20 [root] ERROR: Unable to find match for url: https://www.dnaatlas.com
2018-11-11 06:22:07 [scrapy.extensions.logstats] INFO: Crawled 3197 pages (at 19 pages/min), scraped 2859 items (at 10 items/min)
2018-11-11 06:22:50 [scrapy.extensions.logstats] INFO: Crawled 3199 pages (at 2 pages/min), scraped 2864 items (at 5 items/min)
2018-11-11 06:23:23 [scrapy.extensions.logstats] INFO: Crawled 3202 pages (at 3 pages/min), scraped 2868 items (at 4 items/min)
2018-11-11 06:25:19 [scrapy.extensions.logstats] INFO: Crawled 3212 pages (at 10 pages/min), scraped 2882 items (at 14 items/min)
2018-11-11 06:25:28 [scrapy.extensions.logstats] INFO: Crawled 3215 pages (at 3 pages/min), scraped 2883 items (at 1 items/min)
2018-11-11 06:26:27 [scrapy.extensions.logstats] INFO: Crawled 3220 pages (at 5 pages/min), scraped 2890 items (at 7 items/min)
2018-11-11 06:27:28 [scrapy.extensions.logstats] INFO: Crawled 3233 pages (at 13 pages/min), scraped 2898 items (at 8 items/min)
2018-11-11 06:27:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath-Frozen-Treat-Equipment-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:27:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Frozen-Treat-Equipment> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:28:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Merchandising-Display-Solutions/Merchandising-Display-Solutions-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:28:24 [scrapy.extensions.logstats] INFO: Crawled 3237 pages (at 4 pages/min), scraped 2902 items (at 4 items/min)
2018-11-11 06:28:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Warming-Equipment-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:29:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Cooking-Equipment> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:29:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Warming-Equipment> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:29:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Warming-Equipment/Warming-Equipment-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:29:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Merchandising-Display-Solutions> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:29:33 [scrapy.extensions.logstats] INFO: Crawled 3249 pages (at 12 pages/min), scraped 2905 items (at 3 items/min)
2018-11-11 06:29:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Cooking-Equipment/Cooking-Equipment-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:29:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Cooking-Equipment-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:29:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Food-Prep-Equipment-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:30:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Products/Food-Prep-Equipment/Food-Prep-Equipment-Guides-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:30:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Food-Prep-Equipment> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:30:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Products/Countertop-Equipment.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:30:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Dispensing-Solutions/Dispensing-Solutions-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:30:31 [scrapy.extensions.logstats] INFO: Crawled 3249 pages (at 0 pages/min), scraped 2905 items (at 0 items/min)
2018-11-11 06:30:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Dispensing-Solutions> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:30:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Warewashing-Handling> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:30:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Warewashing-Handling/Warewashing-Handling-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:31:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Warewashing-Handling-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:31:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wheretobuy.vollrath.com> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:31:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Buffet-and-Tabletop-Services-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:31:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Kitchen-Essentials/Kitchen-Essentials-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:31:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Buffet-Tabletop-Service> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:31:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Kitchen-Essentials-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:31:46 [scrapy.extensions.logstats] INFO: Crawled 3263 pages (at 14 pages/min), scraped 2905 items (at 0 items/min)
       Crawling page: http://vollrath.com/inductiondrywell/       Crawling page: https://vollrath.com/Vollrath/Products/Warewashing-Handling-and-Dispensers/Signature-Dishrack-Component-Parts-Guide.htm       Crawling page: https://vollrath.com/Warewashing-Handling-and-Dispensers/How-To-Order-Traex-Color-Racks.htm       Crawling page: http://vollrath.com/induction/       Crawling page: https://vollrath.com/Contact-Us       Crawling page: https://vollrath.com/Contact-Us/Contact-Sales       Crawling page: https://vollrath.com/Cookware-Bakeware-Products.htm?FB_Values=F2_C84_A5!&F2_ajaxEnabled=1&F2_DocID=189&F2_keywordFilter=&&&       Crawling page: https://vollrath.com/Cooking-Equipment-Products.htm?FB_Values=F2_C146_A49!&F2_ajaxEnabled=1&F2_DocID=184&F2_keywordFilter=&&&       Crawling page: https://vollrath.com/Fabricator-Components-Products.htm?FB_Values=F2_C146_A568!F2_C146_A517!&F2_ajaxEnabled=1&F2_DocID=186&F2_keywordFilter=&&&       Crawling page: https://vollrath.com/Contact-Us/Locations       Crawling page: https://www.atum.bio/company       valid
Crawling page: https://www.atum.bio/sitemap       valid
Crawling page: https://vollrath.com/Fabricator-Components/Fabricator-Components-Guides-and-Training.htm       Crawling page: https://vollrath.com/Warming-Equipment-Products.htm?FB_Values=F2_C129_A100!&F2_ajaxEnabled=1&F2_DocID=185&F2_keywordFilter=&&&       Crawling page: https://vollrath.com/Induction-Products       Crawling page: https://www.atum.bio/products/crispr?exp=3       valid
Crawling page: https://vollrath.com/Fabricator-Components       Crawling page: https://vollrath.com/Fabricator-Components-Products.htm       Crawling page: https://vollrath.com/Serving-System-Products.htm       Crawling page: https://vollrath.com/Vollrath-Serving-Systems       Crawling page: https://vollrath.com/Mobile-Food-Serving-Equipment/Serving-Systems-Guides-and-Training.htm       Crawling page: https://vollrath.com/Vollrath/Products/Serving-Systems--Components.htm       Crawling page: https://www.atum.bio/eCommerce/login       valid
Crawling page: https://www.atum.bio/eCommerce/cart       valid
Crawling page: https://www.dnaatlas.com       valid
Crawling page: https://www.westpointhome.com/vendor-information.html       valid
Crawling page: https://www.westpointhome.com/shipping-and-return-policy.html       valid
Crawling page: https://www.westpointhome.com/privacy-policy.html       valid
Crawling page: https://www.westpointhome.com/mm5/       valid
Crawling page: https://www.atum.bio/company/contact       valid
Crawling page: https://www.atum.bio/company/careers       valid
Crawling page: https://www.atum.bio/company/companyprivacy-information       valid
Crawling page: https://www.westpointhome.com/about-us.html       valid
Crawling page: https://www.westpointhome.com/martex-super-soft-fleece-blanket.html       valid
Crawling page: https://www.westpointhome.com/martex-egyptian-cotton-with-dryfast-30-inches-wide-x-54-inches-long-grey-bath-towel.html       valid
Crawling page: https://www.westpointhome.com/utica-essentials-towels.html       valid
Crawling page: https://www.atum.bio/company/news-events/newsletters       valid
Crawling page: https://www.westpointhome.com/martex-egyptian-cotton-dryfast-towels.html       valid
Crawling page: https://www.westpointhome.com/back-to-college/bath-body.html       valid
Crawling page: https://www.westpointhome.com/back-to-college/fashion-bedding.html       valid
Crawling page: https://www.westpointhome.com/back-to-college.html       valid
Crawling page: https://www.atum.bio/company/terms-and-conditions       valid
Crawling page: https://www.westpointhome.com/sale.html       valid
Crawling page: http://taiyo-hd.co.jp/en/terms/       valid
Crawling page: http://taiyo-hd.co.jp/en/privacy/       valid
Crawling page: http://taiyo-hd.co.jp/en/sitemap/       valid
Crawling page: http://taiyo-hd.co.jp/en/glossary/       valid
Crawling page: https://www.atum.bio/company/partners       valid
Crawling page: http://taiyo-hd.co.jp/en/challenge/03/       valid
Crawling page: http://taiyo-hd.co.jp/en/challenge/02/       valid
Crawling page: http://taiyo-hd.co.jp/en/challenge/04/       valid
Crawling page: https://www.taiyo-hd.co.jp/en/contact/?_contact=product       valid
Crawling page: https://www.taiyo-hd.co.jp/en/contact/?_contact=recruit       valid
Crawling page: https://www.taiyo-hd.co.jp/en/contact/?_contact=ir       valid
Crawling page: https://www.taiyo-hd.co.jp/en/contact/?_contact=rd       valid
Crawling page: http://taiyo-hd.co.jp/en/challenge/01/       valid
Crawling page: http://taiyo-hd.co.jp/en/investor/disclaimer/       valid
Crawling page: http://taiyo-hd.co.jp/en/investor/share/       valid
Crawling page: http://taiyo-hd.co.jp/en/investor/performance/       valid
Crawling page: http://taiyo-hd.co.jp/en/investor/shareholder/       valid
Crawling page: https://www.taiyo-hd.co.jp/en/contact/?_contact=company       valid
Crawling page: http://taiyo-hd.co.jp/en/investor/highlight/       valid
Crawling page: http://taiyo-hd.co.jp/en/investor/calendar/       valid
Crawling page: http://taiyo-hd.co.jp/en/investor/disclosure/       valid
Crawling page: http://taiyo-hd.co.jp/en/investor/governance/       valid
Crawling page: http://taiyo-hd.co.jp/en/investor/policy/       valid
Crawling page: http://taiyo-hd.co.jp/en/environment_csr/information_security/       valid
Crawling page: http://taiyo-hd.co.jp/en/environment_csr/quality/       valid
Crawling page: http://taiyo-hd.co.jp/en/environment_csr/csr/       valid
Crawling page: http://taiyo-hd.co.jp/en/environment_csr/environment/       valid
Crawling page: http://taiyo-hd.co.jp/en/business/solderresist/use/       valid
Crawling page: https://vollrath.com/Vollrath-Frozen-Treat-Equipment-Products.htm       Crawling page: https://vollrath.com/Frozen-Treat-Equipment       Crawling page: http://taiyo-hd.co.jp/en/business/solderresist/characteristic/       valid
Crawling page: http://taiyo-hd.co.jp/en/business/new/       valid
Crawling page: http://taiyo-hd.co.jp/en/business/solderresist/process/       valid
Crawling page: http://www.taiyo-hd.co.jp/en/investor/result/       valid
Crawling page: https://vollrath.com/Merchandising-Display-Solutions/Merchandising-Display-Solutions-Guides-and-Training.htm       Crawling page: http://taiyo-hd.co.jp/en/business/fpd/       valid
Crawling page: http://taiyo-hd.co.jp/en/business/solderresist/       valid
Crawling page: http://www.taiyo-hd.co.jp/en/investor/irnews/       valid
Crawling page: https://vollrath.com/Warming-Equipment-Products.htm       Crawling page: https://vollrath.com/Cooking-Equipment       Crawling page: https://vollrath.com/Warming-Equipment       Crawling page: https://vollrath.com/Warming-Equipment/Warming-Equipment-Guides-and-Training.htm       Crawling page: https://vollrath.com/Merchandising-Display-Solutions       Crawling page: https://vollrath.com/Cooking-Equipment/Cooking-Equipment-Guides-and-Training.htm       Crawling page: https://vollrath.com/Cooking-Equipment-Products.htm       Crawling page: https://vollrath.com/Food-Prep-Equipment-Products.htm       Crawling page: https://vollrath.com/Vollrath/Products/Food-Prep-Equipment/Food-Prep-Equipment-Guides-Training.htm       Crawling page: https://vollrath.com/Food-Prep-Equipment       Crawling page: https://vollrath.com/Vollrath/Products/Countertop-Equipment.htm       Crawling page: https://vollrath.com/Dispensing-Solutions/Dispensing-Solutions-Guides-and-Training.htm       Crawling page: https://vollrath.com/Dispensing-Solutions       Crawling page: https://vollrath.com/Warewashing-Handling       Crawling page: https://vollrath.com/Warewashing-Handling/Warewashing-Handling-Guides-and-Training.htm       Crawling page: https://vollrath.com/Warewashing-Handling-Products.htm       Crawling page: http://wheretobuy.vollrath.com       Crawling page: https://vollrath.com/Buffet-and-Tabletop-Services-Products.htm       Crawling page: https://vollrath.com/Kitchen-Essentials/Kitchen-Essentials-Guides-and-Training.htm       Crawling page: https://vollrath.com/Buffet-Tabletop-Service       Crawling page: https://vollrath.com/Kitchen-Essentials-Products.htm       Crawling page:2018-11-11 06:31:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Buffet-and-Tabletop-Service/Buffet-and-Tabletop-Service-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:32:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Kitchen-Essentials> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:32:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Cookware-Bakeware-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:32:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Cookware-Bakeware/Cookware-Bakeware-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:32:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Cookware-Bakeware> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:32:31 [scrapy.extensions.logstats] INFO: Crawled 3266 pages (at 3 pages/min), scraped 2905 items (at 0 items/min)
2018-11-11 06:32:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Steam-Table-Pans> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:32:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Steam-Table-Pans-Products.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:34:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Steam-Table-Pans/Steam-Table-Pans-Guides-and-Training.htm> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 241, in check_response
    raise exception_class(message, screen, stacktrace, alert_text)
selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None
Message: 

2018-11-11 06:34:21 [scrapy.extensions.logstats] INFO: Crawled 3267 pages (at 1 pages/min), scraped 2905 items (at 0 items/min)
2018-11-11 06:34:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://vollrath.com/Vollrath/Products/Smallwares> (referer: http://vollrath.com/Traex-Full-Size-Compartment-Racks-1766.htm)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 57, in parse_links
    browser = webdriver.Firefox(options=options)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/firefox/webdriver.py", line 164, in __init__
    self.service.start()
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/common/service.py", line 76, in start
    stdin=PIPE)
  File "/usr/lib/python3.6/subprocess.py", line 709, in __init__
    restore_signals, start_new_session)
  File "/usr/lib/python3.6/subprocess.py", line 1275, in _execute_child
    restore_signals, start_new_session, preexec_fn)
OSError: [Errno 12] Cannot allocate memory
2018-11-11 06:34:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://alcotek.com> (referer: https://alcotek.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 57, in parse_links
    browser = webdriver.Firefox(options=options)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/firefox/webdriver.py", line 164, in __init__
    self.service.start()
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/common/service.py", line 76, in start
    stdin=PIPE)
  File "/usr/lib/python3.6/subprocess.py", line 709, in __init__
    restore_signals, start_new_session)
  File "/usr/lib/python3.6/subprocess.py", line 1275, in _execute_child
    restore_signals, start_new_session, preexec_fn)
OSError: [Errno 12] Cannot allocate memory
2018-11-11 06:34:22 [scrapy.extensions.logstats] INFO: Crawled 3268 pages (at 1 pages/min), scraped 2905 items (at 0 items/min)
2018-11-11 06:35:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.atum.bio/company/news-events/events> (referer: https://www.atum.bio/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 57, in parse_links
    browser = webdriver.Firefox(options=options)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/firefox/webdriver.py", line 174, in __init__
    keep_alive=True)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 157, in __init__
    self.start_session(capabilities, browser_profile)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 252, in start_session
    response = self.execute(Command.NEW_SESSION, parameters)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: connection refused

2018-11-11 06:35:34 [scrapy.extensions.logstats] INFO: Crawled 3278 pages (at 10 pages/min), scraped 2905 items (at 0 items/min)
