nohup: ignoring input
Checking url for ACACIA RESEARCH GROUP LLC
	Trying http://acaciaresearch.com/
Checking url for Ticona LLC
	Trying http://celanese.com/engineered-materials.aspx
Checking url for Senga Advisors
	Trying http://coengadvisors.com/
Checking url for CyboEnergy
	Trying http://cyboenergy.com/
Checking url for EMD Technologies Inc.
	Trying http://emd-technologies.com/
Checking url for Energen
	Trying http://energen.com/
Checking url for Ferro Corporation
	Trying http://ferro.com/
Checking url for FULL CIRCLE BIOCHAR
	Trying http://fullcirclebiochar.com/
Checking url for Gilead Connecticut
	Trying http://gileadcs.org/
Checking url for Glucan Biorenewables LLC
	Trying http://glucanbio.com/
Checking url for GOAL ZERO LLC
	Trying http://goalzero.com/
Checking url for King Electric Vehicles Inc.
	Trying http://https://king-electric.com/
	Trying http://www.https://king-electric.com/
	Trying https://https://king-electric.com/
	Trying https://www.https://king-electric.com/
Checking url for NanoOncology
	Trying http://iinano.org/nanooncology
Checking url for Immunolight
	Trying http://immunolight.com/
Checking url for Iogen Corporation
	Trying http://iogen.ca/
Checking url for Kinetech Power Company LLC
	Trying http://kinetechpower.com/
Checking url for KR Design House
	Trying http://krdesignhouse.com/
Checking url for Matrix Genetics
	Trying http://lumenbioscience.com/
Checking url for Lux Bio Group
	Trying http://luxbiogroup.com/
Checking url for Magnolia Solar
	Trying http://magnoliasolar.com/
Checking url for Magnolia Solar
	Trying http://magnoliasolar.com/
Checking url for Mattson Technology
	Trying http://mattson.com/
Checking url for Michelin Recherche et Technique S.A.
	Trying http://michelin.com/eng
Checking url for Micro Cooling Concepts
	Trying http://microcoolingconcepts.com/
Checking url for NanoGram Corporation
	Trying http://nanogram.com
Checking url for Newdoll Enterprises LLC
	Trying http://newholdllc.com/
Checking url for U.S. NUTRACEUTICALS
	Trying http://nutraceutical.com/
Checking url for The Paymaster Corporation
	Trying http://paymaster.com/
Checking url for Pharmatrophix
	Trying http://pharmatrophix.com/
Checking url for Plant Sensory Systems
	Trying http://plantsensorysystems.com/
Checking url for PortaFire
	Trying http://port-a-fire.ca/
Checking url for Samsung SDI Co.
	Trying http://samsungsdi.com/
Checking url for Sinton Consulting
	Trying http://sintoninstruments.com/
Checking url for SOL-ELECTRICA
	Trying http://sol-electrica.com/
Checking url for SOLENA FUELS CORPORATION
	Trying http://solenafuels.com/
Checking url for Soliton Lasers
	Trying http://soliton.com/
Checking url for S&S X-Ray Products
	Trying http://ssxray.com/
Checking url for Starsource Scientific LLC
	Trying http://starsource.com/about/?41.html
Checking url for Sun Synchrony
	Trying http://sunsynchrony.com/
Checking url for Integrated Solar Technology
	Trying http://suntegrasolar.com/
Checking url for True-Safe Technologies
	Trying http://true-safe.com/
	Trying http://www.true-safe.com/
	Trying https://true-safe.com/
	Trying https://www.true-safe.com/
Checking url for VERLASE TECHNOLOGIES LLC
	Trying http://verlase.com/
Checking url for Wave Energy Conversion Corporation of America
	Trying http://weccamerica.com/
Checking url for Terra Caloric
	Trying http://wellconnectgeo.com/
Checking url for Crystal Solar Inc.
	Trying http://xtalsolar.com/
Checking url for Crystal Solar Incorporated
	Trying http://xtalsolar.com/
Checking url for Ablexis
	Trying http://ablexis.com/
Checking url for SII Semiconductor Corporation
	Trying http://ablic.com/en/semicon/
Checking url for Alliance for Sustainable Energy
	Trying http://allianceforsustainableenergy.org/
Checking url for Arkival Technology Corp.
	Trying http://arkival.com/
Checking url for Astech
	Trying http://astech.com/
Checking url for Coactive Drive Corporation
	Trying http://coactivehs.com/team/
Checking url for Ford Global Technologies
	Trying http://corporate.ford.com/innovation.html
Checking url for ENI Technology
	Trying http://eni.com/en_IT/innovation.page
Checking url for FRONT EDGE TECHNOLOGY INC.
	Trying http://frontedgetechnology.com/
Checking url for Bi-Modal Corporation
	Trying http://gartner.com/it-glossary/bimodal
Checking url for Genesco Inc.
	Trying http://genescopartners.com/
Checking url for GROW ENERGY
	Trying http://growenergy.org/
Checking url for HM3 Energy
	Trying http://hm3energy.com/
Checking url for HTS
	Trying http://htstechnologies.com/
Checking url for Intel Corporation
	Trying http://intel.com/content/us/en/homepage.html
	Trying http://www.intel.com/content/us/en/homepage.html
	Trying https://intel.com/content/us/en/homepage.html
	Trying https://www.intel.com/content/us/en/homepage.html
Checking url for Linne Industries LLC
	Trying http://linneindustries.com/
Checking url for Gestion Ultra International Inc.
	Trying http://luminultra.com/
Checking url for MicroContinuum
	Trying http://microcontinuum.com/
Checking url for Nanoquantum Sciences
	Trying http://nanoquantum.com/
Checking url for Neural Signals
	Trying http://neuralsignals.com/
Checking url for New Technology Ventures
	Trying http://newtechvc.com/
Checking url for Neutronic Perpetual Innovations
	Trying http://npimobile.com/
Checking url for OAS Design Group
	Trying http://oasdesigngroup.com/
Checking url for Sanyo Electric Co.
	Trying http://panasonic.com/global/corporate/profile/group-companies/sanyo.html
Checking url for Foret Plasma Labs
	Trying http://plasmawhirl.com/
Checking url for RenovaCare Sciences Corp.
	Trying http://renovacareinc.com/contact/
Checking url for Surebeam Corporation
	Trying http://smebeam.com/
Checking url for SOLARTONIC
	Trying http://solartonic.com/
Checking url for Sumitomo Rubber Industries
	Trying http://sumitomorubber-usa.com/
Checking url for Simbol Inc.
	Trying http://symbols.com/
Checking url for T.H.E.M.
	Trying http://them.net/
Checking url for Disney Enterprises
	Trying http://thewaltdisneycompany.com/
Checking url for Thorn Bioscience LLC
	Trying http://thornbioscience.com/
Checking url for Total Marketing Services
	Trying http://total.com/en
Checking url for TP Solar
	Trying http://tpsolar.nl/?lang=en
Checking url for UVIC INDUSTRY PARTNERSHIPS INC.
	Trying http://uvic.ca/research/partner/index.php
Checking url for VINDICO NANOBIO TECHNOLOGY INC.
	Trying http://vindicoat.com/
	Trying http://www.vindicoat.com/
Checking url for Silicon Space Technology Corp.
	Trying http://voragotech.com/
Checking url for Wostec
	Trying http://westec.org/
Checking url for Building Envelope Innovations
	Trying http://wet-flash.com/
Checking url for ADMA Products
	Trying http://admaproducts.com/#!
Checking url for Adynxx
	Trying http://adynxx.com/
Checking url for Annam Biosciences
	Trying http://annambiosciences.com/
Checking url for Atleisure LLC
	Trying http://atleisure.com/
Checking url for Brother International Corporation
	Trying http://brother-usa.com/
Checking url for Cooper Technologies Company
	Trying http://coopertechnologies.net/
Checking url for Enginuity Worldwide
	Trying http://enginuityww.webstarts.com/
Checking url for Gracenote
	Trying http://gracenote.com/
Checking url for Graphene Technologies
	Trying http://graphenetechnologies.com/
Checking url for Green Extraction Technologies
	Trying http://greenextractiontechnologiesllc.com/
Checking url for Hunt Energy Enterprises LLC
	Trying http://huntenergyenterprises.com/
Checking url for JOLED Inc.
	Trying http://j-oled.com/
Checking url for J. E. WHITE
	Trying http://jewhites.com.au/
[{'domain': 'acaciaresearch.com',
  'firm_name': 'ACACIA RESEARCH GROUP LLC',
  'url': 'http://acaciaresearch.com/'},
 {'domain': 'celanese.com',
  'firm_name': 'Ticona LLC',
  'url': 'https://celanese.com/engineered-materials/engineered-materials.aspx'},
 {'domain': 'www.coengadvisors.com',
  'firm_name': 'Senga Advisors',
  'url': 'https://www.coengadvisors.com/'},
 {'domain': 'cyboenergy.com',
  'firm_name': 'CyboEnergy',
  'url': 'http://cyboenergy.com/'},
 {'domain': 'emd-technologies.com',
  'firm_name': 'EMD Technologies Inc.',
  'url': 'https://emd-technologies.com/'},
 {'domain': 'www.energen.com',
  'firm_name': 'Energen',
  'url': 'http://www.energen.com'},
 {'domain': 'www.ferro.com',
  'firm_name': 'Ferro Corporation',
  'url': 'https://www.ferro.com/'},
 {'domain': 'fullcirclebiochar.com',
  'firm_name': 'FULL CIRCLE BIOCHAR',
  'url': 'http://fullcirclebiochar.com/'},
 {'domain': 'gileadcs.org',
  'firm_name': 'Gilead Connecticut',
  'url': 'http://gileadcs.org/'},
 {'domain': 'glucanbio.com',
  'firm_name': 'Glucan Biorenewables LLC',
  'url': 'http://glucanbio.com/'},
 {'domain': 'www.goalzero.com',
  'firm_name': 'GOAL ZERO LLC',
  'url': 'https://www.goalzero.com/'},
 {'domain': 'iinano.org',
  'firm_name': 'NanoOncology',
  'url': 'https://iinano.org/nanooncology'},
 {'domain': 'www.immunolight.com',
  'firm_name': 'Immunolight',
  'url': 'http://www.immunolight.com/'},
 {'domain': 'iogen.ca',
  'firm_name': 'Iogen Corporation',
  'url': 'http://iogen.ca/'},
 {'domain': 'kinetechpower.com',
  'firm_name': 'Kinetech Power Company LLC',
  'url': 'https://kinetechpower.com/'},
 {'domain': 'krdesignhouse.com',
  'firm_name': 'KR Design House',
  'url': 'http://krdesignhouse.com/'},
 {'domain': 'www.lumenbioscience.com',
  'firm_name': 'Matrix Genetics',
  'url': 'https://www.lumenbioscience.com/'},
 {'domain': 'luxbiogroup.com',
  'firm_name': 'Lux Bio Group',
  'url': 'http://luxbiogroup.com/'},
 {'domain': 'magnoliasolar.com',
  'firm_name': 'Magnolia Solar',
  'url': 'http://magnoliasolar.com/'},
 {'domain': 'magnoliasolar.com',
  'firm_name': 'Magnolia Solar',
  'url': 'http://magnoliasolar.com/'},
 {'domain': 'www.mattson.com',
  'firm_name': 'Mattson Technology',
  'url': 'https://www.mattson.com/'},
 {'domain': 'www.michelin.com',
  'firm_name': 'Michelin Recherche et Technique S.A.',
  'url': 'https://www.michelin.com/'},
 {'domain': 'microcoolingconcepts.com',
  'firm_name': 'Micro Cooling Concepts',
  'url': 'http://microcoolingconcepts.com/'},
 {'domain': 'nanogram.com',
  'firm_name': 'NanoGram Corporation',
  'url': 'http://nanogram.com/'},
 {'domain': 'newholdllc.com',
  'firm_name': 'Newdoll Enterprises LLC',
  'url': 'http://newholdllc.com/'},
 {'domain': 'www.nutraceutical.com',
  'firm_name': 'U.S. NUTRACEUTICALS',
  'url': 'https://www.nutraceutical.com/'},
 {'domain': 'paymaster.com',
  'firm_name': 'The Paymaster Corporation',
  'url': 'https://paymaster.com/'},
 {'domain': 'pharmatrophix.com',
  'firm_name': 'Pharmatrophix',
  'url': 'http://pharmatrophix.com/'},
 {'domain': 'www.plantsensorysystems.com',
  'firm_name': 'Plant Sensory Systems',
  'url': 'https://www.plantsensorysystems.com/'},
 {'domain': 'port-a-fire.ca',
  'firm_name': 'PortaFire',
  'url': 'http://port-a-fire.ca/'},
 {'domain': 'samsungsdi.com',
  'firm_name': 'Samsung SDI Co.',
  'url': 'http://samsungsdi.com/'},
 {'domain': 'www.sintoninstruments.com',
  'firm_name': 'Sinton Consulting',
  'url': 'https://www.sintoninstruments.com/'},
 {'domain': 'sol-electrica.com',
  'firm_name': 'SOL-ELECTRICA',
  'url': 'http://sol-electrica.com/'},
 {'domain': 'www.solenafuels.com',
  'firm_name': 'SOLENA FUELS CORPORATION',
  'url': 'http://www.solenafuels.com/'},
 {'domain': 'www.soliton.com',
  'firm_name': 'Soliton Lasers',
  'url': 'https://www.soliton.com/'},
 {'domain': 'www.ssxray.com',
  'firm_name': 'S&S X-Ray Products',
  'url': 'http://www.ssxray.com/'},
 {'domain': 'starsource.com',
  'firm_name': 'Starsource Scientific LLC',
  'url': 'http://starsource.com/about/?41.html'},
 {'domain': 'sunsynchrony.com',
  'firm_name': 'Sun Synchrony',
  'url': 'http://sunsynchrony.com/'},
 {'domain': 'suntegrasolar.com',
  'firm_name': 'Integrated Solar Technology',
  'url': 'http://suntegrasolar.com/'},
 {'domain': 'www.verlase.com',
  'firm_name': 'VERLASE TECHNOLOGIES LLC',
  'url': 'http://www.verlase.com/'},
 {'domain': 'weccamerica.com',
  'firm_name': 'Wave Energy Conversion Corporation of America',
  'url': 'https://weccamerica.com/'},
 {'domain': 'wellconnectgeo.com',
  'firm_name': 'Terra Caloric',
  'url': 'https://wellconnectgeo.com/'},
 {'domain': 'xtalsolar.com',
  'firm_name': 'Crystal Solar Inc.',
  'url': 'http://xtalsolar.com/'},
 {'domain': 'xtalsolar.com',
  'firm_name': 'Crystal Solar Incorporated',
  'url': 'http://xtalsolar.com/'},
 {'domain': 'www.ablexis.com',
  'firm_name': 'Ablexis',
  'url': 'http://www.ablexis.com/'},
 {'domain': 'www.ablic.com',
  'firm_name': 'SII Semiconductor Corporation',
  'url': 'https://www.ablic.com/en/semicon/'},
 {'domain': 'www.allianceforsustainableenergy.org',
  'firm_name': 'Alliance for Sustainable Energy',
  'url': 'http://www.allianceforsustainableenergy.org/'},
 {'domain': 'arkival.com',
  'firm_name': 'Arkival Technology Corp.',
  'url': 'http://arkival.com/'},
 {'domain': 'astech.com', 'firm_name': 'Astech', 'url': 'https://astech.com/'},
 {'domain': 'www.coactivehs.com',
  'firm_name': 'Coactive Drive Corporation',
  'url': 'https://www.coactivehs.com/team/'},
 {'domain': 'corporate.ford.com',
  'firm_name': 'Ford Global Technologies',
  'url': 'https://corporate.ford.com/innovation.html'},
 {'domain': 'www.eni.com',
  'firm_name': 'ENI Technology',
  'url': 'https://www.eni.com/en_IT/innovation.page'},
 {'domain': 'frontedgetechnology.com',
  'firm_name': 'FRONT EDGE TECHNOLOGY INC.',
  'url': 'http://frontedgetechnology.com/'},
 {'domain': 'www.gartner.com',
  'firm_name': 'Bi-Modal Corporation',
  'url': 'https://www.gartner.com/it-glossary/bimodal'},
 {'domain': 'genescopartners.com',
  'firm_name': 'Genesco Inc.',
  'url': 'http://genescopartners.com/'},
 {'domain': 'growenergy.org',
  'firm_name': 'GROW ENERGY',
  'url': 'http://growenergy.org/'},
 {'domain': 'hm3energy.com',
  'firm_name': 'HM3 Energy',
  'url': 'http://hm3energy.com/'},
 {'domain': 'www.htstechnologies.com',
  'firm_name': 'HTS',
  'url': 'http://www.htstechnologies.com/'},
 {'domain': 'linneindustries.com',
  'firm_name': 'Linne Industries LLC',
  'url': 'http://linneindustries.com/'},
 {'domain': 'www.luminultra.com',
  'firm_name': 'Gestion Ultra International Inc.',
  'url': 'https://www.luminultra.com/'},
 {'domain': 'microcontinuum.com',
  'firm_name': 'MicroContinuum',
  'url': 'http://microcontinuum.com/'},
 {'domain': 'nanoquantum.com',
  'firm_name': 'Nanoquantum Sciences',
  'url': 'http://nanoquantum.com/'},
 {'domain': 'www.neuralsignals.com',
  'firm_name': 'Neural Signals',
  'url': 'http://www.neuralsignals.com/'},
 {'domain': 'www.newtechvc.com',
  'firm_name': 'New Technology Ventures',
  'url': 'https://www.newtechvc.com/'},
 {'domain': 'npimobile.com',
  'firm_name': 'Neutronic Perpetual Innovations',
  'url': 'http://npimobile.com/'},
 {'domain': 'oasdesigngroup.com',
  'firm_name': 'OAS Design Group',
  'url': 'http://oasdesigngroup.com/'},
 {'domain': 'www.panasonic.com',
  'firm_name': 'Sanyo Electric Co.',
  'url': 'https://www.panasonic.com/global/corporate/profile/group-companies/sanyo.html'},
 {'domain': 'plasmawhirl.com',
  'firm_name': 'Foret Plasma Labs',
  'url': 'http://plasmawhirl.com/'},
 {'domain': 'www.renovacareinc.com',
  'firm_name': 'RenovaCare Sciences Corp.',
  'url': 'https://www.renovacareinc.com/contact/'},
 {'domain': 'smebeam.com',
  'firm_name': 'Surebeam Corporation',
  'url': 'http://smebeam.com/'},
 {'domain': 'www.solartonic.com',
  'firm_name': 'SOLARTONIC',
  'url': 'http://www.solartonic.com/'},
 {'domain': 'sumitomorubber-usa.com',
  'firm_name': 'Sumitomo Rubber Industries',
  'url': 'https://sumitomorubber-usa.com/'},
 {'domain': 'www.symbols.com',
  'firm_name': 'Simbol Inc.',
  'url': 'https://www.symbols.com/'},
 {'domain': 'www.them.net',
  'firm_name': 'T.H.E.M.',
  'url': 'http://www.them.net/'},
 {'domain': 'www.thewaltdisneycompany.com',
  'firm_name': 'Disney Enterprises',
  'url': 'https://www.thewaltdisneycompany.com/'},
 {'domain': 'thornbioscience.com',
  'firm_name': 'Thorn Bioscience LLC',
  'url': 'http://thornbioscience.com/'},
 {'domain': 'www.total.com',
  'firm_name': 'Total Marketing Services',
  'url': 'https://www.total.com/en'},
 {'domain': 'tpsolar.nl',
  'firm_name': 'TP Solar',
  'url': 'https://tpsolar.nl/?lang=en'},
 {'domain': 'www.uvic.ca',
  'firm_name': 'UVIC INDUSTRY PARTNERSHIPS INC.',
  'url': 'https://www.uvic.ca/research/partner/index.php'},
 {'domain': 'vindicoat.com'2018-11-11 04:02:40 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: FirmDB)
2018-11-11 04:02:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.6 (default, Sep 12 2018, 18:26:19) - [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Linux-4.15.0-1023-aws-x86_64-with-Ubuntu-18.04-bionic
2018-11-11 04:02:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'FirmDB', 'CONCURRENT_REQUESTS_PER_DOMAIN': 4, 'DEPTH_LIMIT': '1', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'FirmDB.spiders', 'ROBOTSTXT_OBEY': 'False', 'SPIDER_MODULES': ['FirmDB.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36'}
2018-11-11 04:02:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-11-11 04:02:40 [py.warnings] WARNING: /home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2018-11-11 04:02:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'random_useragent.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-11 04:02:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-11 04:02:40 [scrapy.middleware] INFO: Enabled item pipelines:
['FirmDB.pipelines.FirmDBPipeline']
2018-11-11 04:02:40 [scrapy.core.engine] INFO: Spider opened
2018-11-11 04:02:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-11 04:02:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://iinano.org/config.php>: HTTP status code is not handled or not allowed
2018-11-11 04:03:49 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 46 pages/min), scraped 12 items (at 12 items/min)
/bin/sh: 1: kill: Illegal number: 
/bin/sh: 1: kill: Illegal number: 
2018-11-11 04:04:41 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 5 pages/min), scraped 24 items (at 12 items/min)
2018-11-11 04:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.michelin.com/fre/lang/switch/eng/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 04:05:45 [scrapy.extensions.logstats] INFO: Crawled 65 pages (at 14 pages/min), scraped 34 items (at 10 items/min)
,
  'firm_name': 'VINDICO NANOBIO TECHNOLOGY INC.',
  'url': 'http://vindicoat.com/joomla1/'},
 {'domain': 'www.voragotech.com',
  'firm_name': 'Silicon Space Technology Corp.',
  'url': 'https://www.voragotech.com/'},
 {'domain': 'www.westec.org',
  'firm_name': 'Wostec',
  'url': 'https://www.westec.org/'},
 {'domain': 'wet-flash.com',
  'firm_name': 'Building Envelope Innovations',
  'url': 'http://wet-flash.com/'},
 {'domain': 'www.admaproducts.com',
  'firm_name': 'ADMA Products',
  'url': 'https://www.admaproducts.com/#!'},
 {'domain': 'www.adynxx.com',
  'firm_name': 'Adynxx',
  'url': 'http://www.adynxx.com/'},
 {'domain': 'annambiosciences.com',
  'firm_name': 'Annam Biosciences',
  'url': 'http://annambiosciences.com/'},
 {'domain': 'atleisure.com',
  'firm_name': 'Atleisure LLC',
  'url': 'http://atleisure.com/'},
 {'domain': 'www.brother-usa.com',
  'firm_name': 'Brother International Corporation',
  'url': 'https://www.brother-usa.com/'},
 {'domain': 'www.coopertechnologies.net',
  'firm_name': 'Cooper Technologies Company',
  'url': 'https://www.coopertechnologies.net/'},
 {'domain': 'enginuityww.webstarts.com',
  'firm_name': 'Enginuity Worldwide',
  'url': 'http://enginuityww.webstarts.com/'},
 {'domain': 'www.gracenote.com',
  'firm_name': 'Gracenote',
  'url': 'http://www.gracenote.com/'},
 {'domain': 'graphenetechnologies.com',
  'firm_name': 'Graphene Technologies',
  'url': 'http://graphenetechnologies.com/'},
 {'domain': 'www.greenextractiontechnologiesllc.com',
  'firm_name': 'Green Extraction Technologies',
  'url': 'https://www.greenextractiontechnologiesllc.com/'},
 {'domain': 'huntenergyenterprises.com',
  'firm_name': 'Hunt Energy Enterprises LLC',
  'url': 'http://huntenergyenterprises.com/'},
 {'domain': 'www.j-oled.com',
  'firm_name': 'JOLED Inc.',
  'url': 'https://www.j-oled.com/'},
 {'domain': 'jewhites.com.au',
  'firm_name': 'J. E. WHITE',
  'url': 'http://jewhites.com.au/'}]
Missing True-Safe Technologies, Intel Corporation, King Electric Vehicles Inc. in the fixed urls list
Pages to scrape: ['http://acaciaresearch.com/', 'https://celanese.com/engineered-materials/engineered-materials.aspx', 'https://www.coengadvisors.com/', 'http://cyboenergy.com/', 'https://emd-technologies.com/', 'http://www.energen.com', 'https://www.ferro.com/', 'http://fullcirclebiochar.com/', 'http://gileadcs.org/', 'http://glucanbio.com/', 'https://www.goalzero.com/', 'https://iinano.org/nanooncology', 'http://www.immunolight.com/', 'http://iogen.ca/', 'https://kinetechpower.com/', 'http://krdesignhouse.com/', 'https://www.lumenbioscience.com/', 'http://luxbiogroup.com/', 'http://magnoliasolar.com/', 'http://magnoliasolar.com/', 'https://www.mattson.com/', 'https://www.michelin.com/', 'http://microcoolingconcepts.com/', 'http://nanogram.com/', 'http://newholdllc.com/', 'https://www.nutraceutical.com/', 'https://paymaster.com/', 'http://pharmatrophix.com/', 'https://www.plantsensorysystems.com/', 'http://port-a-fire.ca/', 'http://samsungsdi.com/', 'https://www.sintoninstruments.com/', 'http://sol-electrica.com/', 'http://www.solenafuels.com/', 'https://www.soliton.com/', 'http://www.ssxray.com/', 'http://starsource.com/about/?41.html', 'http://sunsynchrony.com/', 'http://suntegrasolar.com/', 'http://www.verlase.com/', 'https://weccamerica.com/', 'https://wellconnectgeo.com/', 'http://xtalsolar.com/', 'http://xtalsolar.com/', 'http://www.ablexis.com/', 'https://www.ablic.com/en/semicon/', 'http://www.allianceforsustainableenergy.org/', 'http://arkival.com/', 'https://astech.com/', 'https://www.coactivehs.com/team/', 'https://corporate.ford.com/innovation.html', 'https://www.eni.com/en_IT/innovation.page', 'http://frontedgetechnology.com/', 'https://www.gartner.com/it-glossary/bimodal', 'http://genescopartners.com/', 'http://growenergy.org/', 'http://hm3energy.com/', 'http://www.htstechnologies.com/', 'http://linneindustries.com/', 'https://www.luminultra.com/', 'http://microcontinuum.com/', 'http://nanoquantum.com/', 'http://www.neuralsignals.com/', 'https://www.newtechvc.com/', 'http://npimobile.com/', 'http://oasdesigngroup.com/', 'https://www.panasonic.com/global/corporate/profile/group-companies/sanyo.html', 'http://plasmawhirl.com/', 'https://www.renovacareinc.com/contact/', 'http://smebeam.com/', 'http://www.solartonic.com/', 'https://sumitomorubber-usa.com/', 'https://www.symbols.com/', 'http://www.them.net/', 'https://www.thewaltdisneycompany.com/', 'http://thornbioscience.com/', 'https://www.total.com/en', 'https://tpsolar.nl/?lang=en', 'https://www.uvic.ca/research/partner/index.php', 'http://vindicoat.com/joomla1/', 'https://www.voragotech.com/', 'https://www.westec.org/', 'http://wet-flash.com/', 'https://www.admaproducts.com/#!', 'http://www.adynxx.com/', 'http://annambiosciences.com/', 'http://atleisure.com/', 'https://www.brother-usa.com/', 'https://www.coopertechnologies.net/', 'http://enginuityww.webstarts.com/', 'http://www.gracenote.com/', 'http://graphenetechnologies.com/', 'https://www.greenextractiontechnologiesllc.com/', 'http://huntenergyenterprises.com/', 'https://www.j-oled.com/', 'http://jewhites.com.au/']
Crawling page: http://cyboenergy.com/index.html       valid
Crawling page: http://gileadcs.org       valid
Crawling page: http://microcoolingconcepts.com/TurbineBlade.html       valid
Crawling page: http://gileadcs.org/news-events/major-donor-event/       valid
Crawling page: http://gileadcs.org/advocacy-center/take-action/       valid
Crawling page: http://gileadcs.org/advocacy-center/legislative-events/       valid
Crawling page: http://microcoolingconcepts.com/CryoCoolerConductance.html       valid
Crawling page: http://www.immunolight.com/sitemap/       valid
Crawling page: http://gileadcs.org/news-events/matching-campaign/       valid
Crawling page: http://gileadcs.org/news-events/annual-appeal/       valid
Crawling page: http://gileadcs.org/stay-in-touch/       valid
Crawling page: https://www.goalzero.com/shop/last-chance-gear/       valid
Crawling page: http://fullcirclebiochar.com/news-category/virgin-pioneer/       valid
Crawling page: http://fullcirclebiochar.com/news-category/press-release-full-circle-biochar-named-virgin-earth-challenge-finalist/       valid
Crawling page: http://fullcirclebiochar.com/contact/       valid
Crawling page: http://fullcirclebiochar.com/news/       valid
Crawling page: http://fullcirclebiochar.com/people/advisors/       valid
Crawling page: http://fullcirclebiochar.com/people/board-of-directors/       valid
Crawling page: http://fullcirclebiochar.com/people/team-and-management/       valid
Crawling page: http://fullcirclebiochar.com/people/       valid
Crawling page: http://luxbiogroup.com/       valid
Crawling page: http://luxbiogroup.com/contact.html       valid
Crawling page: https://www.lumenbioscience.com       valid
Crawling page: https://emd-technologies.com/       valid
Crawling page: https://www.coengadvisors.com       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/wood-coatings-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/paper-coating-emulsions-americas.aspx       valid
Crawling page: http://fullcirclebiochar.com/company/       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/interior-wall-and-trim-paints-and-primers-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/high-loft-nonwoven-emulsions-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/paper-packaging-and-converting-adhesives-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/paper-saturationspecialties-emulsions-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/paperboard-coating-emulsions-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/tufcor.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/trumoda.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/nacrylic.aspx       valid
Crawling page: https://celanese.com/privacy-policy2018-11-11 04:06:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://investors.celanese.com> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 04:06:36 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "buyticonadirect.celanese.com"; VerificationError(errors=[DNSMismatch(mismatched_id=DNS_ID(hostname=b'buyticonadirect.celanese.com'))])
2018-11-11 04:07:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tools.celanese.com/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 04:07:05 [scrapy.extensions.logstats] INFO: Crawled 76 pages (at 11 pages/min), scraped 46 items (at 12 items/min)
2018-11-11 04:07:55 [scrapy.extensions.logstats] INFO: Crawled 87 pages (at 11 pages/min), scraped 56 items (at 10 items/min)
2018-11-11 04:08:47 [scrapy.extensions.logstats] INFO: Crawled 100 pages (at 13 pages/min), scraped 66 items (at 10 items/min)
2018-11-11 04:09:53 [scrapy.extensions.logstats] INFO: Crawled 109 pages (at 9 pages/min), scraped 79 items (at 13 items/min)
2018-11-11 04:11:00 [scrapy.extensions.logstats] INFO: Crawled 121 pages (at 12 pages/min), scraped 91 items (at 12 items/min)
2018-11-11 04:11:46 [scrapy.extensions.logstats] INFO: Crawled 129 pages (at 8 pages/min), scraped 99 items (at 8 items/min)
2018-11-11 04:12:47 [scrapy.extensions.logstats] INFO: Crawled 141 pages (at 12 pages/min), scraped 111 items (at 12 items/min)
       valid
Crawling page: https://celanese.com/global-quality-policy.aspx       valid
Crawling page: https://celanese.com/careers.aspx       valid
Crawling page: https://celanese.com/uk-tax-policy.aspx       valid
Crawling page: https://celanese.com/California%20Transparency%20Act.aspx       valid
Crawling page: https://celanese.com/Cautionary%20Statements.aspx       valid
Crawling page: http://investors.celanese.com       Crawling page: https://celanese.com/privacy-policy.aspx       valid
Crawling page: https://celanese.com/disclaimer.aspx       valid
Crawling page: https://celanese.com/engineered-materials/Contact-Us.aspx       valid
Crawling page: https://celanese.com/engineered-materials/Innovation.aspx       valid
Crawling page: http://tools.celanese.com/       Crawling page: https://celanese.com/engineered-materials/Technical-Information.aspx       valid
Crawling page: https://celanese.com/engineered-materials/News-and-Media.aspx       valid
Crawling page: https://celanese.com/engineered-materials/Tribological-Material-Solutions-for-Sliding-Parts.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products.aspx       valid
Crawling page: https://celanese.com/engineered-materials/literature-media.aspx       valid
Crawling page: https://celanese.com/engineered-materials/engineered-materials-auto-specification.aspx       valid
Crawling page: https://celanese.com/engineered-materials/Application%20List.aspx?app=&sc_device=ajax       valid
Crawling page: https://celanese.com/About-Us.aspx       valid
Crawling page: https://celanese.com/innovation.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/x-link.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/vinamul.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/flexbond.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/dur-o-set.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/hiloft.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/vinac.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/dur-o-cote.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/celvaset.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/britecoat.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/avicor.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/vectra-lcpzenite-lcp.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/vandar-pbt.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/thermx--pct.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/riteflex-tpc-et.aspx       valid
Crawling page: https://my.celanese.com/       valid
Crawling page: https://celanese.com/engineered-materials/products/celapex-peek.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/impet--pet.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/hostaform-pom--celcon-pom.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/gur-uhmw-pe.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/frianyl.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/fortron-pps.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/ecomid.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/coolpoly-tcp.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/compel-lfrt.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/acetate-film.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/celstran-lfrt.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/celstran-cfrt.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/celanyl-pa-and-nilamid-pa.aspx       valid
Crawling page: https://celanese.com/engineered-materials/products/celanex--pbt.aspx       valid
Crawling page: https://celanese.com/food-ingredients/products/vinosorb.aspx       valid
Crawling page: https://celanese.com/food-ingredients/products/sunett.aspx       valid
Crawling page: https://celanese.com/food-ingredients/products/panosorb.aspx       valid
Crawling page: https://celanese.com/food-ingredients/products/nutrinova-sorbic-acid.aspx       valid
Crawling page: https://celanese.com/food-ingredients/products/nutrinova-potassium-sorbate.aspx       valid
Crawling page: https://celanese.com/eva-polymers/products/vitaldose-pharmaceutical-grade.aspx       valid
Crawling page: https://celanese.com/eva-polymers/products/ldpe.aspx       valid
Crawling page: https://celanese.com/eva-polymers/products/ateva-g-medical-grade.aspx       valid
Crawling page: https://celanese.com/eva-polymers/products/ateva.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/woodworking-adhesives-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/glass-fiber-sizing-polymers-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/exerior%20paints%20and%20primers%20americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/products/ecovae.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/durable-nonwoven-emulsions-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/disposable-nonwoven-emulsions-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/carpet-backing-adhesivecoating-emulsions-americas.aspx       valid
Crawling page: https://celanese.com/emulsion-polymers/product-groups/building-materials-americas.aspx       valid
Crawling page: https://celanese.com/cellulose-derivatives/products/celfx.aspx       valid
Crawling page: https://celanese.com/cellulose-derivatives/products/acetate-tow-nonwoven.aspx       valid
Crawling page: https://celanese.com/cellulose-derivatives/products/acetate-tow.aspx       valid
Crawling page: https://celanese.com/cellulose-derivatives/products/acetate-flake.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/vinyl-acetate.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/trimethylamine.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/saib.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/propionic-anhydride.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/polysolvan-o.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/wvc-3800.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/paraformaldehyde.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/n-butyl-acetate.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/mibk.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/mibc.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/methyl-acetate.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/isobutyric-anhydride.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/formaldehyde.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/ethyl-acetate.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/dioctyl-maleate-dom.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/dimethylamine.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/dibutyl-maleate-dbm.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/crotonaldehyde.aspx2018-11-11 04:13:47 [scrapy.extensions.logstats] INFO: Crawled 153 pages (at 12 pages/min), scraped 123 items (at 12 items/min)
2018-11-11 04:14:48 [scrapy.extensions.logstats] INFO: Crawled 168 pages (at 15 pages/min), scraped 135 items (at 12 items/min)
2018-11-11 04:15:44 [scrapy.extensions.logstats] INFO: Crawled 176 pages (at 8 pages/min), scraped 142 items (at 7 items/min)
2018-11-11 04:16:57 [scrapy.extensions.logstats] INFO: Crawled 185 pages (at 9 pages/min), scraped 155 items (at 13 items/min)
2018-11-11 04:17:58 [scrapy.extensions.logstats] INFO: Crawled 197 pages (at 12 pages/min), scraped 167 items (at 12 items/min)
2018-11-11 04:18:52 [scrapy.extensions.logstats] INFO: Crawled 205 pages (at 8 pages/min), scraped 178 items (at 11 items/min)
2018-11-11 04:20:00 [scrapy.extensions.logstats] INFO: Crawled 227 pages (at 22 pages/min), scraped 190 items (at 12 items/min)
2018-11-11 04:21:05 [scrapy.extensions.logstats] INFO: Crawled 234 pages (at 7 pages/min), scraped 201 items (at 11 items/min)
2018-11-11 04:21:48 [scrapy.extensions.logstats] INFO: Crawled 241 pages (at 7 pages/min), scraped 208 items (at 7 items/min)
       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/butyric-anhydride.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/butoxyl.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/acetic-anhydride.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/acetic-acid.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/acetaldehyde.aspx       valid
Crawling page: https://celanese.com/intermediate-chemistry/products/3-methoxybutanol.aspx       valid
Crawling page: https://celanese.com/industries/textiles-fibers-and-filtration/liquid-filtration.aspx       valid
Crawling page: https://celanese.com/industries/textiles-fibers-and-filtration/protective-clothing-and-cloth.aspx       valid
Crawling page: https://celanese.com/industries/textiles-fibers-and-filtration/nonwovens.aspx       valid
Crawling page: https://celanese.com/industries/textiles-fibers-and-filtration/extruded-fibers.aspx       valid
Crawling page: https://celanese.com/industries/textiles-fibers-and-filtration/cigarette-filtration.aspx       valid
Crawling page: https://celanese.com/industries/textiles-fibers-and-filtration/carpet.aspx       valid
Crawling page: https://celanese.com/industries/textiles-fibers-and-filtration/apparel.aspx       valid
Crawling page: https://celanese.com/industries/textiles-fibers-and-filtration/air-filtration.aspx       valid
Crawling page: https://celanese.com/industries/personal-care-and-cosmetics/sweeteners.aspx       valid
Crawling page: https://www.coengadvisors.com/contact       valid
Crawling page: https://www.coengadvisors.com/about       valid
Crawling page: https://www.coengadvisors.com/services       valid
Crawling page: https://celanese.com/industries/personal-care-and-cosmetics/supplements-and-vitamins.aspx       valid
Crawling page: https://celanese.com/industries/personal-care-and-cosmetics/solvent.aspx       valid
Crawling page: https://celanese.com/industries/personal-care-and-cosmetics/preservatives.aspx       valid
Crawling page: https://celanese.com/industries/personal-care-and-cosmetics/nonwovens.aspx       valid
Crawling page: https://www.coengadvisors.com/rea       valid
Crawling page: https://celanese.com/industries/personal-care-and-cosmetics/luxury-packaging.aspx       valid
Crawling page: https://celanese.com/industries/personal-care-and-cosmetics/bottles-and-components.aspx       valid
Crawling page: https://celanese.com/industries/personal-care-and-cosmetics/additives.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/water-based-adhesives.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/vinyl-based-emulsion-production.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/solvent.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/preservatives-for-non-food.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/paper-saturationspecialty-papers.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/paperpaperboard-coating.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/medical-packaging.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/luxury-packaging.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/lamination.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/inks.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/hot-melt-adhesives.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/foam.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/flexible-packaging-and-film.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/bottles-and-components.aspx       valid
Crawling page: https://celanese.com/industries/packaging-film-and-printing/additives.aspx       valid
Crawling page: https://celanese.com/industries/oil-gas-and-mining/pipe-and-liner.aspx       valid
Crawling page: https://celanese.com/industries/oil-gas-and-mining/oil-and-gas-extraction.aspx       valid
Crawling page: https://celanese.com/industries/oil-gas-and-mining/flotation-agent.aspx       valid
Crawling page: https://celanese.com/industries/oil-gas-and-mining/downhole-tubing.aspx       valid
Crawling page: https://celanese.com/industries/oil-gas-and-mining/additives.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/tubing.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/sweeteners.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/supplements-and-vitamins.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/solvent.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/protective-clothing-and-cloth.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/preservatives.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/paper-saturationspecialty-papers.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/orthopedic-implants.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/optical.aspx       valid
Crawling page: https://emd-technologies.com/fr/164-2/       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/nonwovens.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/medical-supplies.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/medical-filtration.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/medical-devices.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/medical-packaging.aspx       valid
Crawling page: https://emd-technologies.com/products/radiography/       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/inks.aspx       valid
Crawling page: https://celanese.com/industries/medical-and-pharma/drug-delivery.aspx       valid
Crawling page: https://celanese.com/industries/industrial/wire-and-cable-coating.aspx       valid
Crawling page: https://celanese.com/industries/industrial/water-based-adhesives.aspx       valid
Crawling page: https://www.lumenbioscience.com/privacy       valid
Crawling page: https://www.lumenbioscience.com/terms       valid
Crawling page: https://www.lumenbioscience.com/website-terms-of-use       valid
Crawling page: https://celanese.com/industries/industrial/tools-and-equipment.aspx       valid
Crawling page: https://celanese.com/industries/industrial/solvent.aspx       valid
Crawling page: https://celanese.com/industries/industrial/nonwovens.aspx       valid
Crawling page: https://emd-technologies.com/products/mammography/       valid
Crawling page: https://emd-technologies.com/products/radiography-fluoroscopy/       valid
Crawling page: https://emd-technologies.com/products/cardiovascular/       valid
Crawling page: https://www.lumenbioscience.com/careers       valid
Crawling page: https://emd-technologies.com/products/       valid
Crawling page: https://celanese.com/industries/industrial/material-handling.aspx       valid
Crawling page: https://celanese.com/industries/industrial/insulation.aspx       valid
Crawling page: https://celanese.com/industries/industrial/hvac-fire-control-safety.aspx       valid
Crawling page: https://celanese.com/industries/industrial/hot-melt-adhesives.aspx       valid
Crawling page: https://www.lumenbioscience.com/news       valid
Crawling page: https://celanese.com/industries/industrial/gears.aspx       valid
Crawling page: https://emd-technologies.com/news/       valid
Crawling page: https://emd-technologies.com/contact-us/       valid
Crawling page:2018-11-11 04:22:43 [scrapy.extensions.logstats] INFO: Crawled 253 pages (at 12 pages/min), scraped 220 items (at 12 items/min)
2018-11-11 04:23:45 [scrapy.extensions.logstats] INFO: Crawled 263 pages (at 10 pages/min), scraped 232 items (at 12 items/min)
2018-11-11 04:24:53 [scrapy.extensions.logstats] INFO: Crawled 282 pages (at 19 pages/min), scraped 247 items (at 15 items/min)
2018-11-11 04:25:56 [scrapy.extensions.logstats] INFO: Crawled 291 pages (at 9 pages/min), scraped 261 items (at 14 items/min)
2018-11-11 04:26:46 [scrapy.extensions.logstats] INFO: Crawled 300 pages (at 9 pages/min), scraped 270 items (at 9 items/min)
2018-11-11 04:27:50 [scrapy.extensions.logstats] INFO: Crawled 312 pages (at 12 pages/min), scraped 282 items (at 12 items/min)
2018-11-11 04:28:53 [scrapy.extensions.logstats] INFO: Crawled 324 pages (at 12 pages/min), scraped 294 items (at 12 items/min)
 https://celanese.com/industries/industrial/foam.aspx       valid
Crawling page: https://celanese.com/industries/industrial/flexible-packaging-and-film.aspx       valid
Crawling page: https://celanese.com/industries/industrial/compounds-and-composites.aspx       valid
Crawling page: https://celanese.com/industries/industrial/building-materials.aspx       valid
Crawling page: https://celanese.com/industries/industrial/additives.aspx       valid
Crawling page: https://celanese.com/industries/food-and-beverage/water-based-adhesives.aspx       valid
Crawling page: https://celanese.com/industries/food-and-beverage/tubing.aspx       valid
Crawling page: https://celanese.com/industries/food-and-beverage/sweeteners.aspx       valid
Crawling page: https://celanese.com/industries/food-and-beverage/preservatives.aspx       valid
Crawling page: https://celanese.com/industries/food-and-beverage/paper-saturationspecialty-papers.aspx       valid
Crawling page: https://celanese.com/industries/food-and-beverage/food-additive.aspx       valid
Crawling page: https://celanese.com/industries/food-and-beverage/flexible-packaging-and-film.aspx       valid
Crawling page: https://celanese.com/industries/fluid-handling/liquid-filtration.aspx       valid
Crawling page: https://celanese.com/industries/fluid-handling/kitchen-and-bath.aspx       valid
Crawling page: https://celanese.com/industries/fluid-handling/irrigation.aspx       valid
Crawling page: https://celanese.com/industries/energy/wind.aspx       valid
Crawling page: https://celanese.com/industries/energy/water.aspx       valid
Crawling page: https://celanese.com/industries/energy/solar.aspx       valid
Crawling page: https://celanese.com/industries/energy/fuel.aspx       valid
Crawling page: https://celanese.com/industries/energy/batteries.aspx       valid
Crawling page: https://celanese.com/industries/electrical-and-electronics/wire-and-cable-coating.aspx       valid
Crawling page: https://celanese.com/industries/electrical-and-electronics/sensors-and-switches.aspx       valid
Crawling page: https://celanese.com/industries/electrical-and-electronics/office-equipment.aspx       valid
Crawling page: https://celanese.com/industries/electrical-and-electronics/lighting.aspx       valid
Crawling page: https://celanese.com/industries/electrical-and-electronics/glass-fiber.aspx       valid
Crawling page: https://celanese.com/industries/electrical-and-electronics/components.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/wood-processing.aspx       valid
Crawling page: https://emd-technologies.com/wp-login.php?redirect_to=https%3A%2F%2Femd-technologies.com%2Fcustomer-area%2F       valid
Crawling page: https://celanese.com/industries/consumer-goods/water-based-adhesives.aspx       valid
Crawling page: https://www.mattson.com/contact-us/worldwide-locations/       valid
Crawling page: https://www.mattson.com/contact-us/       valid
Crawling page: https://www.mattson.com/careers/       valid
Crawling page: https://www.mattson.com/technology/millisecond-anneal/       valid
Crawling page: https://www.mattson.com/technology/mature-products/       valid
Crawling page: https://www.mattson.com/customer-support/       valid
Crawling page: https://www.mattson.com/technology/rapid-thermal-processing/       valid
Crawling page: https://www.mattson.com/technology/surface-treatment-and-ultra-selective-materials-removal/       valid
Crawling page: https://www.mattson.com/technology/plasma-etch/       valid
Crawling page: https://www.mattson.com/privacy-policy/       valid
Crawling page: https://www.mattson.com/technology/dry-strip/       valid
Crawling page: https://www.mattson.com/technology/       valid
Crawling page: https://www.mattson.com/about-us/supply-chain/       valid
Crawling page: https://www.mattson.com/about-us/quality/       valid
Crawling page: https://www.mattson.com/about-us/environmental-health-and-safety/       valid
Crawling page: https://www.mattson.com/about-us/corporate-governance/       valid
Crawling page: https://www.mattson.com/about-us/corporate-responsibility/       valid
Crawling page: https://www.mattson.com/about-us/management-team/       valid
Crawling page: https://celanese.com/industries/consumer-goods/tapes-and-labels.aspx       valid
Crawling page: https://www.mattson.com/about-us/       valid
Crawling page: https://celanese.com/industries/consumer-goods/sporting-goods-and-toys.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/paper-saturationspecialty-papers.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/paperpaperboard-coating.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/optical.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/nonwovens.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/lamination.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/furniture.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/lawn-and-garden.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/foam.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/cookware.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/consumer-electronics.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/carpet.aspx       valid
Crawling page: https://celanese.com/industries/consumer-goods/acetate-granules.aspx       valid
Crawling page: https://celanese.com/industries/coatings/vinyl-based-emulsion-production.aspx       valid
Crawling page: https://celanese.com/industries/coatings/solvent.aspx       valid
Crawling page: https://celanese.com/industries/coatings/paperpaperboard-coating.aspx       valid
Crawling page: https://celanese.com/industries/coatings/lamination.aspx       valid
Crawling page: https://celanese.com/industries/coatings/industrial-coatings.aspx       valid
Crawling page: https://celanese.com/industries/coatings/formaldehyde-based-resins.aspx       valid
Crawling page: https://celanese.com/industries/coatings/carpet.aspx       valid
Crawling page: https://celanese.com/industries/coatings/building-materials.aspx       valid
Crawling page: https://celanese.com/industries/coatings/architecturaldecorative-coatings.aspx       valid
Crawling page: https://celanese.com/industries/coatings/additives.aspx       valid
Crawling page: https://celanese.com/industries/chemicals/vinyl-based-emulsion-production.aspx       valid
Crawling page: https://celanese.com/industries/chemicals/solvent.aspx       valid
Crawling page: https://celanese.com/industries/chemicals/oil-and-gas-extraction.aspx       valid
Crawling page: https://celanese.com/industries/chemicals/lube-and-rubber-additives.aspx       valid
Crawling page: https://celanese.com/industries/chemicals/inks.aspx       valid
Crawling page: https://celanese.com/industries/chemicals/formaldehyde-based-resins.aspx       valid
Crawling page: https://celanese.com/industries/chemicals/films.aspx       valid
Crawling page: https://celanese.com/industries/chemicals/architecturaldecorative-coatings.aspx       valid
Crawling page: https://celanese.com/industries/chemicals/additives.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/water-based-adhesives.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/pvb-and-pvc-based-resins.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/paper-saturationspecialty-papers.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/nonwovens.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/insulation.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/glass-fiber.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/formaldehyde-based-resins.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/films.aspx       valid
Crawling page:/bin/sh: 1: kill: Illegal number: 
2018-11-11 04:29:46 [scrapy.extensions.logstats] INFO: Crawled 336 pages (at 12 pages/min), scraped 303 items (at 9 items/min)
2018-11-11 04:30:47 [scrapy.extensions.logstats] INFO: Crawled 350 pages (at 14 pages/min), scraped 310 items (at 7 items/min)
2018-11-11 04:31:41 [scrapy.extensions.logstats] INFO: Crawled 350 pages (at 0 pages/min), scraped 316 items (at 6 items/min)
2018-11-11 04:32:42 [scrapy.extensions.logstats] INFO: Crawled 354 pages (at 4 pages/min), scraped 324 items (at 8 items/min)
2018-11-11 04:33:51 [scrapy.extensions.logstats] INFO: Crawled 367 pages (at 13 pages/min), scraped 337 items (at 13 items/min)
2018-11-11 04:34:52 [scrapy.extensions.logstats] INFO: Crawled 381 pages (at 14 pages/min), scraped 349 items (at 12 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 04:35:56 [scrapy.extensions.logstats] INFO: Crawled 390 pages (at 9 pages/min), scraped 363 items (at 14 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 04:36:39 [root] ERROR: Unable to find match for url: http://ir.energen.com/
2018-11-11 04:37:05 [scrapy.extensions.logstats] INFO: Crawled 407 pages (at 17 pages/min), scraped 381 items (at 18 items/min)
2018-11-11 04:37:44 [scrapy.extensions.logstats] INFO: Crawled 417 pages (at 10 pages/min), scraped 391 items (at 10 items/min)
 https://celanese.com/industries/building-and-construction/carpet.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/building-materials.aspx       valid
Crawling page: https://celanese.com/industries/building-and-construction/architecturaldecorative-coatings.aspx       valid
Crawling page: https://www.mattson.com/       valid
Crawling page: https://www.goalzero.com/blog/       valid
Crawling page: https://www.goalzero.com/product-features/accessories-lights-lanterns/       valid
Crawling page: https://www.goalzero.com/product-features/other-accessories/       valid
Crawling page: https://www.goalzero.com/product-features/accessories-cords-adapters/       valid
Crawling page: https://www.goalzero.com/product-features/solar-kits-large-power/       valid
Crawling page: https://www.goalzero.com/product-features/solar-panels-semi-portable/       valid
Crawling page: https://www.goalzero.com/product-features/solar-panels-portable/       valid
Crawling page: https://www.goalzero.com/product-features/solar-kits-medium-power/       valid
Crawling page: https://www.goalzero.com/product-features/solar-kits-small-power/       valid
Crawling page: https://www.goalzero.com/product-features/solar-panels-foldable/       valid
Crawling page: https://www.goalzero.com/product-features/portable-power-stations/       valid
Crawling page: https://www.goalzero.com/product-features/portable-power-banks/       valid
Crawling page: https://www.goalzero.com/product-features/portable-power-rechargers/       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/wire-and-cable-coating.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/vinyl-based-emulsion-production.aspx       valid
Crawling page: https://www.goalzero.com/shop/accessories/       valid
Crawling page: https://www.goalzero.com/shop/lights/       valid
Crawling page: https://www.goalzero.com/shop/solar-kits/       valid
Crawling page: https://www.goalzero.com/shop/solar-panels/       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/solvent.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/powertrain.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/paper-saturationspecialty-papers.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/off-road.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/motorcycle.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/fuel-systems.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/marine.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/nonwovens.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/films.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/fasteners-and-supports.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/chassis-underbody.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/carpet.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/bus-truck-and-rail.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/batteries.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/automotive-interior.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/automotive-exterior.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/automotive-electrical-and-electronic.aspx       valid
Crawling page: https://celanese.com/industries/automotiveandtransportation/additives.aspx       valid
Crawling page: https://celanese.com/industries/appliance/small-appliance.aspx       valid
Crawling page: https://celanese.com/industries/appliance/large-appliance.aspx       valid
Crawling page: https://celanese.com/industries/agriculture/supplements-and-vitamins.aspx       valid
Crawling page: https://celanese.com/industries/agriculture/herbicide.aspx       valid
Crawling page: https://celanese.com/industries/agriculture/additives.aspx       valid
Crawling page: https://celanese.com/industries/aerospace-and-defense/satellites-electronics-and-communications.aspx       valid
Crawling page: https://celanese.com/industries/aerospace-and-defense/commercial-aircraft-and-general-aviation.aspx       valid
Crawling page: https://celanese.com/industries/adhesives/water-based-adhesives.aspx       valid
Crawling page: https://celanese.com/industries/adhesives/vinyl-based-emulsion-production.aspx       valid
Crawling page: https://celanese.com/industries/adhesives/solvent.aspx       valid
Crawling page: https://celanese.com/industries/adhesives/pvb-and-pvc-based-resins.aspx       valid
Crawling page: https://celanese.com/industries/adhesives/hot-melt-adhesives.aspx       valid
Crawling page: https://celanese.com/industries/adhesives/formaldehyde-based-intermediates.aspx       valid
Crawling page: https://celanese.com/industries/adhesives/carpet.aspx       valid
Crawling page: http://luxbiogroup.com/about.html       valid
Crawling page: https://celanese.com/industries/adhesives/building-materials.aspx       valid
Crawling page: http://luxbiogroup.com/index.html       valid
Crawling page: https://celanese.com/industries/adhesives/additives.aspx       valid
Crawling page: https://celanese.com/       valid
Crawling page: https://celanese.com/contact-us.aspx       valid
Crawling page: http://fullcirclebiochar.com       valid
Crawling page: https://celanese.com/engineered-materials/engineered-materials.aspx       valid
Crawling page: http://www.energen.com/Privacy-Policy-502.html       valid
Crawling page: http://www.energen.com/Legal-Notice-501.html       valid
Crawling page: http://www.energen.com/Safe-Harbor-500.html       valid
Crawling page: http://www.energen.com/Operations-472.html       valid
Crawling page: http://www.energen.com/operations-472.html       valid
Crawling page: http://magnoliasolar.com/news/index.php       valid
Crawling page: http://magnoliasolar.com/in_the_news/index.html       valid
Crawling page: http://magnoliasolar.com/news/displaynews.php?newsid=77       valid
Crawling page: http://krdesignhouse.com/       valid
Crawling page: http://www.energen.com/       valid
Crawling page: http://krdesignhouse.com/index.html       valid
Crawling page: http://www.energen.com/corporate-social-responsibility-763.html       valid
Crawling page: http://magnoliasolar.com/facility/index.html       valid
Crawling page: http://ir.energen.com/       valid
Crawling page: http://www.energen.com/About-Energen/Contact-Us-315.html       valid
Crawling page: http://magnoliasolar.com/news/displaynews.php?newsid=79       valid
Crawling page: http://magnoliasolar.com/investors/index.php       valid
Crawling page: http://magnoliasolar.com/news/displaynews.php?newsid=78       valid
Crawling page: http://www.energen.com/careers/working-at-energen-518.html       valid
Crawling page: http://www.energen.com/about-energen/company-overview-385.html       valid
Crawling page: http://magnoliasolar.com/about/quest.html       valid
Crawling page: http://magnoliasolar.com/about/index.html       valid
Crawling page: https://www.iinano.org/sitemap       valid
Crawling page: http://magnoliasolar.com/about/innovation.html       valid
Crawling page: https://www.iinano.org/contact-us       valid
Crawling page: http://magnoliasolar.com/about/approach.html       valid
Crawling page: http://magnoliasolar.com/about/vision.html       valid
Crawling page: https://www.iinano.org/privacy-policy       valid
Crawling page: https://www.iinano.org/nanotechnology-town-hall-meeting       valid
Crawling page: https://www.iinano.org/nano-boot-camp-clinicians       valid
Crawling page: https://www.iinano.org/pre-18th-century       valid
Crawling page: https://www.iinano.org/david-kabiller-northwestern/bin/sh: 1: kill: Illegal number: 
2018-11-11 04:38:45 [scrapy.extensions.logstats] INFO: Crawled 436 pages (at 19 pages/min), scraped 407 items (at 16 items/min)
2018-11-11 04:38:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://magnoliasolar.com/function.session-start>: HTTP status code is not handled or not allowed
2018-11-11 04:39:50 [scrapy.extensions.logstats] INFO: Crawled 451 pages (at 15 pages/min), scraped 424 items (at 17 items/min)
2018-11-11 04:40:45 [scrapy.extensions.logstats] INFO: Crawled 465 pages (at 14 pages/min), scraped 438 items (at 14 items/min)
2018-11-11 04:41:42 [scrapy.extensions.logstats] INFO: Crawled 479 pages (at 14 pages/min), scraped 452 items (at 14 items/min)
2018-11-11 04:41:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://microcoolingconcepts.com/RandD.html>: HTTP status code is not handled or not allowed
2018-11-11 04:42:55 [scrapy.extensions.logstats] INFO: Crawled 501 pages (at 22 pages/min), scraped 469 items (at 17 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 04:43:52 [scrapy.extensions.logstats] INFO: Crawled 517 pages (at 16 pages/min), scraped 478 items (at 9 items/min)
2018-11-11 04:44:54 [scrapy.extensions.logstats] INFO: Crawled 525 pages (at 8 pages/min), scraped 493 items (at 15 items/min)
2018-11-11 04:45:42 [scrapy.extensions.logstats] INFO: Crawled 535 pages (at 10 pages/min), scraped 503 items (at 10 items/min)
       valid
Crawling page: https://www.iinano.org/warren-chan-kabiller-prize       valid
Crawling page: https://www.iinano.org/power-hour-with-dr.-nancy-gray       valid
Crawling page: https://www.iinano.org/2017-liangfang-zhang-1       valid
Crawling page: https://www.iinano.org/joseph-desimone-kabiller-prize       valid
Crawling page: https://www.iinano.org/2018-iin-frontiers-in-nanotechnology-seminar-series       valid
Crawling page: https://www.iinano.org/kabiller-young-investigator-award-winners       valid
Crawling page: https://www.iinano.org/ryan-fellows       valid
Crawling page: https://www.iinano.org/robert-langer-kabiller-prize       valid
Crawling page: https://www.iinano.org/education-outreach       valid
Crawling page: https://www.iinano.org/giving       valid
Crawling page: http://magnoliasolar.com/       valid
Crawling page: https://www.iinano.org/small-business-partnership       valid
Crawling page: http://magnoliasolar.com/in_the_news/foxnews.html       valid
Crawling page: https://www.iinano.org/kabiller-prize-winners       valid
Crawling page: https://www.iinano.org/professional-development       valid
Crawling page: http://magnoliasolar.com/in_the_news/channel_10.html       valid
Crawling page: http://magnoliasolar.com/in_the_news/video_intro.html       valid
Crawling page: http://magnoliasolar.com/in_the_news/video_investor_1.html       valid
Crawling page: http://magnoliasolar.com/in_the_news/video_company.html       valid
Crawling page: https://www.iinano.org/nanotechnology-town-hall       valid
Crawling page: http://magnoliasolar.com/in_the_news/video_rodman.html       valid
Crawling page: https://www.iinano.org/nano-boot-camp-for-clinicians       valid
Crawling page: https://www.iinano.org/all-scout-nano-day       valid
Crawling page: https://www.iinano.org/nanotechnology-corporate-partners-program       valid
Crawling page: https://www.iinano.org/industry       valid
Crawling page: https://www.iinano.org/ryan-graduate-fellowships       valid
Crawling page: https://www.iinano.org/IIN-postdoctoral-fellowship       valid
Crawling page: https://www.iinano.org/education-opportunities       valid
Crawling page: https://www.iinano.org/food-water       valid
Crawling page: https://www.iinano.org/security-defense       valid
Crawling page: https://www.iinano.org/frontiers-in-nanotechnology       valid
Crawling page: https://www.iinano.org/northwestern-university-nanotechnology-reu       valid
Crawling page: https://www.iinano.org/molecular-electronics       valid
Crawling page: https://www.iinano.org/environmental-nanotechnology       valid
Crawling page: https://www.iinano.org/medicine       valid
Crawling page: https://www.iinano.org/nanoenergy       valid
Crawling page: https://www.iinano.org/administration       valid
Crawling page: https://www.iinano.org/nanooncology       valid
Crawling page: https://www.iinano.org/research       valid
Crawling page: https://www.iinano.org/weinberg       valid
Crawling page: https://www.iinano.org/feinberg       valid
Crawling page: https://www.iinano.org/steering-committee       valid
Crawling page: https://www.iinano.org/executive-council       valid
Crawling page: https://www.iinano.org/people       valid
Crawling page: https://www.iinano.org/mccormick       valid
Crawling page: https://www.iinano.org/kellogg       valid
Crawling page: https://www.iinano.org/thrust-3-advanced-biosensing       valid
Crawling page: https://www.iinano.org/nanomedicine-institute-executive-committee       valid
Crawling page: https://www.iinano.org/thrust-2-functional-substrates       valid
Crawling page: https://www.iinano.org/thrust-1-materials-methods-development       valid
Crawling page: https://www.iinano.org/nu-ccne-synthesis-constructs-core       valid
Crawling page: https://www.iinano.org/nanomedicine       valid
Crawling page: https://www.iinano.org/center-of-excellence-for-advanced-bioprogrammable-nanomaterials       valid
Crawling page: https://www.iinano.org/nuccne-project-1       valid
Crawling page: https://www.iinano.org/northwestern-university-center-for-cancer-nanotechnology-excellence       valid
Crawling page: https://www.iinano.org/nuccne-project-3       valid
Crawling page: https://www.iinano.org/nuccne-project-2       valid
Crawling page: https://www.iinano.org/facilities       valid
Crawling page: https://www.iinano.org/industrial       valid
Crawling page: https://www.iinano.org/academic       valid
Crawling page: https://www.iinano.org/laboratories       valid
Crawling page: http://microcoolingconcepts.com/FuelAirHX.html       valid
Crawling page: http://microcoolingconcepts.com/EmergingCooling.html       valid
Crawling page: http://microcoolingconcepts.com/TwoPhase.html       valid
Crawling page: https://www.iinano.org/research-initiatives       valid
Crawling page: https://www.iinano.org/centers-institutes       valid
Crawling page: https://www.iinano.org/government-agencies       valid
Crawling page: https://www.iinano.org/message-from-the-director       valid
Crawling page: http://microcoolingconcepts.com/CustomCoolers.html       valid
Crawling page: http://microcoolingconcepts.com/StackableCoolers.html       valid
Crawling page: http://microcoolingconcepts.com/ArrayCoolers.html       valid
Crawling page: http://microcoolingconcepts.com/contact_us.html       valid
Crawling page: https://www.iinano.org/about       valid
Crawling page: http://microcoolingconcepts.com/about_us.html       valid
Crawling page: http://microcoolingconcepts.com/gallery.html       valid
Crawling page: http://microcoolingconcepts.com/coolers.html       valid
Crawling page: http://microcoolingconcepts.com/index.html       valid
Crawling page: http://gileadcs.org/contact-us/       valid
Crawling page: http://gileadcs.org/contact-us/directions/       valid
Crawling page: http://www.microcoolingconcepts.com/       valid
Crawling page: http://gileadcs.org/careers/employees/       valid
Crawling page: http://microcoolingconcepts.com/       valid
Crawling page: http://gileadcs.org/news-events/compassion-counts/       valid
Crawling page: http://gileadcs.org/careers/to-apply/       valid
Crawling page: http://gileadcs.org/news-events/quizine-for-a-cause/       valid
Crawling page: http://gileadcs.org/careers/       valid
Crawling page: http://gileadcs.org/news-events/community-conversations/       valid
Crawling page: http://gileadcs.org/news-events/road-race/       valid
Crawling page: http://gileadcs.org/news-events/50th-anniversary/       valid
Crawling page: http://gileadcs.org/news-events/publications/       valid
Crawling page: https://www.iinano.org/events       valid
Crawling page: https://www.iinano.org/kabiller-prize-nanomedicine       valid
Crawling page: https://www.iinano.org/ryan-fellowship       valid
Crawling page: http://gileadcs.org/news-events/media-kit/       valid
Crawling page: http://gileadcs.org/news-events/       valid
Crawling page: http://gileadcs.org/advocacy-center/       valid
Crawling page: http://gileadcs.org/get-involved/partner/       valid
Crawling page: http://gileadcs.org/get-involved/sponsor/       valid
Crawling page: http://gileadcs.org/get-involved/volunteer/       valid
Crawling page: http://gileadcs.org/get-involved/       valid
Crawling page: http://gileadcs.org/ways-to-give/leave-a-legacy/       valid
Crawling page: http://gileadcs.org/ways-to-give/wish-list/       valid
Crawling page: http://gileadcs.org/ways-to-give/endowment-funds/       valid
Crawling page: http://gileadcs.org/ways-to-give/inkind-donations/       valid
Crawling page: http://gileadcs.org/ways-to-give/giving/       valid
Crawling page: http://gileadcs.org/ways-to-give/1-in-5-club/       valid
Crawling page: https://www.iinano.org/       valid
Crawling page: http://gileadcs.org/ways-to-give/       valid
Crawling page: http://gileadcs.org/ways-to-give/why-give-to-gilead/       valid
Crawling page: http://gileadcs.org/donate/       valid
Crawling page: https://www.iinano.org/blog/       valid
Crawling page: http://gileadcs.org/community-impact/testimonials/       valid
Crawling page: http://gileadcs.org/community-impact/results/       valid
Crawling page: http://gileadcs.org/programs-services/mental-health-first-aid/2018-11-11 04:46:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://kinetechpower.com/tel:8111838487>: HTTP status code is not handled or not allowed
2018-11-11 04:46:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://kinetechpower.com/tel:2108031769>: HTTP status code is not handled or not allowed
2018-11-11 04:46:53 [scrapy.extensions.logstats] INFO: Crawled 551 pages (at 16 pages/min), scraped 519 items (at 16 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 04:47:49 [scrapy.extensions.logstats] INFO: Crawled 567 pages (at 16 pages/min), scraped 531 items (at 12 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 04:49:10 [scrapy.extensions.logstats] INFO: Crawled 591 pages (at 24 pages/min), scraped 549 items (at 18 items/min)
2018-11-11 04:49:44 [scrapy.extensions.logstats] INFO: Crawled 595 pages (at 4 pages/min), scraped 557 items (at 8 items/min)
2018-11-11 04:50:57 [scrapy.extensions.logstats] INFO: Crawled 609 pages (at 14 pages/min), scraped 574 items (at 17 items/min)
2018-11-11 04:51:50 [scrapy.extensions.logstats] INFO: Crawled 623 pages (at 14 pages/min), scraped 589 items (at 15 items/min)
2018-11-11 04:52:48 [scrapy.extensions.logstats] INFO: Crawled 642 pages (at 19 pages/min), scraped 603 items (at 14 items/min)
       valid
Crawling page: http://gileadcs.org/community-impact/our-stories/       valid
Crawling page: http://gileadcs.org/programs-services/family-resources/       valid
Crawling page: http://gileadcs.org/programs-services/apartment-services/       valid
Crawling page: http://gileadcs.org/programs-services/community-services/       valid
Crawling page: http://gileadcs.org/programs-services/residential-services/       valid
Crawling page: http://gileadcs.org/programs-services/social-rehab-centers/       valid
Crawling page: http://gileadcs.org/programs-services/       valid
Crawling page: http://gileadcs.org/programs-services/outpatient-clinics/       valid
Crawling page: http://gileadcs.org/who-we-are/carf-accreditation/       valid
Crawling page: http://gileadcs.org/community-impact/       valid
Crawling page: http://gileadcs.org/who-we-are/gilead-today/       valid
Crawling page: http://gileadcs.org/who-we-are/board-of-directors/       valid
Crawling page: http://gileadcs.org/who-we-are/administration/       valid
Crawling page: http://gileadcs.org/who-we-are/       valid
Crawling page: http://gileadcs.org/who-we-are/mission-vision-values/       valid
Crawling page: https://www.ferro.com/%5C       valid
Crawling page: https://www.ferro.com/legal-notices       valid
Crawling page: https://www.ferro.com/sitemap       valid
Crawling page: https://www.ferro.com/news-and-events/press-releases/ferro-reports-third-quarter-2018-results       valid
Crawling page: https://www.ferro.com/news-and-events/press-releases/ferro-adding-manufacturing-capacity-for-ultramarine-blue--and-micronized-iron-oxide-pigments       valid
Crawling page: https://kinetechpower.com/       valid
Crawling page: https://www.ferro.com/privacy-policy       valid
Crawling page: https://www.ferro.com/terms-of-use       valid
Crawling page: https://www.ferro.com/resource-center/literature       valid
Crawling page: https://www.ferro.com/innovation       valid
Crawling page: https://www.ferro.com/careers       valid
Crawling page: https://www.ferro.com/news-and-events       valid
Crawling page: https://www.ferro.com/about/vision-values-and-mission       valid
Crawling page: http://www.immunolight.com/terms-of-use/       valid
Crawling page: https://www.ferro.com/products       valid
Crawling page: https://www.ferro.com/       valid
Crawling page: https://www.ferro.com/contact       valid
Crawling page: http://www.immunolight.com/contact/       valid
Crawling page: http://www.immunolight.com/company/blog/       valid
Crawling page: http://iogen.ca/media-resources/24_7_2015_iogen_raizen.html       valid
Crawling page: http://iogen.ca/media-resources/iogen-press-releases.html       valid
Crawling page: http://iogen.ca/biogas/index.html       valid
Crawling page: http://iogen.ca/raizen-project/index.html       valid
Crawling page: http://iogen.ca/cellulosic_ethanol/index.html       valid
Crawling page: http://www.immunolight.com/company/       valid
Crawling page: http://www.immunolight.com/company/partners/       valid
Crawling page: http://www.immunolight.com/company/team/       valid
Crawling page: http://www.immunolight.com/company/press/       valid
Crawling page: http://iogen.ca/markets/index.html       valid
Crawling page: http://iogen.ca/about-iogen/index.html       valid
Crawling page: http://iogen.ca/common/sitemap.html       valid
Crawling page: http://www.immunolight.com/applications/color/       valid
Crawling page: http://www.immunolight.com/applications/electronics/       valid
Crawling page: http://www.immunolight.com/applications/solar/       valid
Crawling page: http://www.immunolight.com/applications/adhesives/       valid
Crawling page: http://iogen.ca/about-iogen/contact-us.html       valid
Crawling page: http://www.immunolight.com/applications/disease-disorders/       valid
Crawling page: http://www.immunolight.com/applications/cancer/animal-data/       valid
Crawling page: http://www.immunolight.com/applications/cancer/cell-studies/       valid
Crawling page: http://www.immunolight.com/applications/cancer/       valid
Crawling page: http://www.immunolight.com/applications/       valid
Crawling page: http://www.immunolight.com/technology/patents/       valid
Crawling page: http://www.immunolight.com/technology/energy-converters/       valid
Crawling page: http://www.immunolight.com/technology/       valid
Crawling page: http://cyboenergy.com/whatsnew/CyboEnergy-Releases-the-Worlds-First-Batteryless-Off-Grid-Solar-Inverter-for-Air-Conditioners.html       valid
Crawling page: http://cyboenergy.com/technologies/designguidedownload.html       valid
Crawling page: http://iogen.ca/about-iogen/careers.html       valid
Crawling page: http://iogen.ca/index.html       valid
Crawling page: http://www.immunolight.com       valid
Crawling page: http://cyboenergy.com/technologies/onoffgriddesignguidedownload.html       valid
Crawling page: http://cyboenergy.com/whatsnew/CyboEnergy-Offers-OnGrid-OffGrid-and-OnOffGrid-CyboInverters-with-Unique-Features-and-Benefits-for-Special-Solar-Applications.html       valid
Crawling page: http://cyboenergy.com/whatsnew/CyboEnergy-Wins-Solar-Inverter-Innovation-Award-from-Frost-and-Sullivan.html       valid
Crawling page: http://cyboenergy.com/whatsnew/CyboEnergy-Awarded-Four-U.S.-Patents-for-Solar-Inverter-Technologies.html       valid
Crawling page: http://cyboenergy.com/whatsnew/CyboEnergy-Introduces-AC-Assisted-Off-Grid-CyboInverters.html       valid
Crawling page: http://cyboenergy.com/newsandevents/tradeshows.html       valid
Crawling page: http://cyboenergy.com/newsandevents/cyboenergyinthenews.html       valid
Crawling page: http://cyboenergy.com/company/form.html       valid
Crawling page: http://cyboenergy.com/newsandevents/announcements.html       valid
Crawling page: http://cyboenergy.com/company/contactus.html       valid
Crawling page: http://cyboenergy.com/company/awards.html       valid
Crawling page: http://cyboenergy.com/company/about_cyboenergy.html       valid
Crawling page: http://cyboenergy.com/technologies/nationalelectricalcode.html       valid
Crawling page: http://cyboenergy.com/technologies/mfacontrol.html       valid
Crawling page: http://cyboenergy.com/technologies/invertertechnology.html       valid
Crawling page: http://cyboenergy.com/business/resourcecenter.html       valid
Crawling page: http://cyboenergy.com/business/partnership.html       valid
Crawling page: http://cyboenergy.com/business/howtobuy.html       valid
Crawling page: http://cyboenergy.com/solutions/pvsolarcooking.html       valid
Crawling page: http://cyboenergy.com/cybopower/index.php/site/login       valid
Crawling page: http://cyboenergy.com/solutions/pvsolarheating.html       valid
Crawling page: http://cyboenergy.com/solutions/onoffqanda.html       valid
Crawling page: http://cyboenergy.com/solutions/qanda.html       valid
Crawling page: http://cyboenergy.com/solutions/offgridkeypoints.html       valid
Crawling page: http://cyboenergy.com/solutions/overview.html       valid
Crawling page: http://cyboenergy.com/products/microgridaccessoryparts.html       valid
Crawling page: http://cyboenergy.com/products/cybobridge_spec.html       valid
Crawling page: http://cyboenergy.com/products/dualoutputoffgridoverview.html       valid
Crawling page: http://cyboenergy.com/products/onoffgridoverview.html       valid
Crawling page: http://cyboenergy.com/products/offgridoverview.html       valid
Crawling page: http://cyboenergy.com/products/offgridHmodeloverview.html       valid
Crawling page: http://acaciaresearch.com/contact-us/       valid
Crawling page: http://acaciaresearch.com/event_cat/events/       valid
Crawling page: http://acaciaresearch.com/events/       valid
Crawling page: http://cyboenergy.com/products/ongridoverview.html       valid
Crawling page: http://cyboenergy.com/products/cyboinverterproductfamily.html       valid
Crawling page: http://acaciaresearch.com/in-the-news/       valid
Crawling page: http://cyboenergy.com/products/productsoverview.html       valid
Crawling page: http://acaciaresearch.com/announcement/       valid
Crawling page: http://acaciaresearch.com/corporate-governance/       valid
Crawling page: http://acaciaresearch.com/investor-relations/2018-11-11 04:53:43 [scrapy.extensions.logstats] INFO: Crawled 646 pages (at 4 pages/min), scraped 614 items (at 11 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 04:54:56 [scrapy.extensions.logstats] INFO: Crawled 668 pages (at 22 pages/min), scraped 628 items (at 14 items/min)
2018-11-11 04:56:22 [scrapy.extensions.logstats] INFO: Crawled 668 pages (at 0 pages/min), scraped 638 items (at 10 items/min)
2018-11-11 04:56:41 [scrapy.extensions.logstats] INFO: Crawled 678 pages (at 10 pages/min), scraped 640 items (at 2 items/min)
2018-11-11 04:58:13 [scrapy.extensions.logstats] INFO: Crawled 682 pages (at 4 pages/min), scraped 649 items (at 9 items/min)
2018-11-11 04:58:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://glucanbio.com/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 04:58:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://glucanbio.com/gallery/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 04:58:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://client.gileadcs.org:8443/portal/login.aspx>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 111: Connection refused.
2018-11-11 04:58:48 [scrapy.extensions.logstats] INFO: Crawled 684 pages (at 2 pages/min), scraped 654 items (at 5 items/min)
2018-11-11 04:58:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.goalzero.com/shop/sherpa-power-banks-and-accessories/sherpa-40-power-bank/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 04:58:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.goalzero.com/shop/semi-portable-solar-panels/boulder-100-solar-panel/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 04:58:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.goalzero.com/shop/portable-power/goal-zero-yeti-1400-lithium-power-station-app/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
/bin/sh: 1: kill: Illegal number: 
/bin/sh: 1: kill: Illegal number: 
/bin/sh: 1: kill: Illegal number: 
2018-11-11 05:00:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.goalzero.com/tel%3A18887946250/>: HTTP status code is not handled or not allowed
2018-11-11 05:00:15 [scrapy.extensions.logstats] INFO: Crawled 707 pages (at 23 pages/min), scraped 664 items (at 10 items/min)
2018-11-11 05:00:51 [scrapy.extensions.logstats] INFO: Crawled 714 pages (at 7 pages/min), scraped 670 items (at 6 items/min)
2018-11-11 05:02:16 [scrapy.extensions.logstats] INFO: Crawled 721 pages (at 7 pages/min), scraped 682 items (at 12 items/min)
2018-11-11 05:02:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/world-berries/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:02:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/the-real-food-trading-company/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:02:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/december-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:02:56 [scrapy.extensions.logstats] INFO: Crawled 732 pages (at 11 pages/min), scraped 686 items (at 4 items/min)
2018-11-11 05:03:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/november-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:03:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/february-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:03:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/january-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:03:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.nutraceutical.com/catalog/supplement-aisle/>: HTTP status code is not handled or not allowed
2018-11-11 05:03:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/march-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:03:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-april-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:03:49 [scrapy.extensions.logstats] INFO: Crawled 737 pages (at 5 pages/min), scraped 689 items (at 3 items/min)
2018-11-11 05:04:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-may-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:04:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.nutraceutical.com/catalog/grocery-aisle/>: HTTP status code is not handled or not allowed
2018-11-11 05:04:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-august-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:04:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-june-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:04:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-october-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:04:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-september-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:04:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-july-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:04:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-december-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-november-3013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:04:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-january-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:04:52 [scrapy.extensions.logstats] INFO: Crawled 752 pages (at 15 pages/min), scraped 690 items (at 1 items/min)
2018-11-11 05:04:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-april-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:05:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-march-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:05:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-february-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:05:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/june-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:05:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/july-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:05:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/august-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/september-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:05:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/october-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:05:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/march-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:05:49 [scrapy.extensions.logstats] INFO: Crawled 763 pages (at 11 pages/min), scraped 690 items (at 0 items/min)
       valid
Crawling page: http://acaciaresearch.com/corporate-profile/       valid
Crawling page: http://acaciaresearch.com/how-we-work/       valid
Crawling page: http://acaciaresearch.com/history/       valid
Crawling page: http://acaciaresearch.com/overview/       valid
Crawling page: http://acaciaresearch.com/       valid
Crawling page: http://glucanbio.com/about/       valid
Crawling page: https://www.goalzero.com/store-finder/stores/       valid
Crawling page: https://www.goalzero.com/warranty/       valid
Crawling page: http://glucanbio.com/strategic-partners/       valid
Crawling page: https://www.goalzero.com/faq/       valid
Crawling page: http://glucanbio.com/features/       valid
Crawling page: http://glucanbio.com/contact/       valid
Crawling page: http://glucanbio.com/why-glucanbio/       valid
Crawling page: http://glucanbio.com/why-glucanbio/derisking-scaleup/       valid
Crawling page: https://www.goalzero.com/blog/page/events/       valid
Crawling page: https://www.goalzero.com/product-landing/       valid
Crawling page: https://www.goalzero.com/shop/portable-power/       valid
Crawling page: https://www.goalzero.com/story/       valid
Crawling page: http://glucanbio.com/why-glucanbio/news-publications/       valid
Crawling page: http://glucanbio.com/about/team/       valid
Crawling page: https://www.goalzero.com/account/login/?next=/account/       valid
Crawling page: https://www.goalzero.com/ambassadors/       valid
Crawling page: https://www.goalzero.com/cart/       valid
Crawling page: https://www.goalzero.com/shop/sherpa-power-banks-and-accessories/sherpa-100ac-power-bank/       valid
Crawling page: https://www.goalzero.com/shop/lights/crush-light-chroma/       valid
Crawling page: https://www.goalzero.com/blog/this-is-goal-zero/       valid
Crawling page: https://www.goalzero.com/shop/       valid
Crawling page: https://www.goalzero.com/blog/home-integration-kit-home-back-up/       valid
Crawling page: https://www.goalzero.com/shop/sherpa-power-banks-and-accessories/sherpa-40-power-bank/silver/       valid
Crawling page: https://www.goalzero.com/shop/sherpa-power-banks-and-accessories/sherpa-40-power-bank/copper/       valid
Crawling page: https://www.goalzero.com/shop/sherpa-power-banks-and-accessories/sherpa-40-power-bank/black/       valid
Crawling page: https://www.goalzero.com/blog/ruby-and-revolver/       valid
Crawling page: https://emd-technologies.com/products/computed-tomography/       valid
Crawling page: https://www.goalzero.com/blog/puerto-rico/       valid
Crawling page: https://www.goalzero.com/product-registration/       valid
Crawling page: https://www.goalzero.com/user-guides/       valid
Crawling page: https://www.goalzero.com/how-it-works/       valid
Crawling page: https://emd-technologies.com/heico-aerospace-privacy-and-cookie-statement/       valid
Crawling page: https://www.goalzero.com/product-care/       valid
Crawling page: https://www.goalzero.com/contact/       valid
Crawling page: https://www.goalzero.com/privacy/       valid
Crawling page: https://emd-technologies.com/author/webadm/       valid
Crawling page: https://emd-technologies.com/about-emd/       valid
Crawling page: https://www.goalzero.com/       valid
Crawling page: https://emd-technologies.com/customer-support/       valid
Crawling page: https://paymaster.com/       valid
Crawling page: https://paymaster.com/p/sitemap/       valid
Crawling page: https://www.goalzero.com/blog/education-technology/       valid
Crawling page: https://www.goalzero.com/shop/lanterns/lighthouse-core-lantern-usb-power-hub/       valid
Crawling page: http://www.immunolight.com/now-recruiting-phase-ii-studies/       valid
Crawling page: https://www.goalzero.com/shop/open-box-product/       valid
Crawling page: https://www.goalzero.com/how-it-works/       valid
Crawling page: https://emd-technologies.com/       valid
Crawling page: http://www.immunolight.com/applications/solar/       valid
Crawling page: http://www.immunolight.com/privacy-policy/       valid
Crawling page: https://www.goalzero.com/terms/       valid
Crawling page: https://paymaster.com/login/       valid
Crawling page: https://paymaster.com/p/privacy-policy/       valid
Crawling page: https://paymaster.com/p/resources/       valid
Crawling page: http://port-a-fire.ca/contact.htm       valid
Crawling page: http://port-a-fire.ca/links.htm       valid
Crawling page: http://port-a-fire.ca/features.htm       valid
Crawling page: http://port-a-fire.ca/faq.htm       valid
Crawling page: https://paymaster.com/p/terms-of-service/       valid
Crawling page: https://paymaster.com/p/services/       valid
Crawling page: https://paymaster.com/p/products/       valid
Crawling page: https://paymaster.com/p/quick-links/       valid
Crawling page: http://newholdllc.com/author/newhold/       valid
Crawling page: https://paymaster.com/p/company/       valid
Crawling page: https://paymaster.com/p/quick-links/help/       valid
Crawling page: https://paymaster.com/p/resources/state/       valid
Crawling page: http://port-a-fire.ca/index.htm       valid
Crawling page: http://port-a-fire.ca/description.htm       valid
Crawling page: https://www.nutraceutical.com/?s       valid
Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/world-berries/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/the-real-food-trading-company/       Crawling page: https://www.nutraceutical.com/products/sustainable-labs/       valid
Crawling page: https://www.nutraceutical.com/products/whats-new/december-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/november-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/february-2015/       Crawling page: https://www.nutraceutical.com/caring-and-sharing/       valid
Crawling page: https://www.nutraceutical.com/products/       valid
Crawling page: https://www.nutraceutical.com/products/whats-new/january-2015/       Crawling page: https://www.nutraceutical.com/catalog/       valid
Crawling page: https://www.nutraceutical.com/products/whats-new/march-2015/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-april-2013/       Crawling page: https://www.nutraceutical.com/company/       valid
Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-may-2013/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-august-2013/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-june-2013/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-october-2013/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-september-2013/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-july-2013/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-december-2013/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-november-3013/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-january-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-april-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-march-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/new-beautiful-february-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/june-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/july-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/august-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/september-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/october-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/march-2015/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/february-2015/2018-11-11 05:05:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/february-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/november-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/december-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/august-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/july-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/may-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/april-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/september-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/november-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/january-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/february-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:06:55 [scrapy.extensions.logstats] INFO: Crawled 768 pages (at 5 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:07:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/march-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:07:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/december-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:07:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/june-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:07:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/august-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:07:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/may-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:07:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/september-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:07:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/november-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:07:43 [scrapy.extensions.logstats] INFO: Crawled 779 pages (at 11 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:07:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/marchapril-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:08:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/february-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:08:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/july-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:08:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/january-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:08:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/december-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:08:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/mayjune-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:08:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/novemberdecember-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:08:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/sitemap/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:08:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/septemberoctober-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:09:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/new-and-beautiful/julyaugust-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:09:01 [scrapy.extensions.logstats] INFO: Crawled 784 pages (at 5 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:09:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/copyright-disclaimer/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:09:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/new-search/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:09:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/find-a-retailer/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:09:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/contact-us/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:09:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/retailers/natures-cures-application/practitioner-supplemental-terms-and-conditions-of-sale/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:09:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/retailers/chain-update-form/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:09:46 [scrapy.extensions.logstats] INFO: Crawled 789 pages (at 5 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:09:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/retailers/new-account-application/terms-and-conditions-of-purchase/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/retailers/natures-cures-application/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/retailers/new-account-application/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/retailers/new-account-application/terms-and-conditions/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/investors/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/retailers/retailer-login/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/retailers/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/retailers/minimum_advertised_price_policy/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/science-and-innovation/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/responsible-sourcing/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/product-formulation/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:10:56 [scrapy.extensions.logstats] INFO: Crawled 804 pages (at 15 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-april-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:11:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-may-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:11:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-june-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:11:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-july-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:11:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-october-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:11:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-november-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:11:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-august-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:11:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-september-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-march-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-february-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:04 [scrapy.extensions.logstats] INFO: Crawled 816 pages (at 12 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:12:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-january-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-december-2013/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/august-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/whats-new-april-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/september-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/july-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:43 [scrapy.extensions.logstats] INFO: Crawled 820 pages (at 4 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:12:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/june-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:12:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/october-2014/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/april-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:13:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/may-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:13:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/june-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:13:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/july-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:13:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/december-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:13:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/august-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:13:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/september-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:13:46 [scrapy.extensions.logstats] INFO: Crawled 832 pages (at 12 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:13:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/january-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:13:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/november-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/october-2015/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/april/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/march-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/february-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/may-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/june-2016/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/january-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:41 [scrapy.extensions.logstats] INFO: Crawled 836 pages (at 4 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:14:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/february-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/march-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:14:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/mayjune-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:15:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/julyaugust/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:15:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/septemberoctober-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:15:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/novemberdecember-2017/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:15:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:15:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/caring-and-sharing/caring-sharing-beta/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:15:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/januaryfebruary-2018/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:15:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/products/whats-new/marchapril-2018-2/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:15:42 [scrapy.extensions.logstats] INFO: Crawled 847 pages (at 11 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:15:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/books/woodland-publishing/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:15:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/books/woodland-publishing/my-home-pharmacy/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:16:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/pets/actipet/the-pet-crystal/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:16:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/pets/actipet/brand-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:16:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/books/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/november-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/december-2014/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/august-2015/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/july-2015/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/may-2015/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/april-2015/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/september-2015/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/november-2015/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/january-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/february-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/march-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/december-2015/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/june-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/august-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/may-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/september-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/november-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/marchapril-2017/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/february-2017/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/july-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/january-2017/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/december-2016/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/mayjune-2017/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/novemberdecember-2017/       Crawling page: https://www.nutraceutical.com/sitemap/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/septemberoctober-2017/       Crawling page: https://www.nutraceutical.com/products/new-and-beautiful/julyaugust-2017/       Crawling page: https://www.nutraceutical.com/copyright-disclaimer/       Crawling page: https://www.nutraceutical.com/new-search/       Crawling page: https://www.nutraceutical.com/find-a-retailer/       Crawling page: https://www.nutraceutical.com/contact-us/       Crawling page: https://www.nutraceutical.com/retailers/natures-cures-application/practitioner-supplemental-terms-and-conditions-of-sale/       Crawling page: https://www.nutraceutical.com/retailers/chain-update-form/       Crawling page: https://www.nutraceutical.com/retailers/new-account-application/terms-and-conditions-of-purchase/       Crawling page: https://www.nutraceutical.com/retailers/natures-cures-application/       Crawling page: https://www.nutraceutical.com/retailers/new-account-application/       Crawling page: https://www.nutraceutical.com/retailers/new-account-application/terms-and-conditions/       Crawling page: https://www.nutraceutical.com/investors/       Crawling page: https://www.nutraceutical.com/retailers/retailer-login/       Crawling page: https://www.nutraceutical.com/retailers/       Crawling page: https://www.nutraceutical.com/retailers/minimum_advertised_price_policy/       Crawling page: https://www.nutraceutical.com/products/science-and-innovation/       Crawling page: https://www.nutraceutical.com/products/responsible-sourcing/       Crawling page: https://www.nutraceutical.com/products/product-formulation/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-april-2013/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-may-2013/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-june-2013/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-july-2013/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-october-2013/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-november-2013/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-august-2013/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-september-2013/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-march-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-february-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-january-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-december-2013/       Crawling page: https://www.nutraceutical.com/products/whats-new/august-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/whats-new-april-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/september-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/july-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/june-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/october-2014/       Crawling page: https://www.nutraceutical.com/products/whats-new/april-2015/       Crawling page: https://www.nutraceutical.com/products/whats-new/may-2015/       Crawling page: https://www.nutraceutical.com/products/whats-new/june-2015/       Crawling page: https://www.nutraceutical.com/products/whats-new/july-2015/       Crawling page: https://www.nutraceutical.com/products/whats-new/december-2015/       Crawling page: https://www.nutraceutical.com/products/whats-new/august-2015/       Crawling page: https://www.nutraceutical.com/products/whats-new/september-2015/       Crawling page: https://www.nutraceutical.com/products/whats-new/january-2016/       Crawling page: https://www.nutraceutical.com/products/whats-new/november-2015/       Crawling page: https://www.nutraceutical.com/products/whats-new/october-2015/       Crawling page: https://www.nutraceutical.com/products/whats-new/april/       Crawling page: https://www.nutraceutical.com/products/whats-new/march-2016/       Crawling page: https://www.nutraceutical.com/products/whats-new/february-2016/       Crawling page: https://www.nutraceutical.com/products/whats-new/may-2016/       Crawling page: https://www.nutraceutical.com/products/whats-new/june-2016/       Crawling page: https://www.nutraceutical.com/products/whats-new/january-2017/       Crawling page: https://www.nutraceutical.com/products/whats-new/february-2017/       Crawling page: https://www.nutraceutical.com/products/whats-new/march-2017/       Crawling page: https://www.nutraceutical.com/products/whats-new/mayjune-2017/       Crawling page: https://www.nutraceutical.com/products/whats-new/julyaugust/       Crawling page: https://www.nutraceutical.com/products/whats-new/septemberoctober-2017/       Crawling page: https://www.nutraceutical.com/products/whats-new/novemberdecember-2017/       Crawling page: https://www.nutraceutical.com/products/whats-new/       Crawling page: https://www.nutraceutical.com/caring-and-sharing/caring-sharing-beta/       Crawling page: https://www.nutraceutical.com/products/whats-new/januaryfebruary-2018/       Crawling page: https://www.nutraceutical.com/products/whats-new/marchapril-2018-2/       Crawling page: https://www.nutraceutical.com/collections/books/woodland-publishing/       Crawling page: https://www.nutraceutical.com/collections/books/woodland-publishing/my-home-pharmacy/       Crawling page: https://www.nutraceutical.com/collections/pets/actipet/the-pet-crystal/       Crawling page: https://www.nutraceutical.com/collections/pets/actipet/brand-brochure/       Crawling page: https://www.nutraceutical.com/collections/books/       Crawling page: https://www.nutraceutical.com/collections/pets/actipet/2018-11-11 05:16:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/pets/actipet/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:16:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beehive/premier-one/premier-one-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:16:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beehive/montana-big-sky/montana-big-sky-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:16:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/pets/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:16:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beehive/premier-one/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:16:45 [scrapy.extensions.logstats] INFO: Crawled 857 pages (at 10 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beehive/honey-gardens/honey-gardens-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:16:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beehive/montana-big-sky/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beehive/honey-gardens/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/spring-drops/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beehive/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/zylicious/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/sweet-moose/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/taste-waves/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/miztique/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/paleo-planettm/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/refrigerator-fresh/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:17:58 [scrapy.extensions.logstats] INFO: Crawled 869 pages (at 12 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:18:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/funfresh-foods-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/dowd/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:18:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/active/natural-sport/buckpower/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:18:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:18:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/active/natural-sport/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:18:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/active/natural-sport/ns-brand-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:18:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:18:44 [scrapy.extensions.logstats] INFO: Crawled 875 pages (at 6 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:18:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/active/natural-balance/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:18:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/zand/natures-herbs/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:19:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/active/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:19:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/zand/zand-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:19:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/zand/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:19:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/vaxa/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/vaxa/vaxa-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:19:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/pioneer/pioneer-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:19:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/oakmont-labs/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:19:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/pioneer/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:19:56 [scrapy.extensions.logstats] INFO: Crawled 887 pages (at 12 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:20:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/naturalcare/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:20:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/natrabio/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:20:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/nutra-biogenesis/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:20:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/herbs-for-kids/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:20:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/herbs-for-kids/homeopathy-for-kids/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:20:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/herbs-for-kids/herbs-kids-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:20:43 [scrapy.extensions.logstats] INFO: Crawled 891 pages (at 4 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:20:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/bioallers/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:20:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/complimed/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:21:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/allvia/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:21:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/natures-cures/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:21:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/vitalogic/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:21:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/natures-life/vida-natura/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:21:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/thompson/thompson-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:21:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/thompson/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:21:42 [scrapy.extensions.logstats] INFO: Crawled 901 pages (at 10 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:21:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/natures-life/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:21:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/health-from-the-sun/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:22:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/all-one/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:22:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/all-one/perfect-7/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:22:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/lifetime/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:22:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/dynamic-health/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:22:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/innovative/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:22:40 [scrapy.extensions.logstats] INFO: Crawled 905 pages (at 4 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:22:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/zola-naturals/moiststic/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:22:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/zola-naturals/naturally-fresh/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:23:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/zola-naturals/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:23:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/zola-naturals/geodeo/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:23:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/sun-feather/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:23:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/organix-south/xylivita/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:23:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/skin-by-ann-webb/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:23:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/organix-south/tea-tree-remedies/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:23:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/organix-south/naked-organix/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:23:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/organix-south/theraneem/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:23:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/living-flower-essences/simplers/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/organix-south/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:01 [scrapy.extensions.logstats] INFO: Crawled 919 pages (at 14 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:24:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/living-flower-essences/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/living-flower-essences/mia-rose/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/living-clay/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/life-flo/5k1n/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/life-flo/collective-wellbeing/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/life-flo/mababa/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/life-flo/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/larenim/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:45 [scrapy.extensions.logstats] INFO: Crawled 928 pages (at 9 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:24:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/heritage-store/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:24:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/heritage-store/emu-gold/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:25:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/heritage-store/your-crown-glory/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:25:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/aubrey/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:25:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/emerita/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:25:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/veglife/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:25:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/veglife/peaceful-planet/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:25:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/beautiful/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:25:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/solaray/food-source/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:25:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/sunny-green/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:25:54 [scrapy.extensions.logstats] INFO: Crawled 937 pages (at 9 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:26:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/solaray/natural-woman/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:26:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/sunny-green/brand-brochure/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:26:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/solaray/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:26:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/solaray/fermented-fungi/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:26:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/kal/kal-innovation/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
       Crawling page: https://www.nutraceutical.com/collections/beehive/premier-one/premier-one-brochure/       Crawling page: https://www.nutraceutical.com/collections/beehive/montana-big-sky/montana-big-sky-brochure/       Crawling page: https://www.nutraceutical.com/collections/pets/       Crawling page: https://www.nutraceutical.com/collections/beehive/premier-one/       Crawling page: https://www.nutraceutical.com/collections/beehive/honey-gardens/honey-gardens-brochure/       Crawling page: https://www.nutraceutical.com/collections/beehive/montana-big-sky/       Crawling page: https://www.nutraceutical.com/collections/beehive/honey-gardens/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/spring-drops/       Crawling page: https://www.nutraceutical.com/collections/beehive/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/zylicious/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/sweet-moose/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/taste-waves/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/miztique/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/paleo-planettm/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/refrigerator-fresh/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/funfresh-foods-brochure/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/dowd/       Crawling page: https://www.nutraceutical.com/collections/active/natural-sport/buckpower/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/       Crawling page: https://www.nutraceutical.com/collections/active/natural-sport/       Crawling page: https://www.nutraceutical.com/collections/active/natural-sport/ns-brand-brochure/       Crawling page: https://www.nutraceutical.com/collections/healthy-market/funfresh-foods/       Crawling page: https://www.nutraceutical.com/collections/active/natural-balance/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/zand/natures-herbs/       Crawling page: https://www.nutraceutical.com/collections/active/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/zand/zand-brochure/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/zand/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/vaxa/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/vaxa/vaxa-brochure/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/pioneer/pioneer-brochure/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/oakmont-labs/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/pioneer/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/naturalcare/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/natrabio/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/nutra-biogenesis/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/herbs-for-kids/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/herbs-for-kids/homeopathy-for-kids/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/herbs-for-kids/herbs-kids-brochure/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/bioallers/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/complimed/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/allvia/       Crawling page: https://www.nutraceutical.com/collections/natures-cures/       Crawling page: https://www.nutraceutical.com/collections/innovative/vitalogic/       Crawling page: https://www.nutraceutical.com/collections/innovative/natures-life/vida-natura/       Crawling page: https://www.nutraceutical.com/collections/innovative/thompson/thompson-brochure/       Crawling page: https://www.nutraceutical.com/collections/innovative/thompson/       Crawling page: https://www.nutraceutical.com/collections/innovative/natures-life/       Crawling page: https://www.nutraceutical.com/collections/innovative/health-from-the-sun/       Crawling page: https://www.nutraceutical.com/collections/innovative/all-one/       Crawling page: https://www.nutraceutical.com/collections/innovative/all-one/perfect-7/       Crawling page: https://www.nutraceutical.com/collections/innovative/lifetime/       Crawling page: https://www.nutraceutical.com/collections/innovative/dynamic-health/       Crawling page: https://www.nutraceutical.com/collections/innovative/       Crawling page: https://www.nutraceutical.com/collections/beautiful/zola-naturals/moiststic/       Crawling page: https://www.nutraceutical.com/collections/beautiful/zola-naturals/naturally-fresh/       Crawling page: https://www.nutraceutical.com/collections/beautiful/zola-naturals/       Crawling page: https://www.nutraceutical.com/collections/beautiful/zola-naturals/geodeo/       Crawling page: https://www.nutraceutical.com/collections/beautiful/sun-feather/       Crawling page: https://www.nutraceutical.com/collections/beautiful/organix-south/xylivita/       Crawling page: https://www.nutraceutical.com/collections/beautiful/skin-by-ann-webb/       Crawling page: https://www.nutraceutical.com/collections/beautiful/organix-south/tea-tree-remedies/       Crawling page: https://www.nutraceutical.com/collections/beautiful/organix-south/naked-organix/       Crawling page: https://www.nutraceutical.com/collections/beautiful/organix-south/theraneem/       Crawling page: https://www.nutraceutical.com/collections/beautiful/living-flower-essences/simplers/       Crawling page: https://www.nutraceutical.com/collections/beautiful/organix-south/       Crawling page: https://www.nutraceutical.com/collections/beautiful/living-flower-essences/       Crawling page: https://www.nutraceutical.com/collections/beautiful/living-flower-essences/mia-rose/       Crawling page: https://www.nutraceutical.com/collections/beautiful/living-clay/       Crawling page: https://www.nutraceutical.com/collections/beautiful/life-flo/5k1n/       Crawling page: https://www.nutraceutical.com/collections/beautiful/life-flo/collective-wellbeing/       Crawling page: https://www.nutraceutical.com/collections/beautiful/life-flo/mababa/       Crawling page: https://www.nutraceutical.com/collections/beautiful/life-flo/       Crawling page: https://www.nutraceutical.com/collections/beautiful/larenim/       Crawling page: https://www.nutraceutical.com/collections/beautiful/heritage-store/       Crawling page: https://www.nutraceutical.com/collections/beautiful/heritage-store/emu-gold/       Crawling page: https://www.nutraceutical.com/collections/beautiful/heritage-store/your-crown-glory/       Crawling page: https://www.nutraceutical.com/collections/beautiful/aubrey/       Crawling page: https://www.nutraceutical.com/collections/beautiful/emerita/       Crawling page: https://www.nutraceutical.com/collections/healthy/veglife/       Crawling page: https://www.nutraceutical.com/collections/healthy/veglife/peaceful-planet/       Crawling page: https://www.nutraceutical.com/collections/beautiful/       Crawling page: https://www.nutraceutical.com/collections/healthy/solaray/food-source/       Crawling page: https://www.nutraceutical.com/collections/healthy/sunny-green/       Crawling page: https://www.nutraceutical.com/collections/healthy/solaray/natural-woman/       Crawling page: https://www.nutraceutical.com/collections/healthy/sunny-green/brand-brochure/       Crawling page: https://www.nutraceutical.com/collections/healthy/solaray/       Crawling page: https://www.nutraceutical.com/collections/healthy/solaray/fermented-fungi/       Crawling page: https://www.nutraceutical.com/collections/healthy/kal/kal-innovation/       Crawling page:2018-11-11 05:26:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/kal/kal-clinical-lifestyle/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:26:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/kal/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:26:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/kal/kal-vitamin-c/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:26:49 [scrapy.extensions.logstats] INFO: Crawled 944 pages (at 7 pages/min), scraped 690 items (at 0 items/min)
2018-11-11 05:26:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/collections/healthy/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:27:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/company/employees/nutraceutical-benefits/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:27:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/catalog/brand-brochures/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:27:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/company/directors/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:27:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/company/employees/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:27:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/company/employees/current-open-positions/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:27:42 [scrapy.extensions.logstats] INFO: Crawled 953 pages (at 9 pages/min), scraped 691 items (at 1 items/min)
2018-11-11 05:27:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/company/vision/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:27:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/company/executive-team/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:28:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/company/ethics/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:28:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/author-spotlight/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:28:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.nutraceutical.com/company/history/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 05:28:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://newholdllc.com/operating-model>: HTTP status code is not handled or not allowed
/bin/sh: 1: kill: Illegal number: 
2018-11-11 05:28:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://newholdllc.com/building-partnerships>: HTTP status code is not handled or not allowed
2018-11-11 05:28:44 [scrapy.extensions.logstats] INFO: Crawled 965 pages (at 12 pages/min), scraped 695 items (at 4 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 05:30:19 [scrapy.extensions.logstats] INFO: Crawled 976 pages (at 11 pages/min), scraped 707 items (at 12 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 05:31:03 [scrapy.extensions.logstats] INFO: Crawled 981 pages (at 5 pages/min), scraped 712 items (at 5 items/min)
2018-11-11 05:31:49 [scrapy.extensions.logstats] INFO: Crawled 985 pages (at 4 pages/min), scraped 717 items (at 5 items/min)
2018-11-11 05:33:01 [scrapy.extensions.logstats] INFO: Crawled 993 pages (at 8 pages/min), scraped 725 items (at 8 items/min)
2018-11-11 05:34:04 [scrapy.extensions.logstats] INFO: Crawled 999 pages (at 6 pages/min), scraped 732 items (at 7 items/min)
2018-11-11 05:35:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://paymaster.com/tel:8887175577>: HTTP status code is not handled or not allowed
2018-11-11 05:35:10 [scrapy.extensions.logstats] INFO: Crawled 1007 pages (at 8 pages/min), scraped 740 items (at 8 items/min)
2018-11-11 05:35:46 [scrapy.extensions.logstats] INFO: Crawled 1017 pages (at 10 pages/min), scraped 745 items (at 5 items/min)
2018-11-11 05:36:53 [scrapy.extensions.logstats] INFO: Crawled 1025 pages (at 8 pages/min), scraped 756 items (at 11 items/min)
2018-11-11 05:37:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://sol-electrica.com/about_sere_sol_electrica.htm> (referer: http://sol-electrica.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 54, in replace
    return Response.replace(self, *args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 81, in replace
    return cls(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/__init__.py", line 22, in __init__
    self._set_body(body)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/http/response/text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
  File "/usr/lib/python3.6/encodings/cp1252.py", line 12, in encode
    return codecs.charmap_encode(input,errors,encoding_table)
UnicodeEncodeError: 'charmap' codec can't encode character '\u25ca' in position 2156: character maps to <undefined>
/bin/sh: 1: kill: Illegal number: 
2018-11-11 05:38:11 [scrapy.extensions.logstats] INFO: Crawled 1049 pages (at 24 pages/min), scraped 769 items (at 13 items/min)
2018-11-11 05:38:47 [scrapy.extensions.logstats] INFO: Crawled 1054 pages (at 5 pages/min), scraped 775 items (at 6 items/min)
/bin/sh: 1: kill: Illegal number: 
/bin/sh: 1: kill: Illegal number: 
2018-11-11 05:39:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://suntegrasolar.com/downloads/Ja-MarSunTegraPressRelease9.5.17.pdf%3C/a%3E%0A%09%09%09%09%09%09%09%09%09%09%09%09%09%3Csmall%3ESep%202017%3C/small%3E%0A%09%09%09%09%09%09%09%09%3C/li%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3Cli%3E%0A%09%09%09%09%09%09%09%09%09%3Ca%20class=>: HTTP status code is not handled or not allowed
 https://www.nutraceutical.com/collections/healthy/kal/kal-clinical-lifestyle/       Crawling page: https://www.nutraceutical.com/collections/healthy/kal/       Crawling page: https://www.nutraceutical.com/collections/healthy/kal/kal-vitamin-c/       Crawling page: https://www.nutraceutical.com/collections/healthy/       Crawling page: https://www.nutraceutical.com/company/employees/nutraceutical-benefits/       Crawling page: https://www.nutraceutical.com/catalog/brand-brochures/       Crawling page: https://www.nutraceutical.com/company/directors/       Crawling page: https://www.nutraceutical.com/company/employees/       Crawling page: https://www.nutraceutical.com/company/employees/current-open-positions/       Crawling page: https://www.nutraceutical.com/collections/       valid
Crawling page: https://www.nutraceutical.com/company/vision/       Crawling page: https://www.nutraceutical.com/company/executive-team/       Crawling page: https://www.nutraceutical.com/company/ethics/       Crawling page: https://www.nutraceutical.com/author-spotlight/       Crawling page: https://www.nutraceutical.com/company/history/       Crawling page: https://www.nutraceutical.com/       valid
Crawling page: http://newholdllc.com/news/       valid
Crawling page: http://newholdllc.com/contact/       valid
Crawling page: http://newholdllc.com/platforms/       valid
Crawling page: http://newholdllc.com/key-values/       valid
Crawling page: http://newholdllc.com/leadership/       valid
Crawling page: http://newholdllc.com/operating-strategy/       valid
Crawling page: https://www.plantsensorysystems.com/high-sugar-beets/       valid
Crawling page: https://www.plantsensorysystems.com/team/       valid
Crawling page: https://www.plantsensorysystems.com/nuest/       valid
Crawling page: https://paymaster.com/p/resources/status/       valid
Crawling page: https://paymaster.com/p/resources/calculators/       valid
Crawling page: https://paymaster.com/p/resources/app/       valid
Crawling page: https://paymaster.com/p/resources/conference/       valid
Crawling page: https://www.plantsensorysystems.com/       valid
Crawling page: http://newholdllc.com/who-we-are/       valid
Crawling page: https://paymaster.com/p/products/timeclocks/       valid
Crawling page: https://paymaster.com/p/products/paymaster-hcm/hr/       valid
Crawling page: https://paymaster.com/p/products/paymaster-hcm/pr/       valid
Crawling page: https://paymaster.com/p/products/paymaster-hcm/tlm/       valid
Crawling page: http://newholdllc.com/       valid
Crawling page: https://blog.paymaster.com       valid
Crawling page: https://paymaster.com/p/products/paymaster-hcm/overview/       valid
Crawling page: https://paymaster.com/p/services/industry/hospitality/       valid
Crawling page: https://paymaster.com/p/services/industry/construction-manufacturing/       valid
Crawling page: https://paymaster.com/p/services/insurance/workers-comp/       valid
Crawling page: https://paymaster.com/p/services/insurance/online-benefit-enrollment/       valid
Crawling page: https://paymaster.com/p/services/insurance/hsa/       valid
Crawling page: https://paymaster.com/p/services/insurance/fsa/       valid
Crawling page: https://paymaster.com/p/services/insurance/premium-only-plan/       valid
Crawling page: https://paymaster.com/p/services/insurance/aca/       valid
Crawling page: https://paymaster.com/p/services/benefits/online-benefit-enrollment/       valid
Crawling page: https://paymaster.com/p/services/benefits/retirement/       valid
Crawling page: https://paymaster.com/p/services/hr/labor-posters/       valid
Crawling page: https://paymaster.com/p/services/hr/substance-abuse/       valid
Crawling page: https://paymaster.com/p/services/hr/background-checks/       valid
Crawling page: https://paymaster.com/p/services/hr/state-new-hire/       valid
Crawling page: https://paymaster.com/p/services/hr/employee-handbooks/       valid
Crawling page: https://paymaster.com/p/services/hr/ess/       valid
Crawling page: https://paymaster.com/p/services/hr/recruitment/       valid
Crawling page: https://paymaster.com/p/services/hr/support/       valid
Crawling page: https://paymaster.com/p/services/tax/credit/       valid
Crawling page: https://paymaster.com/p/services/tax/year-end/       valid
Crawling page: https://paymaster.com/p/services/tax/federal-state-local/       valid
Crawling page: https://paymaster.com/p/services/payroll/general-ledger/       valid
Crawling page: https://paymaster.com/p/services/payroll/methods/       valid
Crawling page: https://paymaster.com/p/services/payroll/labor-distribution/       valid
Crawling page: https://paymaster.com/p/services/payroll/ess/       valid
Crawling page: https://paymaster.com/p/company/network/       valid
Crawling page: https://paymaster.com/p/company/contact/       valid
Crawling page: https://paymaster.com/p/company/about/       valid
Crawling page: https://www.plantsensorysystems.com/pss-images/       valid
Crawling page: https://www.plantsensorysystems.com/ourtechnologiesimages/       valid
Crawling page: https://paymaster.com/login/       valid
Crawling page: https://www.plantsensorysystems.com/management-team-pics/       valid
Crawling page: https://www.plantsensorysystems.com/pss-team/       valid
Crawling page: https://www.plantsensorysystems.com/advisory-team/       valid
Crawling page: https://www.plantsensorysystems.com/news/       valid
Crawling page: https://www.plantsensorysystems.com/media-coverage/       valid
Crawling page: https://www.plantsensorysystems.com/enhanced-nutrition/       valid
Crawling page: https://www.plantsensorysystems.com/enhanced-nutrition       valid
Crawling page: https://www.plantsensorysystems.com/taurine/       valid
Crawling page: https://www.plantsensorysystems.com/taurine       valid
Crawling page: https://www.plantsensorysystems.com/contact/       valid
Crawling page: https://www.plantsensorysystems.com/nuest       valid
Crawling page: https://www.plantsensorysystems.com/ourtechnologiesimages/       valid
Crawling page: http://sol-electrica.com/contact.htm       valid
Crawling page: http://sol-electrica.com/about_sere_sol_electrica.htm       Crawling page: http://samsungsdi.com/       valid
Crawling page: https://www.plantsensorysystems.com/ourtechnologiesimages/       valid
Crawling page: http://www.solenafuels.com/category/health-insurance/       valid
Crawling page: http://www.solenafuels.com/3-tips-for-choosing-health-insurance-coverage-in-virginia/       valid
Crawling page: http://www.solenafuels.com/how-to-select-affordable-automobile-insurance-in-virginia/       valid
Crawling page: http://www.solenafuels.com/category/auto-insurance-information/       valid
Crawling page: http://samsungsdi.com/ess/energy-storage-system-technology.html       valid
Crawling page: http://samsungsdi.com/ess/index.html       valid
Crawling page: http://samsungsdi.com/ess/energy-storage-system-application.html       valid
Crawling page: http://samsungsdi.com/automotive-battery/china-special.html       valid
Crawling page: http://starsource.com/index.asp       valid
Crawling page: http://samsungsdi.com/automotive-battery/partnership.html       valid
Crawling page: http://samsungsdi.com/sitemap.html       valid
Crawling page: http://samsungsdi.com/cs-center-inquiry.html       valid
Crawling page: http://www.verlase.com/contact.html       valid
Crawling page: https://www.soliton.com       valid
Crawling page: http://starsource.com/about/?33.html       valid
Crawling page: http://www.verlase.com/news.html       valid
Crawling page: http://starsource.com/about/?40.html       valid
Crawling page: http://starsource.com/about/?41.html       valid
Crawling page: http://suntegrasolar.com/contact-suntegra       valid
Crawling page: http://www.verlase.com/       valid
Crawling page: http://starsource.com/about/?39.html       valid
Crawling page: http://suntegrasolar.com/solar-roof-shingles-residential-solar-quote       valid
Crawling page: http://suntegrasolar.com/solar-roof-tiles-residential-solar-quote       valid
Crawling page: http://starsource.com/about/?45.html       valid
Crawling page: http://suntegrasolar.com/suntegra-partner-form2018-11-11 05:39:56 [scrapy.extensions.logstats] INFO: Crawled 1066 pages (at 12 pages/min), scraped 787 items (at 12 items/min)
2018-11-11 05:40:50 [scrapy.extensions.logstats] INFO: Crawled 1081 pages (at 15 pages/min), scraped 797 items (at 10 items/min)
2018-11-11 05:41:49 [scrapy.extensions.logstats] INFO: Crawled 1089 pages (at 8 pages/min), scraped 807 items (at 10 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 05:42:49 [scrapy.extensions.logstats] INFO: Crawled 1105 pages (at 16 pages/min), scraped 821 items (at 14 items/min)
2018-11-11 05:43:44 [scrapy.extensions.logstats] INFO: Crawled 1111 pages (at 6 pages/min), scraped 830 items (at 9 items/min)
2018-11-11 05:44:45 [scrapy.extensions.logstats] INFO: Crawled 1119 pages (at 8 pages/min), scraped 838 items (at 8 items/min)
2018-11-11 05:46:04 [scrapy.extensions.logstats] INFO: Crawled 1127 pages (at 8 pages/min), scraped 850 items (at 12 items/min)
2018-11-11 05:46:45 [scrapy.extensions.logstats] INFO: Crawled 1137 pages (at 10 pages/min), scraped 856 items (at 6 items/min)
2018-11-11 05:47:56 [scrapy.extensions.logstats] INFO: Crawled 1145 pages (at 8 pages/min), scraped 866 items (at 10 items/min)
2018-11-11 05:48:59 [scrapy.extensions.logstats] INFO: Crawled 1152 pages (at 7 pages/min), scraped 874 items (at 8 items/min)
2018-11-11 05:48:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.sintoninstruments.com/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:49:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.soliton.com/technology/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:49:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.soliton.com/for-clinicians/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 05:49:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://samsungsdi.com/about-sdi/index.html>: HTTP status code is not handled or not allowed
2018-11-11 05:49:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.soliton.com/privacy-policy/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 05:49:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://sunsynchrony.com/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 05:49:45 [scrapy.extensions.logstats] INFO: Crawled 1157 pages (at 5 pages/min), scraped 881 items (at 7 items/min)
2018-11-11 05:49:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://weccamerica.com/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
       valid
Crawling page: http://starsource.com/about/?43.html       valid
Crawling page: http://starsource.com/about/?32.html       valid
Crawling page: http://starsource.com/gbook/?42_1.html       valid
Crawling page: http://suntegrasolar.com/solar-roof-system-testimonial-eastvale       valid
Crawling page: http://suntegrasolar.com/solar-roof-system-testimonial-glendale       valid
Crawling page: http://suntegrasolar.com/solar-roof-system-testimonial-morristown       valid
Crawling page: http://suntegrasolar.com/suntegra-news       valid
Crawling page: https://www.soliton.com/contact/       valid
Crawling page: https://www.soliton.com/about/       valid
Crawling page: http://suntegrasolar.com/about-suntegra       valid
Crawling page: http://suntegrasolar.com/suntegra-press-releases       valid
Crawling page: http://suntegrasolar.com/suntegra-careers       valid
Crawling page: http://suntegrasolar.com/suntegra-testimonials       valid
Crawling page: http://suntegrasolar.com/suntegra-homeowners       valid
Crawling page: http://suntegrasolar.com/suntegra-gallery       valid
Crawling page: http://suntegrasolar.com/suntegra-business       valid
Crawling page: https://www.soliton.com/standards/       valid
Crawling page: https://www.soliton.com/our-future/       valid
Crawling page: https://www.soliton.com/trials/       valid
Crawling page: https://www.soliton.com/for-patients/       valid
Crawling page: https://www.soliton.com/for-clinicians/       valid
Crawling page: http://starsource.com/list/?31_1.html       valid
Crawling page: http://suntegrasolar.com/suntegra-tiles       valid
Crawling page: http://suntegrasolar.com/the-suntegra-advantage       valid
Crawling page: http://suntegrasolar.com/suntegra-shingles       valid
Crawling page: http://suntegrasolar.com/suntegra-partner       valid
Crawling page: http://www.ssxray.com/?page_id=45       valid
Crawling page: http://www.ssxray.com/?page_id=12       valid
Crawling page: http://www.ssxray.com/?page_id=11       valid
Crawling page: http://starsource.com/about/?35.html       valid
Crawling page: http://starsource.com/?LanguageAlias1=cn       valid
Crawling page: http://starsource.com/       valid
Crawling page: http://www.solenafuels.com/what-is-the-right-amount-of-coverage-for-virginia-insurance-for-your-home/       valid
Crawling page: http://www.solenafuels.com/       valid
Crawling page: http://www.ssxray.com/?page_id=10       valid
Crawling page: http://www.solenafuels.com/category/home-insurance/       valid
Crawling page: http://suntegrasolar.com       valid
Crawling page: http://www.ssxray.com       valid
Crawling page: http://samsungsdi.com/column/technology/detail/55446.html?listType=gallery       valid
Crawling page: http://samsungsdi.com/column/technology/detail/55162.html?listType=gallery       valid
Crawling page: http://samsungsdi.com/cyber-audit/business-principle.html       valid
Crawling page: http://samsungsdi.com/column/technology/detail/55272.html?listType=gallery       valid
Crawling page: http://samsungsdi.com/sdi-news/1842.html?idx=1842       valid
Crawling page: http://samsungsdi.com/sdi-news/1803.html?idx=1803       valid
Crawling page: http://samsungsdi.com/sdi-news/1903.html?idx=1903       valid
Crawling page: http://samsungsdi.com/column/all/gallery.html       valid
Crawling page: http://samsungsdi.com/electronic-materials/oled/tfe-thin-film-encapsulation.html       valid
Crawling page: http://samsungsdi.com/electronic-materials/solar-battery/pv-paste.html       valid
Crawling page: http://samsungsdi.com/sdi-news/list.html       valid
Crawling page: http://samsungsdi.com/electronic-materials/oled/evaporation-material.html       valid
Crawling page: http://samsungsdi.com/electronic-materials/lcd/color-pr.html       valid
Crawling page: http://samsungsdi.com/electronic-materials/lcd/pol-polarizing-film.html       valid
Crawling page: http://samsungsdi.com/electronic-materials/semiconductor/emc-epoxy-molding-compound.html       valid
Crawling page: http://samsungsdi.com/electronic-materials/semiconductor/sod-spin-on-dielectrics.html       valid
Crawling page: http://samsungsdi.com/electronic-materials/semiconductor/soh-spin-on-hardmask.html       valid
Crawling page: http://samsungsdi.com/electronic-materials/index.html       valid
Crawling page: http://samsungsdi.com/ess/energy-storage-system-reference.html       valid
Crawling page: http://samsungsdi.com/automotive-battery/battery-application.html       valid
Crawling page: http://samsungsdi.com/automotive-battery/products/prismatic-lithium-ion-battery-cell.html       valid
Crawling page: http://samsungsdi.com/automotive-battery/innovation.html       valid
Crawling page: http://samsungsdi.com/automotive-battery/index.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/safe-information.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/trans-devices/ignition.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/trans-devices/e-scooter.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/trans-devices/e-bike.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/power-devices/vacuum-cleaner.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/power-devices/garden-tool.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/power-devices/power-tool.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/it-devices/power-bank.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/it-devices/wearable-device.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/it-devices/tablet.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/it-devices/laptop.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/index.html       valid
Crawling page: http://samsungsdi.com/lithium-ion-battery/it-devices/mobile-phone.html       valid
Crawling page: http://samsungsdi.com/career/job-description-philosophy.html       valid
Crawling page: http://samsungsdi.com/ir/financial-information/financial-highlights.html       valid
Crawling page: http://samsungsdi.com/business.html       valid
Crawling page: http://samsungsdi.com/ir/corporate-governance/articles-of-incorporation.html       valid
Crawling page: http://samsungsdi.com/ir/stock-information/dividend-details.html       valid
Crawling page: http://samsungsdi.com/social-contribution/we-dream/school.html       valid
Crawling page: http://samsungsdi.com/social-contribution/index.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/safety-environment-policy/index.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/quality-management/index.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/compliance/index.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/suppliers/joint-growth.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/sustainability/report/sustainability-report.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/sustainability/supply-chain-responsibility.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/sustainability/climate-environment/eco-value.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/sustainability/approach/vision-strategy.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/sustainability/implementation-system.html       valid
Crawling page: http://samsungsdi.com/about-sdi/research-development.html       valid
Crawling page: http://samsungsdi.com/sustainable-management/index.html       valid
Crawling page: http://samsungsdi.com/about-sdi/global-network.html       valid
Crawling page: http://samsungsdi.com/about-sdi.html       valid
Crawling page: http://samsungsdi.com/about-sdi/ci.html       valid
Crawling page: http://samsungsdi.com/about-sdi/history.html       valid
Crawling page: http://www.allianceforsustainableenergy.org/terms-conditions.html       valid
Crawling page: http://frontedgetechnology.com/contact.htm/bin/sh: 1: kill: No such process

2018-11-11 05:50:41 [scrapy.extensions.logstats] INFO: Crawled 1191 pages (at 34 pages/min), scraped 892 items (at 11 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 05:52:40 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 22 pages/min), scraped 910 items (at 18 items/min)
2018-11-11 05:52:48 [scrapy.extensions.logstats] INFO: Crawled 1216 pages (at 3 pages/min), scraped 912 items (at 2 items/min)
2018-11-11 05:53:41 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 6 pages/min), scraped 921 items (at 9 items/min)
2018-11-11 05:54:53 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 11 pages/min), scraped 932 items (at 11 items/min)
2018-11-11 05:55:55 [scrapy.extensions.logstats] INFO: Crawled 1241 pages (at 8 pages/min), scraped 940 items (at 8 items/min)
2018-11-11 05:56:41 [scrapy.extensions.logstats] INFO: Crawled 1249 pages (at 8 pages/min), scraped 947 items (at 7 items/min)
2018-11-11 05:57:55 [scrapy.extensions.logstats] INFO: Crawled 1260 pages (at 11 pages/min), scraped 959 items (at 12 items/min)
2018-11-11 05:58:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://eni.com/enipedia/en_IT/financial-corporate-reporting/operating-activities/remit-regulation.page>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 05:58:49 [scrapy.extensions.logstats] INFO: Crawled 1269 pages (at 9 pages/min), scraped 968 items (at 9 items/min)
       valid
Crawling page: http://xtalsolar.com/       valid
Crawling page: http://www.htstechnologies.com/manufacturing-partners       valid
Crawling page: https://gsrm.samsungsdi.com       valid
Crawling page: http://www.htstechnologies.com/home       valid
Crawling page: http://www.htstechnologies.com/about       valid
Crawling page: http://www.htstechnologies.com/contact-us       valid
Crawling page: http://www.htstechnologies.com/equipment-tooling       valid
Crawling page: https://astech.com/privacy-policy       valid
Crawling page: http://nanoquantum.com/Privacy.html       valid
Crawling page: http://nanoquantum.com/Products.html       valid
Crawling page: http://www.ablexis.com/privacy-policy/       valid
Crawling page: http://www.ablexis.com/contact/       valid
Crawling page: http://nanoquantum.com/About.html       valid
Crawling page: http://nanoquantum.com/       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/enhancing-professionalism.page       valid
Crawling page: http://nanoquantum.com/Technology.html       valid
Crawling page: http://www.growenergy.org/company/investors/       valid
Crawling page: http://www.growenergy.org/company/press/       valid
Crawling page: http://www.growenergy.org/company/partners/       valid
Crawling page: http://www.growenergy.org/company/legal/       valid
Crawling page: https://astech.com/news/astech-announces-new-extended-hours       valid
Crawling page: https://astech.com/news/see-what-cant-be-seen-with-the-astech       valid
Crawling page: https://astech.com/news/repairify-inc-parent-company-of-astech-expands-again-and-opens-new-center-of-excellence-in-irving       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/training-at-eni.page       valid
Crawling page: https://www.luminultra.com/privacy-policy/       valid
Crawling page: https://www.luminultra.com/newsletter/       valid
Crawling page: https://www.luminultra.com/press-kit/       valid
Crawling page: https://www.eni.com/en_IT/privacy.page       valid
Crawling page: https://www.eni.com/en_IT/terms-and-conditions.page       valid
Crawling page: https://www.luminultra.com/terms-and-conditions/       valid
Crawling page: https://www.eni.com/en_IT/accessibility.page       valid
Crawling page: https://www.eni.com/en_IT/sitemap.page       valid
Crawling page: https://www.eni.com/enipedia/en_IT/business-model/awards-recognition/eni-award-announcement-2019.page       valid
Crawling page: https://www.eni.com/en_IT/mobile-app.page       valid
Crawling page: https://www.eni.com/en_IT/careers/contacts-careers.page       valid
Crawling page: https://www.eni.com/en_IT/careers/training-and-guidance/masters-programmes-promoted-by-eni-with-universities.page       valid
Crawling page: https://www.eni.com/en_IT/careers/training-and-guidance/2nd-level-specializing-master-energy-engineering-operations.page       valid
Crawling page: https://www.eni.com/en_IT/careers/training-and-guidance/2nd-level-specializing-master-energy-innovation.page       valid
Crawling page: https://www.eni.com/en_IT/careers/training-and-guidance/the-scuola-mattei-and-the-medea-masters.page       valid
Crawling page: https://www.eni.com/en_IT/careers/training-and-guidance/enis-contribution-to-masters-degrees.page       valid
Crawling page: https://www.eni.com/en_IT/careers/training-and-guidance/university-courses-and-high-level-training.page       valid
Crawling page: https://www.eni.com/en_IT/careers/training-and-guidance/eni-corporate-university.page       valid
Crawling page: https://www.eni.com/en_IT/careers/training-and-guidance.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/eni-international-resources.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/compensation-and-benefits.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/corporate-welfare-and-personal-services.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/career-paths.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/our-people-in-numbers/our-people-in-numbers.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/our-people.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/diversity.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/what-we-expect-from-our-people.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/amran-story.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/being-part-of-Eni.page       valid
Crawling page: https://www.eni.com/en_IT/careers/job-opportunities/false-job-offers.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni.page       valid
Crawling page: https://www.eni.com/en_IT/careers/job-opportunities/professional-areas-necessary-qualifications.page       valid
Crawling page: https://www.eni.com/en_IT/careers/job-opportunities/the-selection-process.page       valid
Crawling page: https://www.eni.com/en_IT/careers/job-opportunities/jobs-available.page       valid
Crawling page: https://www.eni.com/en_IT/careers/job-opportunities.page       valid
Crawling page: https://www.eni.com/en_IT/careers.page       valid
Crawling page: https://www.eni.com/en_IT/calendar.page       valid
Crawling page: https://www.eni.com/en_IT/media/press-center/press-announcements.page       valid
Crawling page: https://www.eni.com/en_IT/media/press-center/press-kit.page       valid
Crawling page: https://www.eni.com/en_IT/media/press-center.page       valid
Crawling page: https://www.eni.com/en_IT/media/editoria.page       valid
Crawling page: https://www.eni.com/en_IT/media/multimedia.page       valid
Crawling page: https://www.eni.com/en_IT/media/eni-social-media.page       valid
Crawling page: https://www.eni.com/en_IT/media/focus-on.page       valid
Crawling page: https://www.eni.com/en_IT/media/news.page       valid
Crawling page: https://www.eni.com/en_IT/media/press-releases.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/contacts-sustainability.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/news-sustainability.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/reporting/performance-tool.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/reporting/the-sustainability-reporting-certification-process.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/reporting/gri-content-index.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/reporting/results.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/reporting/materiality.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/reporting.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/eni-interest-representation-activities.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/organisational-transparency.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/tax-strategy.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/transparency-of-payments.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/combating-corruption.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/access-to-remedy.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/due-diligence/human-rights-security.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/due-diligence/host-communities.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/due-diligence/suppliers-other-business-partners.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/due-diligence/human-rights-workplace.page       valid
Crawling page:2018-11-11 05:59:41 [scrapy.extensions.logstats] INFO: Crawled 1280 pages (at 11 pages/min), scraped 977 items (at 9 items/min)
2018-11-11 06:00:50 [scrapy.extensions.logstats] INFO: Crawled 1290 pages (at 10 pages/min), scraped 989 items (at 12 items/min)
2018-11-11 06:01:54 [scrapy.extensions.logstats] INFO: Crawled 1302 pages (at 12 pages/min), scraped 1001 items (at 12 items/min)
2018-11-11 06:02:52 [scrapy.extensions.logstats] INFO: Crawled 1311 pages (at 9 pages/min), scraped 1010 items (at 9 items/min)
2018-11-11 06:03:46 [scrapy.extensions.logstats] INFO: Crawled 1320 pages (at 9 pages/min), scraped 1019 items (at 9 items/min)
2018-11-11 06:04:53 [scrapy.extensions.logstats] INFO: Crawled 1332 pages (at 12 pages/min), scraped 1031 items (at 12 items/min)
2018-11-11 06:05:56 [scrapy.extensions.logstats] INFO: Crawled 1341 pages (at 9 pages/min), scraped 1040 items (at 9 items/min)
 https://www.eni.com/en_IT/sustainability/integrity-human-rights/due-diligence/salient-hr-issues.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/due-diligence.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/commitment/partnerships.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/commitment/training.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/commitment/communication.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/commitment/governance.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/commitment/policies.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/commitment.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/environment-day.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/remediation.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/oil-spill-management.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/the-protection-of-air-quality.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/the-protection-of-biodiversity-and-water.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/environmental-management/green-sourcing-position.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/environmental-management/biomass-commitments-results.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/environmental-management/position-biomass.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/enis-environmental-management.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/partnerships-for-sustainable-energy/memorandum-understanding-between-eni-undp.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/partnerships-for-sustainable-energy/ogci.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/energy-scenarios.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/governance-and-risk-management.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/research-development.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/commitment-to-renewable-energy.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/the-low-carbon-portfolio-and-its-resilience.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/reducing-emissions.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/energy-and-climate-Enis-strategy.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/local-development/global-health.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/local-development/access-to-energy.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/local-development/local-content.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/local-development/local-communities-development.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/local-development.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety/day.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety/safety4.0.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety/management/contractor.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety/management/emergency.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety/management/process.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety/management.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety/culture/sharing-excellence.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety/culture.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/stakeholder-relations/enis-relations-with-suppliers.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/stakeholder-relations/enis-relations-with-consumer-associations.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/stakeholder-relations/eni-s-relations-with-NGOs.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/stakeholder-relations/eni-s-relations-with-financial-stakeholders.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/stakeholder-relations/relations-with-international-bodies.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/stakeholder-relations/stakeholder-involvement.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/stakeholder-relations.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/product-safety.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/labour-standards.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/enhancing-diversity.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/knowledge-management.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/eni-healthy-business.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/sustainability-objectives.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/responsible-company/our-sustainable-story.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/news-innovation.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award/2018-recognition-innovation.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award/2018-elvis-tinashe-ganda-debut-research-young-talents-africa.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award/2018-emerance-goma-tchimbakala-debut-research-young-talents-africa.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award/2018-michele-de-bastiani-young-researcher-year.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award/2018-zhong-lin-wang-energy-frontiers.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award/2018-gianluca-longoni-young-researcher-year.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award/2018-sang-yup-lee-advanced-environmental-solutions.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award/2018-omar-yaghi-energy-transition.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/our-skills/knowledge-management-system.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/our-skills/research-alliances-and-collaborations/eni-cnr.page2018-11-11 06:06:53 [scrapy.extensions.logstats] INFO: Crawled 1350 pages (at 9 pages/min), scraped 1049 items (at 9 items/min)
2018-11-11 06:07:54 [scrapy.extensions.logstats] INFO: Crawled 1359 pages (at 9 pages/min), scraped 1058 items (at 9 items/min)
2018-11-11 06:09:04 [scrapy.extensions.logstats] INFO: Crawled 1368 pages (at 9 pages/min), scraped 1067 items (at 9 items/min)
2018-11-11 06:09:44 [scrapy.extensions.logstats] INFO: Crawled 1376 pages (at 8 pages/min), scraped 1073 items (at 6 items/min)
2018-11-11 06:10:45 [scrapy.extensions.logstats] INFO: Crawled 1385 pages (at 9 pages/min), scraped 1082 items (at 9 items/min)
2018-11-11 06:11:55 [scrapy.extensions.logstats] INFO: Crawled 1392 pages (at 7 pages/min), scraped 1091 items (at 9 items/min)
2018-11-11 06:12:54 [scrapy.extensions.logstats] INFO: Crawled 1402 pages (at 10 pages/min), scraped 1100 items (at 9 items/min)
2018-11-11 06:13:51 [scrapy.extensions.logstats] INFO: Crawled 1411 pages (at 9 pages/min), scraped 1110 items (at 10 items/min)
       valid
Crawling page: https://www.eni.com/en_IT/innovation/our-skills/research-alliances-and-collaborations/eni-mit-collaboration-energy-transition.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/our-skills/research-alliances-and-collaborations/research-eni-mit-exploration.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/our-skills/research-alliances-and-collaborations.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/our-skills/renewable-energy-and-environmental-rd-center.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/our-skills.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/renewable-energy/concentrated-thermodynamic-solar-power.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/renewable-energy/new-solar-energy-technology.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/renewable-energy/lsc-luminescent-solar-concentrators.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/renewable-energy.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/energy-transition/carbon-dioxide.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/energy-transition/promoting-sulphur-as-resource.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/energy-transition/methanol-gas.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/energy-transition.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/bio-refinery/green-diesel.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/bio-refinery/algae-biofuel.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/bio-refinery/waste-to-fuel.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/bio-refinery.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/safety-and-the-environment/rapid-cube.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/safety-and-the-environment/clean-sea.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/maximize-recovery/hpc.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/maximize-recovery.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/upstream-operational-excellence.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/successful-exploration/technology-gas-systems.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/successful-exploration/technology-seismic-data.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/successful-exploration/technology-sand-box.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/successful-exploration/technology-core-sampling.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/successful-exploration.page       valid
Crawling page: https://www.eni.com/en_IT/investors/contacts-investors.page       valid
Crawling page: https://www.eni.com/en_IT/investors/financial-calendar.page       valid
Crawling page: https://www.eni.com/en_IT/investors/investor-tool/value-your-portfolio.page       valid
Crawling page: https://www.eni.com/en_IT/investors/investor-tool/share-price-performance.page       valid
Crawling page: https://www.eni.com/en_IT/investors/investor-tool/annual-charts-operating-data.page       valid
Crawling page: https://www.eni.com/en_IT/investors/investor-tool/annual-charts-financial-highlights.page       valid
Crawling page: https://www.eni.com/en_IT/investors/investor-tool/historic-trend.page       valid
Crawling page: https://www.eni.com/en_IT/investors/investor-tool/interactive-financial-highlights.page       valid
Crawling page: https://www.eni.com/en_IT/investors/investor-tool.page       valid
Crawling page: https://www.eni.com/en_IT/investors/presentations-and-reports/reports.page       valid
Crawling page: https://www.eni.com/en_IT/investors/presentations-and-reports/presentations/financial-results-and-presentations.page       valid
Crawling page: https://www.eni.com/en_IT/investors/results-and-reports.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-in-numbers/capital-expenditures-by-division.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-in-numbers/summarized-group-cash-flow-statement-changes-net-borrowings.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-in-numbers/summarized-group-balance-sheet.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-in-numbers/adjusted-operating-profit.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-in-numbers/profit-loss-account.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-in-numbers/selected-operating-data.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-in-numbers/selected-consolidated-financial-data.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-in-numbers.page       valid
Crawling page: https://www.eni.com/en_IT/investors/market-rating/dcm-documents.page       valid
Crawling page: https://www.eni.com/en_IT/investors/market-rating/credit-rating-and-debt.page       valid
Crawling page: https://www.eni.com/en_IT/investors/market-rating.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-on-the-stock-markets/sustainability-indexes.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-on-the-stock-markets/share-data.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-on-the-stock-markets/share-capital-evolution.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-on-the-stock-markets/eni-peers.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-on-the-stock-markets/dividends.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-on-the-stock-markets/adrs-on-the-nyse.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-on-the-stock-markets/listing-and-indices.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-on-the-stock-markets.page       valid
Crawling page: https://www.luminultra.com/careers/       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/risks/financial-risks.page       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/sensitivity-factors.page       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/risks/top-risks.page       valid
Crawling page: https://www.eni.com/en_IT/investors/risk-management.page       valid
Crawling page: https://www.eni.com/en_IT/investors/global-energy-scenarios/world-energy-outlook.page       valid
Crawling page: https://www.eni.com/en_IT/investors/global-energy-scenarios/world-gas-e-renewables-review-2018.page       valid
Crawling page: https://www.eni.com/en_IT/investors/global-energy-scenarios.page       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/macro-economic-trends.page       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/acquisitions-and-disposals.page       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/outlook.page       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/enis-strengths.page       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/decarbonization-sustainability.page       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/2021-objectives-concrete-actions.page       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/strategic-plan-2018-2021.page       valid
Crawling page:2018-11-11 06:14:49 [scrapy.extensions.logstats] INFO: Crawled 1422 pages (at 11 pages/min), scraped 1119 items (at 9 items/min)
2018-11-11 06:15:49 [scrapy.extensions.logstats] INFO: Crawled 1430 pages (at 8 pages/min), scraped 1128 items (at 9 items/min)
2018-11-11 06:16:42 [scrapy.extensions.logstats] INFO: Crawled 1441 pages (at 11 pages/min), scraped 1136 items (at 8 items/min)
2018-11-11 06:17:43 [scrapy.extensions.logstats] INFO: Crawled 1447 pages (at 6 pages/min), scraped 1145 items (at 9 items/min)
2018-11-11 06:19:06 [scrapy.extensions.logstats] INFO: Crawled 1461 pages (at 14 pages/min), scraped 1155 items (at 10 items/min)
2018-11-11 06:20:08 [scrapy.extensions.logstats] INFO: Crawled 1472 pages (at 11 pages/min), scraped 1163 items (at 8 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 06:20:54 [scrapy.extensions.logstats] INFO: Crawled 1476 pages (at 4 pages/min), scraped 1170 items (at 7 items/min)
2018-11-11 06:21:42 [scrapy.extensions.logstats] INFO: Crawled 1486 pages (at 10 pages/min), scraped 1179 items (at 9 items/min)
2018-11-11 06:23:03 [scrapy.extensions.logstats] INFO: Crawled 1494 pages (at 8 pages/min), scraped 1188 items (at 9 items/min)
2018-11-11 06:23:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <406 http://linneindustries.com/company/>: HTTP status code is not handled or not allowed
2018-11-11 06:23:48 [scrapy.extensions.logstats] INFO: Crawled 1494 pages (at 0 pages/min), scraped 1195 items (at 7 items/min)
2018-11-11 06:23:57 [root] ERROR: Unable to find match for url: https://jobs.gartner.com
2018-11-11 06:24:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.gartner.com/events/calendar/ea.jsp?cm_sp=site-_-itg-_-easummit2017> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 06:24:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.gartner.com/events/calendar/io.jsp?cm_sp=site-_-itg-_-iosummit0217> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 06:24:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.gartner.com/technology/research/predicts/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 06:24:58 [scrapy.extensions.logstats] INFO: Crawled 1510 pages (at 16 pages/min), scraped 1200 items (at 5 items/min)
 https://www.eni.com/en_IT/investors/strategy.page       valid
Crawling page: https://www.eni.com/en_IT/investors.page       valid
Crawling page: https://www.eni.com/en_IT/operations/news-operations.page       valid
Crawling page: https://www.eni.com/en_IT/operations/new-energy-solutions/renewables/sustainable-sources.page       valid
Crawling page: https://www.eni.com/en_IT/operations/new-energy-solutions/renewables/progetto-italia.page       valid
Crawling page: https://www.eni.com/en_IT/operations/new-energy-solutions/renewables.page       valid
Crawling page: https://www.eni.com/en_IT/operations/new-energy-solutions/gas-advocacy.page       valid
Crawling page: https://www.eni.com/en_IT/operations/new-energy-solutions/decarbonization.page       valid
Crawling page: https://www.eni.com/en_IT/operations/new-energy-solutions.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/chemicals/guayule-rubber.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/chemicals/green-chemistry.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/chemicals.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/refining-marketing/retail-downstream-mobility.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/refining-marketing/biorefineries.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/refining-marketing/biofuel-urban-mobility.page       valid
Crawling page: https://www.luminultra.com/resource-types/case-studies/       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/power-activities/portfolio.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/power-activities/sustainability-environment-safety.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/power-activities/thermoelectric-plants.page       valid
Crawling page: https://www.luminultra.com/quickstart/       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/power-activities.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/eni-trading-and-shipping.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/ing-activities.page       valid
Crawling page: https://www.luminultra.com/how-to-mitigate-biofouling-in-your-industrial-process-using-2nd-generation-atp/       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/gas-power.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/restructuring-mid-downstream.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream.page       valid
Crawling page: https://www.luminultra.com/most-wanted-microbes-pseudomonas/       valid
Crawling page: https://www.luminultra.com/luminultra-academy/       valid
Crawling page: https://www.luminultra.com/luminultra-cloud/       valid
Crawling page: https://www.luminultra.com/mitigating-reservoir-souring-through-biological-monitoring/       valid
Crawling page: https://www.luminultra.com/why-raw-water-may-not-be-as-pure-as-you-think-the-risks-of-all-natural-raw-water/       valid
Crawling page: https://www.luminultra.com/what-can-2nd-generation-atp-do-for-an-operator-or-field-technician/       valid
Crawling page: https://www.luminultra.com/quiz-time-time-to-test-your-water-smarts/       valid
Crawling page: https://www.luminultra.com/industry/product-preservation/       valid
Crawling page: https://www.luminultra.com/industry/metalworking-fluids/       valid
Crawling page: https://www.luminultra.com/industry/upstream-oil-gas/       valid
Crawling page: https://www.luminultra.com/industry/cooling-water-systems/       valid
Crawling page: https://www.luminultra.com/industry/petroleum-and-fuel/       valid
Crawling page: https://www.luminultra.com/industry/industrial-process-fluids/       valid
Crawling page: https://www.luminultra.com/industry/wastewater-treatment/       valid
Crawling page: https://www.luminultra.com/industry/drinking-water/       valid
Crawling page: https://www.luminultra.com/news-release-one-stop-microbiology-management-now-available-as-luminultra-acquires-instantlabs/       valid
Crawling page: https://www.luminultra.com/contact/       valid
Crawling page: https://www.luminultra.com/resources/       valid
Crawling page: https://www.luminultra.com/blog/       valid
Crawling page: https://www.luminultra.com/products/       valid
Crawling page: https://www.luminultra.com/industries/       valid
Crawling page: https://www.luminultra.com/photonmaster/       valid
Crawling page: https://www.luminultra.com/tech/       valid
Crawling page: https://www.luminultra.com/about/       valid
Crawling page: https://www.luminultra.com/       valid
Crawling page: http://linneindustries.com/privacy/       valid
Crawling page: http://linneindustries.com/site-map/       valid
Crawling page: http://linneindustries.com/pondhawk-solar-pond-aeration-at-hokies-housing-in-blacksburg/       valid
Crawling page: https://www.luminultra.com/partner-community-section/       valid
Crawling page: http://linneindustries.com/linne-industries-introduces-pondhawk-lease-program/       valid
Crawling page: http://linneindustries.com/controller/       valid
Crawling page: http://linneindustries.com/linne-industries-participates-in-spark-program/       valid
Crawling page: http://linneindustries.com/events/       valid
Crawling page: http://linneindustries.com/contact/       valid
Crawling page: http://linneindustries.com/past-events/       valid
Crawling page: http://linneindustries.com/news/       valid
Crawling page: https://www.gartner.com/reviews/home?refval=it_glossary&campaign=it_glossary       valid
Crawling page: https://www.gartner.com/en/newsroom       valid
Crawling page: https://www.gartner.com/webinar/3842671?srcId=1-3931087981       valid
Crawling page: https://www.gartner.com/user/registration/prospect?resId=3471568&srcId=1-2625048590&pcp=gi       valid
Crawling page: https://www.gartner.com/en/about/policies/overview       valid
Crawling page: http://linneindustries.com/tag/subsurface-aeration/       valid
Crawling page: http://linneindustries.com/leasing-program/       valid
Crawling page: http://linneindustries.com/pondhawk-faqs/       valid
Crawling page: http://linneindustries.com/pondhawk-technical-information/       valid
Crawling page: http://linneindustries.com/briefs/       valid
Crawling page: https://www.gartner.com/webinar/3886523?srcId=1-3931087981       valid
Crawling page: https://www.gartner.com/en/become-a-client       valid
Crawling page: http://linneindustries.com/pondhawk-videos/       valid
Crawling page: http://linneindustries.com/pondhawk-projects/       valid
Crawling page: http://linneindustries.com/pondhawk-features/       valid
Crawling page: http://linneindustries.com/pondhawk-overview/       valid
Crawling page: https://www.gartner.com/doc/3170720?srcId=1-3931087981       valid
Crawling page: https://jobs.gartner.com       valid
Crawling page: https://www.gartner.com/events/calendar/ea.jsp?cm_sp=site-_-itg-_-easummit2017       Crawling page: https://www.gartner.com/events/calendar/io.jsp?cm_sp=site-_-itg-_-iosummit0217       Crawling page: https://www.gartner.com/technology/research/predicts/       Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model/production-gas-nooros-egypt.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model/indonesia-jangkrik.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model/zohr-egypt.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model/goliat-norway.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model/congo-nene-marine.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model/east-west-hub-angola.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model/production-record.page       2018-11-11 06:25:58 [scrapy.extensions.logstats] INFO: Crawled 1514 pages (at 4 pages/min), scraped 1208 items (at 8 items/min)
2018-11-11 06:26:56 [scrapy.extensions.logstats] INFO: Crawled 1522 pages (at 8 pages/min), scraped 1216 items (at 8 items/min)
2018-11-11 06:27:42 [scrapy.extensions.logstats] INFO: Crawled 1530 pages (at 8 pages/min), scraped 1224 items (at 8 items/min)
2018-11-11 06:28:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.neuralsignals.com/www.neuralsignalsdonate.com>: HTTP status code is not handled or not allowed
/bin/sh: 1: kill: No such process

2018-11-11 06:29:07 [scrapy.extensions.logstats] INFO: Crawled 1545 pages (at 15 pages/min), scraped 1238 items (at 14 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 06:29:41 [scrapy.extensions.logstats] INFO: Crawled 1554 pages (at 9 pages/min), scraped 1246 items (at 8 items/min)
/bin/sh: 1: kill: No such process

/bin/sh: 1: kill: No such process

2018-11-11 06:30:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.gartner.com/webinar/3123418> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 06:30:42 [scrapy.extensions.logstats] INFO: Crawled 1563 pages (at 9 pages/min), scraped 1257 items (at 11 items/min)
2018-11-11 06:32:11 [scrapy.extensions.logstats] INFO: Crawled 1583 pages (at 20 pages/min), scraped 1273 items (at 16 items/min)
2018-11-11 06:32:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/en/products>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 06:32:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/events/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 06:32:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/en/about>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:32:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://plus.google.com/share?url=http%3A%2F%2Fhm3energy.com%2F>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:32:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/en/contact/analyst-relations/analysts>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 06:32:58 [scrapy.extensions.logstats] INFO: Crawled 1589 pages (at 6 pages/min), scraped 1281 items (at 8 items/min)
2018-11-11 06:32:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/en>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 06:33:47 [scrapy.extensions.logstats] INFO: Crawled 1599 pages (at 10 pages/min), scraped 1289 items (at 8 items/min)
valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model/mexico.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model/octp-ghana.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-model.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream.page       valid
Crawling page: https://www.eni.com/en_IT/operations/how-we-operate/performance-investments.page       valid
Crawling page: https://www.eni.com/en_IT/operations/how-we-operate/environmental-restoration/poseidon.page       valid
Crawling page: https://www.eni.com/en_IT/operations/how-we-operate/environmental-restoration/ponticelle-project.page       valid
Crawling page: https://www.eni.com/en_IT/operations/how-we-operate/environmental-restoration.page       valid
Crawling page: https://www.eni.com/en_IT/operations/how-we-operate/energy-mix.page       valid
Crawling page: https://www.eni.com/en_IT/operations/how-we-operate/our-activities/responsibility-and-safety-reach-regulation.page       valid
Crawling page: https://www.eni.com/en_IT/operations/how-we-operate/our-activities.page       valid
Crawling page: https://www.eni.com/en_IT/operations/how-we-operate.page       valid
Crawling page: https://www.eni.com/en_IT/operations.page       valid
Crawling page: https://www.eni.com/en_IT/company/news-company.page       valid
Crawling page: https://www.eni.com/en_IT/company/fuel-cafe/eni-and-education.page       valid
Crawling page: https://www.eni.com/en_IT/company/fuel-cafe/brent-price-oil.page       valid
Crawling page: https://www.eni.com/en_IT/company/fuel-cafe/centrality-natural-gas.page       valid
Crawling page: https://www.eni.com/en_IT/company/fuel-cafe/green-finance.page       valid
Crawling page: https://www.eni.com/en_IT/company/fuel-cafe/mediterranean-energy-perspectives.page       valid
Crawling page: https://www.eni.com/en_IT/company/fuel-cafe.page       valid
Crawling page: https://www.eni.com/en_IT/company/eni-history/history-oil-exploration-italy.page       valid
Crawling page: https://www.eni.com/en_IT/company/eni-history/eni-historic-magazines.page       valid
Crawling page: https://www.eni.com/en_IT/company/eni-history/preserving-the-past.page       valid
Crawling page: https://www.eni.com/en_IT/company/eni-history/the-six-legged-dog-history-eni-logo.page       valid
Crawling page: https://www.eni.com/en_IT/company/eni-history/remembering-eni-founder.page       valid
Crawling page: https://www.eni.com/en_IT/company/eni-history/eni-history-of-great-company.page       valid
Crawling page: https://www.eni.com/en_IT/company/eni-history.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/contacts-governance.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/publications.page       valid
Crawling page: http://www.neuralsignals.com/?page_id=110       valid
Crawling page: http://www.neuralsignals.com/?page_id=113       valid
Crawling page: http://linneindustries.com/       valid
Crawling page: https://www.eni.com/en_IT/company/governance/internal-dealing-and-shareholdings.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/shareholders-meeting.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/shareholders.page       valid
Crawling page: http://www.neuralsignals.com/?page_id=27       valid
Crawling page: http://www.neuralsignals.com/?page_id=65       valid
Crawling page: http://www.neuralsignals.com/?page_id=29       valid
Crawling page: http://www.neuralsignals.com/wp-login.php       valid
Crawling page: http://arkival.com/consulting/       valid
Crawling page: http://arkival.com/       valid
Crawling page: http://arkival.com/measurements/       valid
Crawling page: http://arkival.com/technology-research-and-development/       valid
Crawling page: http://www.neuralsignals.com/       valid
Crawling page: http://www.neuralsignals.com/?page_id=36       valid
Crawling page: http://www.neuralsignals.com/?page_id=57       valid
Crawling page: http://arkival.com/contact-us/       valid
Crawling page: http://www.neuralsignals.com/?page_id=75       valid
Crawling page: https://www.coactivehs.com/contact/       valid
Crawling page: https://www.coactivehs.com/team/       valid
Crawling page: http://hm3energy.com/wp-login.php       valid
Crawling page: https://www.coactivehs.com/commercialization/       valid
Crawling page: https://www.coactivehs.com/clinical-development/       valid
Crawling page: https://www.gartner.com/webinar/3123418       Crawling page: https://www.coactivehs.com/       valid
Crawling page: http://hm3energy.com/?shared=email&msg=fail       valid
Crawling page: http://hm3energy.com/contact/       valid
Crawling page: https://www.eni.com/en_IT/company/governance/the-internal-control-and-risk-management-system.page       valid
Crawling page: http://hm3energy.com/blog/       valid
Crawling page: http://hm3energy.com/biomass-news-and-resources/       valid
Crawling page: https://www.eni.com/en_IT/company/governance/compensation-paid-2017.page       valid
Crawling page: http://hm3energy.com/about/investor-relations/       valid
Crawling page: http://hm3energy.com/about/faq/       valid
Crawling page: https://www.eni.com/en_IT/company/governance/remuneration.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/audit-firm.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/board-of-statutory-auditors.page       valid
Crawling page: https://www.gartner.com/en/consulting       valid
Crawling page: https://www.eni.com/en_IT/company/governance/committees-of-the-board-of-directors.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/board-of-directors.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/eni-governance-awards.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/code-of-ethics.page       valid
Crawling page: http://hm3energy.com/about/hm3-energy-news/       valid
Crawling page: https://www.eni.com/en_IT/company/governance/corporate-governance-report.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/eni-model.page       valid
Crawling page: http://hm3energy.com/about/hm3-energy-achievements/       valid
Crawling page: https://www.eni.com/en_IT/company/governance/by-laws.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance/corporate-governance-code.page       valid
Crawling page: https://www.eni.com/en_IT/company/governance.page       valid
Crawling page: https://www.eni.com/en_IT/company/our-management.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/enis-subsidiaries-and-affiliates.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/market-share.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/year-results.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/profile-of-the-year.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/employees/employees-by-country.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/people.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/business-model/digitalization.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/business-model.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/how-we-work.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/Eni-values.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/our-new-mission.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile/brand-identity.page       valid
Crawling page: https://www.eni.com/en_IT/company/company-profile.page       valid
Crawling page: https://www.eni.com/en_IT/company.page       valid
Crawling page: https://www.eni.com/en_IT/newsletter/registration.page       valid
Crawling page: https://www.eni.com/en_IT/documentations.page2018-11-11 06:34:48 [scrapy.extensions.logstats] INFO: Crawled 1610 pages (at 11 pages/min), scraped 1297 items (at 8 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 06:36:07 [scrapy.extensions.logstats] INFO: Crawled 1614 pages (at 4 pages/min), scraped 1310 items (at 13 items/min)
2018-11-11 06:36:54 [scrapy.extensions.logstats] INFO: Crawled 1627 pages (at 13 pages/min), scraped 1321 items (at 11 items/min)
/bin/sh: 1: kill: No such process

/bin/sh: 1: kill: No such process

2018-11-11 06:38:54 [scrapy.extensions.logstats] INFO: Crawled 1650 pages (at 23 pages/min), scraped 1338 items (at 17 items/min)
2018-11-11 06:39:50 [scrapy.extensions.logstats] INFO: Crawled 1651 pages (at 1 pages/min), scraped 1344 items (at 6 items/min)
2018-11-11 06:40:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://portal.astech.com/Account/Login> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
/bin/sh: 1: kill: No such process

2018-11-11 06:40:43 [scrapy.extensions.logstats] INFO: Crawled 1660 pages (at 9 pages/min), scraped 1352 items (at 8 items/min)
2018-11-11 06:41:54 [scrapy.extensions.logstats] INFO: Crawled 1685 pages (at 25 pages/min), scraped 1367 items (at 15 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 06:43:00 [scrapy.extensions.logstats] INFO: Crawled 1695 pages (at 10 pages/min), scraped 1381 items (at 14 items/min)
2018-11-11 06:43:51 [scrapy.extensions.logstats] INFO: Crawled 1701 pages (at 6 pages/min), scraped 1393 items (at 12 items/min)
       valid
Crawling page: https://www.eni.com/en_IT/contacts/contacts.page       valid
Crawling page: https://www.eni.com/en_IT/products.page       valid
Crawling page: https://www.eni.com/en_IT/social-media-newsroom.page       valid
Crawling page: https://www.eni.com/en_IT/company/international-presence.page       valid
Crawling page: https://www.tumblr.com/widgets/share/tool/preview?shareSource=legacy&canonicalUrl=&url=http%3A%2F%2Fhm3energy.com%2F&title=Torrefaction+Technology       valid
Crawling page: https://www.eni.com/it_IT/innovazione.page       valid
Crawling page: https://www.eni.com/enipedia/en_IT/home.page       valid
Crawling page: http://www.ablexis.com/licensing/       valid
Crawling page: http://www.ablexis.com/news/       valid
Crawling page: https://www.eni.com/en_IT/home.page       valid
Crawling page: https://www.eni.com/en_IT/innovation.page       valid
Crawling page: http://www.ablexis.com/technology/       valid
Crawling page: http://www.ablexis.com/about/       valid
Crawling page: http://www.ablexis.com       valid
Crawling page: http://microcontinuum.com/contact.htm       valid
Crawling page: http://microcontinuum.com/news.htm       valid
Crawling page: http://hm3energy.com/about/       valid
Crawling page: http://hm3energy.com/about/leadership/       valid
Crawling page: http://microcontinuum.com/business.htm       valid
Crawling page: http://hm3energy.com/replacing-coal/raw-vs-torrefied-biomass/       valid
Crawling page: http://microcontinuum.com/technology.htm       valid
Crawling page: http://microcontinuum.com/about.htm       valid
Crawling page: http://microcontinuum.com/index.htm       valid
Crawling page: http://hm3energy.com/replacing-coal/comparing-green-energy-costs/       valid
Crawling page: http://hm3energy.com/torrefaction-feedstock/energy-crops-feedstock/       valid
Crawling page: https://www.eni.com/en_IT/cookies.page       valid
Crawling page: http://hm3energy.com/replacing-coal/       valid
Crawling page: http://hm3energy.com/benefits/       valid
Crawling page: http://hm3energy.com/torrefaction-feedstock/agricultural-residue-feedstock/       valid
Crawling page: http://hm3energy.com/torrefaction-feedstock/urban-wood-waste-feedstock/       valid
Crawling page: https://m.facebook.com/login.php?skip_api_login=1&api_key=966242223397117&signed_next=1&next=https%3A%2F%2Fm.facebook.com%2Fsharer.php%3Fu%3Dhttp%253A%252F%252Fhm3energy.com%252F%26t%3DTorrefaction%2BTechnology&cancel_url=https%3A%2F%2Fm.facebook.com%2Fdialog%2Fclose_window%2F%3Fapp_id%3D966242223397117%26connect%3D0%23_%3D_&display=touch&locale=en_US&_rdr       valid
Crawling page: http://hm3energy.com/torrefaction-feedstock/       valid
Crawling page: http://hm3energy.com/torrefaction-feedstock/woody-biomass-feedstock/       valid
Crawling page: https://astech.com/       valid
Crawling page: http://hm3energy.com/torrefied-biomass-properties/       valid
Crawling page: https://astech.com/careers       valid
Crawling page: http://hm3energy.com/torrefied-biomass-energy-efficiency/       valid
Crawling page: http://hm3energy.com/       valid
Crawling page: http://hm3energy.com/torrefied-biomass-2/       valid
Crawling page: https://astech.com/contact       valid
Crawling page: https://astech.com/about       valid
Crawling page: https://astech.com/oem-info       valid
Crawling page: https://astech.com/news       valid
Crawling page: https://astech.com/what-is-astech       valid
Crawling page: https://astech.com/get-an-astech       valid
Crawling page: http://www.growenergy.org/hydral/       valid
Crawling page: http://www.growenergy.org/verde/       valid
Crawling page: https://astech.com/resources       valid
Crawling page: http://www.growenergy.org/       valid
Crawling page: https://portal.astech.com/Account/Login       Crawling page: http://www.htstechnologies.com/power-machines/       valid
Crawling page: http://www.htstechnologies.com/portable-machines/       valid
Crawling page: http://www.growenergy.org/company/       valid
Crawling page: http://www.htstechnologies.com/equipment-tooling/       valid
Crawling page: http://www.htstechnologies.com/about/       valid
Crawling page: http://www.htstechnologies.com/       valid
Crawling page: http://www.htstechnologies.com/hts-tooling/       valid
Crawling page: https://wellconnectgeo.com/site-preview/       valid
Crawling page: https://wellconnectgeo.com/featured-in-michigan-country-lines-june-2017/       valid
Crawling page: https://wellconnectgeo.com/blog/       valid
Crawling page: https://wellconnectgeo.com/?s=       valid
Crawling page: https://corporate.ford.com/legal/copyright.html       valid
Crawling page: https://wellconnectgeo.com/frequently-asked-questions/       valid
Crawling page: http://genescopartners.com/site_updates.php       valid
Crawling page: http://genescopartners.com/anonymous_reporting.php       valid
Crawling page: http://genescopartners.com/store_address_lists.php       valid
Crawling page: http://genescopartners.com/new_vendor_setup.php       valid
Crawling page: https://corporate.ford.com/legal/privacy-policy.html       valid
Crawling page: https://wellconnectgeo.com/specifications/       valid
Crawling page: https://corporate.ford.com/legal/your-california-privacy-rights.html       valid
Crawling page: https://wellconnectgeo.com/video-description/       valid
Crawling page: https://wellconnectgeo.com/installation-options/       valid
Crawling page: https://wellconnectgeo.com/calculator/       valid
Crawling page: http://genescopartners.com/gco.php       valid
Crawling page: http://genescopartners.com/bass/index.php       valid
Crawling page: https://wellconnectgeo.com/well-connect-in-your-neighborhood/       valid
Crawling page: https://wellconnectgeo.com/benefits/       valid
Crawling page: http://genescopartners.com/dk/index.php       valid
Crawling page: http://genescopartners.com/lucky/index.php       valid
Crawling page: https://wellconnectgeo.com/       valid
Crawling page: https://wellconnectgeo.com/cart/       valid
Crawling page: https://corporate.ford.com/global-links.html       valid
Crawling page: https://corporate.ford.com/contact-us.html       valid
Crawling page: https://corporate.ford.com/microsites/sustainability-report-2017-18/index.html       valid
Crawling page: http://frontedgetechnology.com/index.htm       valid
Crawling page: https://corporate.ford.com/innovation/it-came-from-outer-space.html       valid
Crawling page: https://corporate.ford.com/innovation/sonic-signals.html       valid
Crawling page: https://corporate.ford.com/innovation/research-and-innovation-center.html       valid
Crawling page: http://frontedgetechnology.com/tech.htm       valid
Crawling page: http://frontedgetechnology.com/gen.htm       valid
Crawling page: http://frontedgetechnology.com/about.htm       valid
Crawling page: https://corporate.ford.com/innovation/100-years-moving-assembly-line.html       valid
Crawling page: https://corporate.ford.com/innovation/project-sumurr-medicine-in-motion.html       valid
Crawling page: https://corporate.ford.com/innovation/battery-research-powers-up.html       valid
Crawling page: https://corporate.ford.com/innovation/new-generation-electric-vehicles.html       valid
Crawling page: https://corporate.ford.com/content/ford-corporate/en/innovation/innovation-ideas-submission.html       valid
Crawling page: https://corporate.ford.com/history.html       valid
Crawling page: https://corporate.ford.com/company/community/dearborn-campus-transformation-.html       valid
Crawling page: https://corporate.ford.com/company/community.html       valid
Crawling page: https://corporate.ford.com/careers/transitioning-military.html       valid
Crawling page: https://corporate.ford.com/careers/students-and-recent-grads.html       valid
Crawling page: https://corporate.ford.com/careers/experienced-professionals.html       valid
Crawling page: https://corporate.ford.com/careers/faqs.html       valid
Crawling page: https://corporate.ford.com/careers/recruiting-events.html       valid
Crawling page: https://corporate.ford.com/careers/departments.html       valid
Crawling page: https://corporate.ford.com/careers/profiles.html       valid
Crawling page:/bin/sh: 1: kill: No such process

2018-11-11 06:44:44 [scrapy.extensions.logstats] INFO: Crawled 1717 pages (at 16 pages/min), scraped 1407 items (at 14 items/min)
2018-11-11 06:45:47 [scrapy.extensions.logstats] INFO: Crawled 1722 pages (at 5 pages/min), scraped 1415 items (at 8 items/min)
2018-11-11 06:46:55 [scrapy.extensions.logstats] INFO: Crawled 1730 pages (at 8 pages/min), scraped 1422 items (at 7 items/min)
2018-11-11 06:47:41 [scrapy.extensions.logstats] INFO: Crawled 1736 pages (at 6 pages/min), scraped 1427 items (at 5 items/min)
2018-11-11 06:48:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/power-management-ic/lithium-ion-battery-protection-ic/s-8255b/%0D/>: HTTP status code is not handled or not allowed
2018-11-11 06:48:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/power-management-ic/lithium-ion-battery-protection-ic/s-8255a/%0D/>: HTTP status code is not handled or not allowed
2018-11-11 06:48:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/power-management-ic/lithium-ion-battery-protection-ic/s-8245bd/%0D/>: HTTP status code is not handled or not allowed
2018-11-11 06:48:44 [scrapy.extensions.logstats] INFO: Crawled 1744 pages (at 8 pages/min), scraped 1434 items (at 7 items/min)
2018-11-11 06:48:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/automotive/automotive-voltage-regulator-ldo/s-19252/%0D/>: HTTP status code is not handled or not allowed
2018-11-11 06:49:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/datasheets/power-management-ic/voltage-regulator-ldo/s-1313xxxh/%0D/>: HTTP status code is not handled or not allowed
2018-11-11 06:49:54 [scrapy.extensions.logstats] INFO: Crawled 1757 pages (at 13 pages/min), scraped 1441 items (at 7 items/min)
2018-11-11 06:50:58 [scrapy.extensions.logstats] INFO: Crawled 1764 pages (at 7 pages/min), scraped 1447 items (at 6 items/min)
2018-11-11 06:52:00 [scrapy.extensions.logstats] INFO: Crawled 1769 pages (at 5 pages/min), scraped 1454 items (at 7 items/min)
2018-11-11 06:52:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://hub.ablic.com/en/ceatec2018%0D>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 06:52:54 [scrapy.extensions.logstats] INFO: Crawled 1774 pages (at 5 pages/min), scraped 1460 items (at 6 items/min)
2018-11-11 06:54:18 [scrapy.extensions.logstats] INFO: Crawled 1782 pages (at 8 pages/min), scraped 1468 items (at 8 items/min)
2018-11-11 06:54:56 [scrapy.extensions.logstats] INFO: Crawled 1788 pages (at 6 pages/min), scraped 1472 items (at 4 items/min)
2018-11-11 06:56:22 [scrapy.extensions.logstats] INFO: Crawled 1794 pages (at 6 pages/min), scraped 1480 items (at 8 items/min)
2018-11-11 06:57:08 [scrapy.extensions.logstats] INFO: Crawled 1798 pages (at 4 pages/min), scraped 1484 items (at 4 items/min)
2018-11-11 06:57:49 [scrapy.extensions.logstats] INFO: Crawled 1803 pages (at 5 pages/min), scraped 1488 items (at 4 items/min)
2018-11-11 06:59:01 [scrapy.extensions.logstats] INFO: Crawled 1809 pages (at 6 pages/min), scraped 1495 items (at 7 items/min)
 https://corporate.ford.com/innovation.html       valid
Crawling page: https://corporate.ford.com/company/diversity.html       valid
Crawling page: https://corporate.ford.com/company/operation-list.html       valid
Crawling page: https://corporate.ford.com/company/articles.html       valid
Crawling page: https://corporate.ford.com/company/governance.html       valid
Crawling page: https://corporate.ford.com/company.html       valid
Crawling page: https://corporate.ford.com/homepage.html       valid
Crawling page: https://www.ablic.com/en/semicon/siteinfo/privacy/       valid
Crawling page: https://www.ablic.com/en/semicon/siteinfo/privacy/website/       valid
Crawling page: https://www.ablic.com/en/semicon/siteinfo/terms/       valid
Crawling page: https://www.ablic.com/en/semicon/column/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2017/02/13/electronica_china_2017/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2017/10/30/elexcon2017/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2018/02/14/electronicachina/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2018/06/07/site-url-change/       valid
Crawling page: https://www.ablic.com/en/semicon/news/new-products/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2018/08/10/s-5420/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2018/09/13/s-19630ab/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2018/07/09/s-85s0p/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2018/08/20/s-85m0a/       valid
Crawling page: https://www.ablic.com/en/semicon/techanalye/part1/?rf=topics%0D       valid
Crawling page: https://www.ablic.com/en/semicon/news/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2018/10/17/electronica2018/       valid
Crawling page: https://www.ablic.com/en/semicon/news/event/       valid
Crawling page: https://www.ablic.com/en/semicon/news/2018/10/24/zcl/       valid
Crawling page: https://www.ablic.com/en/semicon/news/topics/       valid
Crawling page: https://www.ablic.com/en/semicon/news/release/       valid
Crawling page: https://www.ablic.com/en/semicon/techanalye/part2/?rf=topics%0D       valid
Crawling page: https://www.ablic.com/en/semicon/news/2018/11/05/mail/       valid
Crawling page: https://www.ablic.com/en/semicon/applications/cordless-power-tool/?rf=topics%0D       valid
Crawling page: https://www.ablic.com/en/semicon/corp/vision/?rf=subbnr       valid
Crawling page: https://www.ablic.com/en/semicon/feed/       valid
Crawling page: https://www.ablic.com/en/semicon/sales/webshop/       valid
Crawling page: https://www.ablic.com/en/semicon/applications/cordless-power-tool/?rf=subbnr       valid
Crawling page: https://www.ablic.com/cn/semicon/       valid
Crawling page: https://www.ablic.com/jp/semicon/       valid
Crawling page: https://www.ablic.com/en/semicon/techanalye/part1/?rf=subbnr       valid
Crawling page: https://www.ablic.com/en/semicon/ablic/?rf=important       valid
Crawling page: https://www.ablic.com/en/semicon/corp/base/       valid
Crawling page: https://www.ablic.com/en/semicon/corp/quality-environment/       valid
Crawling page: https://www.ablic.com/en/semicon/corp/csr/       valid
Crawling page: https://www.ablic.com/en/semicon/corp/production/       valid
Crawling page: https://www.ablic.com/en/semicon/corp/field/       valid
Crawling page: https://www.ablic.com/en/semicon/corp/history/       valid
Crawling page: https://www.ablic.com/en/semicon/corp/vision/       valid
Crawling page: https://www.ablic.com/en/semicon/corp/outline/       valid
Crawling page: http://www.allianceforsustainableenergy.org/leadership.html       valid
Crawling page: http://www.allianceforsustainableenergy.org/about.html       valid
Crawling page: https://www.ablic.com/en/semicon/corp/       valid
Crawling page: https://www.ablic.com/en/semicon/support/package/package-list/       valid
Crawling page: https://www.ablic.com/en/semicon/support/tools/       valid
Crawling page: https://www.ablic.com/en/semicon/corp/message/       valid
Crawling page: https://www.ablic.com/en/semicon/sales/       valid
Crawling page: https://www.ablic.com/en/semicon/support/       valid
Crawling page: https://www.ablic.com/en/semicon/support/old-product/       valid
Crawling page: https://www.ablic.com/en/semicon/healthcare/analog-switch/       valid
Crawling page: https://www.ablic.com/en/semicon/healthcare/linear-pulser/       valid
Crawling page: https://www.ablic.com/en/semicon/datasheets/       valid
Crawling page: https://www.ablic.com/en/semicon/healthcare/digital-pulser/       valid
Crawling page: https://www.ablic.com/en/semicon/healthcare/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-convenience-timer/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-opamp/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-realtime-clock/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-magnetism-sensor-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-serial-eeprom/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-lithium-ion-battery-protection-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-composite-power-management-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-diagnosis-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-watchdog-timer/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-voltage-detector-reset-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/automotive-voltage-regulator-ldo/       valid
Crawling page: https://www.ablic.com/en/semicon/products/automotive/       valid
Crawling page: https://www.ablic.com/en/semicon/products/analog/comparator/       valid
Crawling page: https://www.ablic.com/en/semicon/products/analog/opamp/       valid
Crawling page: https://www.ablic.com/en/semicon/products/analog/       valid
Crawling page: https://www.ablic.com/en/semicon/products/rtc/wireless-power-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/rtc/programmable-port-controller/       valid
Crawling page: https://www.ablic.com/en/semicon/products/rtc/realtime-clock/       valid
Crawling page: https://www.ablic.com/en/semicon/products/rtc/       valid
Crawling page: https://www.ablic.com/en/semicon/datasheets/sensor/uv-sensor/s-5420/       valid
Crawling page: https://www.ablic.com/en/semicon/products/sensor/photo-detect-ics/       valid
Crawling page: https://www.ablic.com/en/semicon/products/sensor/magnetism-sensor-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/sensor/temperature-sensor-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/sensor/       valid
Crawling page: https://www.ablic.com/en/semicon/products/memory/general-serial-eeprom/       valid
Crawling page: https://www.ablic.com/en/semicon/products/memory/       valid
Crawling page: https://www.ablic.com/en/semicon/products/power-management-ic/composite-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/power-management-ic/charge-pump-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/power-management-ic/power-sequencer-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/power-management-ic/lithium-ion-battery-protection-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/power-management-ic/switching-regulator/       valid
Crawling page: https://www.ablic.com/en/semicon/products/power-management-ic/watchdog-timer/       valid
Crawling page: https://www.ablic.com/en/semicon/products/power-management-ic/voltage-detector-reset-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/power-management-ic/       valid
Crawling page: https://www.ablic.com/en/semicon/products/power-management-ic/voltage-regulator-ldo//bin/sh: 1: kill: No such process

2018-11-11 06:59:42 [scrapy.extensions.logstats] INFO: Crawled 1810 pages (at 1 pages/min), scraped 1499 items (at 4 items/min)
2018-11-11 07:00:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ablic.com/en/semicon/corp/quality-environment/%0D/>: HTTP status code is not handled or not allowed
2018-11-11 07:00:51 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://wellconnectgeo.com/news-events/>: HTTP status code is not handled or not allowed
2018-11-11 07:00:51 [scrapy.extensions.logstats] INFO: Crawled 1832 pages (at 22 pages/min), scraped 1514 items (at 15 items/min)
/bin/sh: 1: kill: No such process

/bin/sh: 1: kill: No such process

2018-11-11 07:01:42 [scrapy.extensions.logstats] INFO: Crawled 1835 pages (at 3 pages/min), scraped 1521 items (at 7 items/min)
2018-11-11 07:03:16 [scrapy.extensions.logstats] INFO: Crawled 1850 pages (at 15 pages/min), scraped 1533 items (at 12 items/min)
2018-11-11 07:04:02 [scrapy.extensions.logstats] INFO: Crawled 1858 pages (at 8 pages/min), scraped 1541 items (at 8 items/min)
2018-11-11 07:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/technology/contact/contact_gartner.jsp>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 07:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/privacy/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 07:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/technology/webinars/?prm=ftr>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 07:04:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/technology/site-index.jsp>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 07:04:56 [scrapy.core.scraper] ERROR: Error downloading <GET http://nanoquantum.com/Contact.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-11-11 07:04:56 [scrapy.core.scraper] ERROR: Error downloading <GET http://nanoquantum.com/Employment.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-11-11 07:04:56 [scrapy.extensions.logstats] INFO: Crawled 1866 pages (at 8 pages/min), scraped 1549 items (at 8 items/min)
2018-11-11 07:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/user/registration/client>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 07:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/it-glossary/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 07:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/login/loginInitAction.do?method=initialize>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 07:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.gartner.com/doc/3772092?srcId=1-3931087981>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 07:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://nanoquantum.com/Terms.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-11-11 07:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coactivehs.com/performance-optimization/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 07:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coactivehs.com/market-monitoring/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 07:05:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coactivehs.com/specialty-consulting/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 07:05:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://wellconnectgeo.com/about-us/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 07:05:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://wellconnectgeo.com/testimonial-charles-schultz/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 07:05:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://wellconnectgeo.com/contact-us-2/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 07:05:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://genescopartners.com/jm/index.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 07:05:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://xtalsolar.com/technology.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 07:05:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://xtalsolar.com/contact.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 07:05:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://xtalsolar.com/news.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 07:05:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://xtalsolar.com/careers.html>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 07:05:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://wellconnectgeo.com/contact-us-2/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 07:05:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wellconnectgeo.com/testimonial-charles-schultz/> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 07:06:01 [scrapy.extensions.logstats] INFO: Crawled 1881 pages (at 15 pages/min), scraped 1560 items (at 11 items/min)
2018-11-11 07:07:30 [scrapy.extensions.logstats] INFO: Crawled 1912 pages (at 31 pages/min), scraped 1570 items (at 10 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 07:08:37 [scrapy.extensions.logstats] INFO: Crawled 1912 pages (at 0 pages/min), scraped 1576 items (at 6 items/min)
2018-11-11 07:09:34 [scrapy.extensions.logstats] INFO: Crawled 1917 pages (at 5 pages/min), scraped 1580 items (at 4 items/min)
2018-11-11 07:09:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wet-flash.com/about.html> (referer: http://wet-flash.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: Reached error page: about:neterror?e=dnsNotFound&u=http%3A//wet-flash.com/about.html&c=UTF-8&f=regular&d=We%20can%E2%80%99t%20connect%20to%20the%20server%20at%20wet-flash.com.

2018-11-11 07:09:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wet-flash.com/index.html> (referer: http://wet-flash.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: Reached error page: about:neterror?e=dnsNotFound&u=http%3A//wet-flash.com/index.html&c=UTF-8&f=regular&d=We%20can%E2%80%99t%20connect%20to%20the%20server%20at%20wet-flash.com.

2018-11-11 07:09:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wet-flash.com/contact.html> (referer: http://wet-flash.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: Reached error page: about:neterror?e=dnsNotFound&u=http%3A//wet-flash.com/contact.html&c=UTF-8&f=regular&d=We%20can%E2%80%99t%20connect%20to%20the%20server%20at%20wet-flash.com.

2018-11-11 07:09:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wet-flash.com/video.html> (referer: http://wet-flash.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: Reached error page: about:neterror?e=dnsNotFound&u=http%3A//wet-flash.com/video.html&c=UTF-8&f=regular&d=We%20can%E2%80%99t%20connect%20to%20the%20server%20at%20wet-flash.com.

2018-11-11 07:09:45 [scrapy.extensions.logstats] INFO: Crawled 1920 pages (at 3 pages/min), scraped 1581 items (at 1 items/min)
2018-11-11 07:10:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://tpsolar.nl/gerard.simmerman@tpsolar.nl>: HTTP status code is not handled or not allowed
2018-11-11 07:11:17 [scrapy.extensions.logstats] INFO: Crawled 1934 pages (at 14 pages/min), scraped 1593 items (at 12 items/min)
       valid
Crawling page: https://www.ablic.com/en/semicon/products/       valid
Crawling page: https://www.ablic.com/en/semicon/       valid
Crawling page: https://www.ablic.com/en/semicon/siteinfo/       valid
Crawling page: http://www.htstechnologies.com/ordering-info/       valid
Crawling page: http://www.htstechnologies.com/aftermarket-tooling/       valid
Crawling page: http://www.htstechnologies.com/manufacturing-partners/       valid
Crawling page: http://www.htstechnologies.com/engineering-services       valid
Crawling page: http://www.htstechnologies.com/engineering-services/       valid
Crawling page: http://microcontinuum.com/flexible.htm       valid
Crawling page: https://wellconnectgeo.com/page/2/       valid
Crawling page: http://microcontinuum.com/solar.htm       valid
Crawling page: http://microcontinuum.com/nanoTHZ.htm       valid
Crawling page: http://www.htstechnologies.com/contact-us/       valid
Crawling page: http://microcontinuum.com/storage.htm       valid
Crawling page: https://wellconnectgeo.com/tim-and-dennis-schultz-interviewed-by-kirk-heinze-2/       valid
Crawling page: https://wellconnectgeo.com/governor-recognizes-dennis-schultz-for-reducing-energy-waste/       valid
Crawling page: http://microcontinuum.com/chemistry.htm       valid
Crawling page: http://microcontinuum.com/       valid
Crawling page: http://microcontinuum.com/awards.htm       valid
Crawling page: http://www.growenergy.org/biomass/       valid
Crawling page: http://www.growenergy.org/research/       valid
Crawling page: https://www.newtechvc.com/privacy-policy.html       valid
Crawling page: https://www.newtechvc.com/       valid
Crawling page: https://www.newtechvc.com/the-ntv-team.html       valid
Crawling page: https://www.newtechvc.com/contact.html       valid
Crawling page: https://www.eni.com/en_IT/investors/strategy/2014-2017-results.page       valid
Crawling page: https://www.eni.com/en_IT/investors/global-energy-scenarios/world-oil-gas-review-eng.page       valid
Crawling page: https://www.eni.com/en_IT/investors/market-rating/analyst-coverage.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-on-the-stock-markets/eni-shares.page       valid
Crawling page: https://www.eni.com/en_IT/investors/investor-tool/share-total-return.page       valid
Crawling page: https://www.eni.com/en_IT/investors/eni-in-numbers/adjusted-net-profit-by-segment.page       valid
Crawling page: https://www.newtechvc.com/about.html       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/safety-and-the-environment.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/technological-platforms/energy-transition/eni-mit-fusion.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/our-skills/the-san-donato-milanese-oil-gas-laboratory.page       valid
Crawling page: https://www.eni.com/en_IT/innovation/eni-award/eni-award-recognising-excellence-in-energy.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/our-responsible-model/responsible-company.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/stakeholder-relations/eni-s-institutional-relations.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/safety/management/work.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/local-development/operational-and-management-tools.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/climate-change-and-new-forms-of-energy/partnerships-for-sustainable-energy.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/environment/waste-management.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/integrity-human-rights/due-diligence/assessing-monitoring.page       valid
Crawling page: https://www.eni.com/en_IT/sustainability/reporting/our-sustainability-report.page       valid
Crawling page: https://www.eni.com/en_IT/media.page       valid
Crawling page: https://www.eni.com/en_IT/media/contacts-media.page       valid
Crawling page: https://www.eni.com/en_IT/careers/working-at-eni/daniela-story.page       valid
Crawling page: https://www.eni.com/en_IT/careers/events-calendar.page       valid
Crawling page: https://www.eni.com/en_IT/reserved-area.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/gas-power/retail-gas-luce.page       valid
Crawling page: https://www.eni.com/en_IT/operations/mid-downstream/refining-marketing.page       valid
Crawling page: https://www.eni.com/en_IT/operations/new-energy-solutions/decarbonization/low-carbon-vision.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/upstream-italy.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/exploration-development.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/dual-exploration-model.page       valid
Crawling page: https://www.eni.com/en_IT/operations/upstream/production.page       valid
Crawling page: http://genescopartners.com/trask/trask_vendor_guide.php       valid
Crawling page: https://wellconnectgeo.com/testimonial-charles-schultz/       Crawling page: http://xtalsolar.com/company.html       valid
Crawling page: https://corporate.ford.com/company/community/corktown-campus.html       valid
Crawling page: https://corporate.ford.com/careers.html       valid
Crawling page: https://corporate.ford.com/innovation/f-150-body-of-work.html       valid
Crawling page: https://corporate.ford.com/innovation/human-machine-interaction.html       valid
Crawling page: http://oasdesigngroup.com/contact-2/index.html       valid
Crawling page: https://www.symbols.com/login.php       valid
Crawling page: https://www.symbols.com/privacy.php       valid
Crawling page: https://www.symbols.com/contact.php       valid
Crawling page: https://www.symbols.com/terms.php       valid
Crawling page: https://www.symbols.com/faq.php       valid
Crawling page: http://npimobile.com/about-us/       valid
Crawling page: http://npimobile.com/contact-us/       valid
Crawling page: http://npimobile.com/news/       valid
Crawling page: http://npimobile.com/the-future/       valid
Crawling page: https://www.symbols.com/invite.php       valid
Crawling page: https://www.symbols.com/collection.php       valid
Crawling page: http://npimobile.com/       valid
Crawling page: https://www.symbols.com/activity.php       valid
Crawling page: https://www.symbols.com/editors.php       valid
Crawling page: http://thornbioscience.com/contact-us/       valid
Crawling page: https://www.symbols.com/signup.php       valid
Crawling page: https://www.symbols.com/editcategory.php       valid
Crawling page: https://www.symbols.com/editgroup.php       valid
Crawling page: https://www.symbols.com/editsymbol.php       valid
Crawling page: http://wet-flash.com/about.html       Crawling page: http://wet-flash.com/index.html       Crawling page: http://wet-flash.com/contact.html       Crawling page: http://wet-flash.com/video.html       Crawling page: http://smebeam.com/contact.html       valid
Crawling page: http://smebeam.com/faq.html       valid
Crawling page: http://smebeam.com/services.html       valid
Crawling page: http://smebeam.com/about.html       valid
Crawling page: https://www.total.com/en/media/news       valid
Crawling page: https://www.total.com/en/media/news?type=article&thematic=All       valid
Crawling page: https://www.total.com/en/media/media       valid
Crawling page: https://www.total.com/en/investors/questions-contacts       valid
Crawling page: https://www.total.com/en/republic-congo       valid
Crawling page: https://www.total.com/en/nigeria       valid
Crawling page: https://tpsolar.nl/privacy-statement/?lang=en       valid
Crawling page: https://tpsolar.nl/our-references/?lang=en       valid
Crawling page: https://tpsolar.nl/568-2/?lang=en       valid
Crawling page: https://www.total.com/en/russia       valid
Crawling page: https://www.total.com/en/lebanon-       valid
Crawling page: https://www.total.com/en/kuwait-       2018-11-11 07:12:04 [scrapy.extensions.logstats] INFO: Crawled 1938 pages (at 4 pages/min), scraped 1597 items (at 4 items/min)
2018-11-11 07:12:59 [scrapy.extensions.logstats] INFO: Crawled 1942 pages (at 4 pages/min), scraped 1601 items (at 4 items/min)
2018-11-11 07:13:42 [scrapy.extensions.logstats] INFO: Crawled 1946 pages (at 4 pages/min), scraped 1605 items (at 4 items/min)
2018-11-11 07:15:42 [scrapy.extensions.logstats] INFO: Crawled 1954 pages (at 8 pages/min), scraped 1613 items (at 8 items/min)
2018-11-11 07:17:19 [scrapy.extensions.logstats] INFO: Crawled 1962 pages (at 8 pages/min), scraped 1621 items (at 8 items/min)
2018-11-11 07:18:07 [scrapy.extensions.logstats] INFO: Crawled 1966 pages (at 4 pages/min), scraped 1625 items (at 4 items/min)
2018-11-11 07:18:54 [scrapy.extensions.logstats] INFO: Crawled 1970 pages (at 4 pages/min), scraped 1629 items (at 4 items/min)
2018-11-11 07:20:23 [scrapy.extensions.logstats] INFO: Crawled 1978 pages (at 8 pages/min), scraped 1637 items (at 8 items/min)
2018-11-11 07:21:18 [scrapy.extensions.logstats] INFO: Crawled 1982 pages (at 4 pages/min), scraped 1641 items (at 4 items/min)
2018-11-11 07:21:52 [scrapy.extensions.logstats] INFO: Crawled 1986 pages (at 4 pages/min), scraped 1645 items (at 4 items/min)
2018-11-11 07:22:41 [scrapy.extensions.logstats] INFO: Crawled 1990 pages (at 4 pages/min), scraped 1649 items (at 4 items/min)
2018-11-11 07:23:53 [scrapy.extensions.logstats] INFO: Crawled 1998 pages (at 8 pages/min), scraped 1657 items (at 8 items/min)
2018-11-11 07:25:23 [scrapy.extensions.logstats] INFO: Crawled 2006 pages (at 8 pages/min), scraped 1665 items (at 8 items/min)
2018-11-11 07:26:12 [scrapy.extensions.logstats] INFO: Crawled 2010 pages (at 4 pages/min), scraped 1669 items (at 4 items/min)
2018-11-11 07:27:02 [scrapy.extensions.logstats] INFO: Crawled 2014 pages (at 4 pages/min), scraped 1673 items (at 4 items/min)
2018-11-11 07:27:46 [scrapy.extensions.logstats] INFO: Crawled 2018 pages (at 4 pages/min), scraped 1677 items (at 4 items/min)
2018-11-11 07:29:12 [scrapy.extensions.logstats] INFO: Crawled 2026 pages (at 8 pages/min), scraped 1685 items (at 8 items/min)
2018-11-11 07:30:08 [scrapy.extensions.logstats] INFO: Crawled 2030 pages (at 4 pages/min), scraped 1689 items (at 4 items/min)
2018-11-11 07:30:51 [scrapy.extensions.logstats] INFO: Crawled 2034 pages (at 4 pages/min), scraped 1693 items (at 4 items/min)
2018-11-11 07:32:24 [scrapy.extensions.logstats] INFO: Crawled 2042 pages (at 8 pages/min), scraped 1701 items (at 8 items/min)
2018-11-11 07:33:11 [scrapy.extensions.logstats] INFO: Crawled 2046 pages (at 4 pages/min), scraped 1705 items (at 4 items/min)
2018-11-11 07:34:03 [scrapy.extensions.logstats] INFO: Crawled 2050 pages (at 4 pages/min), scraped 1709 items (at 4 items/min)
2018-11-11 07:34:53 [scrapy.extensions.logstats] INFO: Crawled 2054 pages (at 4 pages/min), scraped 1713 items (at 4 items/min)
2018-11-11 07:36:26 [scrapy.extensions.logstats] INFO: Crawled 2062 pages (at 8 pages/min), scraped 1721 items (at 8 items/min)
2018-11-11 07:37:18 [scrapy.extensions.logstats] INFO: Crawled 2065 pages (at 3 pages/min), scraped 1725 items (at 4 items/min)
valid
Crawling page: https://www.total.com/en/jordan-       valid
Crawling page: https://www.total.com/en/uruguay       valid
Crawling page: https://www.total.com/en/united-states-       valid
Crawling page: https://www.total.com/en/iraq-       valid
Crawling page: https://www.total.com/en/venezuela       valid
Crawling page: https://www.total.com/en/panama       valid
Crawling page: https://www.total.com/en/mexico       valid
Crawling page: https://www.total.com/en/puerto-rico       valid
Crawling page: https://www.total.com/en/peru       valid
Crawling page: https://www.total.com/en/martinique       valid
Crawling page: https://www.total.com/en/french-guiana       valid
Crawling page: https://www.total.com/en/jamaica       valid
Crawling page: https://www.total.com/en/guadeloupe       valid
Crawling page: https://www.total.com/en/cuba       valid
Crawling page: https://www.total.com/en/costa-rica       valid
Crawling page: https://www.total.com/en/dominican-republic       valid
Crawling page: https://www.total.com/en/ecuador       valid
Crawling page: https://www.total.com/en/colombia       valid
Crawling page: https://www.total.com/en/canada       valid
Crawling page: https://www.total.com/en/brazil       valid
Crawling page: https://www.total.com/en/chile       valid
Crawling page: https://www.total.com/en/united-arab-emirates-       valid
Crawling page: https://www.total.com/en/aruba       valid
Crawling page: https://www.total.com/en/argentina       valid
Crawling page: https://www.total.com/en/bolivia       valid
Crawling page: https://www.total.com/en/turkey       valid
Crawling page: https://www.total.com/en/qatar-0-       valid
Crawling page: https://www.total.com/en/saudi-arabia-0-       valid
Crawling page: https://www.total.com/en/pakistan       valid
Crawling page: https://www.total.com/en/switzerland       valid
Crawling page: https://www.total.com/en/ukraine       valid
Crawling page: https://www.total.com/en/united-kingdom       valid
Crawling page: https://www.total.com/en/oman-       valid
Crawling page: https://www.total.com/en/slovenia       valid
Crawling page: https://www.total.com/en/sweden       valid
Crawling page: https://www.total.com/en/spain       valid
Crawling page: https://www.total.com/en/slovakia       valid
Crawling page: https://www.total.com/en/portugal       valid
Crawling page: https://www.total.com/en/romania       valid
Crawling page: https://www.total.com/en/serbia       valid
Crawling page: https://www.total.com/en/poland       valid
Crawling page: https://www.total.com/en/norway       valid
Crawling page: https://www.total.com/en/netherlands       valid
Crawling page: https://www.total.com/en/luxembourg       valid
Crawling page: https://www.total.com/en/malta       valid
Crawling page: https://www.total.com/en/lithuania       valid
Crawling page: https://www.total.com/en/kazakhstan       valid
Crawling page: https://www.total.com/en/latvia       valid
Crawling page: https://www.total.com/en/italy       valid
Crawling page: https://www.total.com/en/hungary       valid
Crawling page: https://www.total.com/en/germany       valid
Crawling page: https://www.total.com/en/ireland       valid
Crawling page: https://www.total.com/en/greece       valid
Crawling page: https://www.total.com/en/denmark       valid
Crawling page: https://www.total.com/en/finland       valid
Crawling page: https://www.total.com/en/estonia       valid
Crawling page: https://www.total.com/en/france       valid
Crawling page: https://www.total.com/en/belgium-0       valid
Crawling page: https://www.total.com/en/bulgaria       valid
Crawling page: https://www.total.com/en/czech-republic       valid
Crawling page: https://www.total.com/en/cyprus       valid
Crawling page: https://www.total.com/en/austria       valid
Crawling page: https://www.total.com/en/thailand       valid
Crawling page: https://www.total.com/en/uzbekistan       valid
Crawling page: https://www.total.com/en/vietnam       valid
Crawling page: https://www.total.com/en/south-korea       valid
Crawling page: https://www.total.com/en/taiwan       valid
Crawling page: https://www.total.com/en/tajikistan       valid
Crawling page: https://www.total.com/en/singapore       valid
Crawling page: https://www.total.com/en/new-caledonia       valid
Crawling page: https://www.total.com/en/papua-new-guinea       valid
Crawling page: https://www.total.com/en/philippines       valid
Crawling page: https://www.total.com/en/new-zealand       valid
Crawling page: https://www.total.com/en/malaysia       valid
Crawling page: https://www.total.com/en/indonesia       valid
Crawling page: https://www.total.com/en/japan       valid
Crawling page: https://www.total.com/en/myanmar       valid
Crawling page: https://www.total.com/en/china       valid
Crawling page: https://www.total.com/en/french-polynesia       valid
Crawling page: https://www.total.com/en/fidji-tonga-samoa-kiribati-naura-and-micronesie       valid
Crawling page: https://www.total.com/en/india       valid
Crawling page: https://www.total.com/en/bangladesh       valid
Crawling page: https://www.total.com/en/brunei       valid
Crawling page: https://www.total.com/en/cambodia       valid
Crawling page: https://www.total.com/en/azerbaijan       valid
Crawling page: https://www.total.com/en/australia       valid
Crawling page: https://www.total.com/en/zambia       valid
Crawling page: https://www.total.com/en/zimbabwe       valid
Crawling page: https://www.total.com/en/uganda       valid
Crawling page: https://www.total.com/en/swaziland       valid
Crawling page: https://www.total.com/en/tunisia       valid
Crawling page: https://www.total.com/en/tanzania       valid
Crawling page: https://www.total.com/en/togo       valid
Crawling page: https://www.total.com/en/sierra-leone       valid
Crawling page: https://www.total.com/en/senegal       valid
Crawling page: https://www.total.com/en/south-africa       valid
Crawling page: https://www.total.com/en/reunion       valid
Crawling page: https://www.total.com/en/niger       valid
Crawling page: https://www.total.com/en/morocco       valid
Crawling page: https://www.total.com/en/namibia       valid
Crawling page: https://www.total.com/en/mozambique       valid
Crawling page: https://www.total.com/en/mayotte       valid
Crawling page: https://www.total.com/en/mauritius       valid
Crawling page: https://www.total.com/en/mali       valid
Crawling page: https://www.total.com/en/mauritania       valid
Crawling page: https://www.total.com/en/malawi       valid
Crawling page: https://www.total.com/en/liberia       valid
Crawling page: https://www.total.com/en/madagascar       valid
Crawling page: https://www.total.com/en/libya       valid
Crawling page: https://www.total.com/en/kenya       valid
Crawling page: https://www.total.com/en/total-republic-guinea       valid
Crawling page: https://www.total.com/en/ivory-coast       valid
Crawling page: https://www.total.com/en/ghana       valid
Crawling page: https://www.total.com/en/ethiopia       valid
Crawling page: https://www.total.com/en/equatorial-guinea       valid
Crawling page: https://www.total.com/en/eritrea       valid
Crawling page: https://www.total.com/en/gabon       valid
Crawling page: https://www.total.com/en/egypt       valid
Crawling page: https://www.total.com/en/democratic-republic-congo       valid
Crawling page: https://www.total.com/en/central-african-republic       valid
Crawling page: https://www.total.com/en/chad       valid
Crawling page: https://www.total.com/en/burkina-faso       valid
Crawling page: https://www.total.com/en/angola       valid
Crawling page: https://www.total.com/en/botswana       valid
Crawling page: https://www.total.com/en/cameroon       valid
Crawling page: https://www.total.com/en/accessibility       valid
Crawling page: https://www.total.com/en/site-map       valid
Crawling page: https://www.total.com/en/privacy       valid
Crawling page: https://www.total.com/en/algeria       valid
Crawling page: https://www.total.com/en/media/media?type=publication&thematic=All       valid
Crawling page: https://www.total.com/en/legal       valid
Crawling page: https://www.total.com/en/media/media-relations2018-11-11 07:37:56 [scrapy.extensions.logstats] INFO: Crawled 2067 pages (at 2 pages/min), scraped 1728 items (at 3 items/min)
2018-11-11 07:38:42 [scrapy.extensions.logstats] INFO: Crawled 2074 pages (at 7 pages/min), scraped 1733 items (at 5 items/min)
2018-11-11 07:40:21 [scrapy.extensions.logstats] INFO: Crawled 2082 pages (at 8 pages/min), scraped 1741 items (at 8 items/min)
2018-11-11 07:41:04 [scrapy.extensions.logstats] INFO: Crawled 2086 pages (at 4 pages/min), scraped 1745 items (at 4 items/min)
2018-11-11 07:41:52 [scrapy.extensions.logstats] INFO: Crawled 2090 pages (at 4 pages/min), scraped 1749 items (at 4 items/min)
2018-11-11 07:42:42 [scrapy.extensions.logstats] INFO: Crawled 2096 pages (at 6 pages/min), scraped 1753 items (at 4 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 07:43:44 [scrapy.extensions.logstats] INFO: Crawled 2104 pages (at 8 pages/min), scraped 1759 items (at 6 items/min)
2018-11-11 07:44:59 [scrapy.extensions.logstats] INFO: Crawled 2109 pages (at 5 pages/min), scraped 1767 items (at 8 items/min)
2018-11-11 07:45:54 [scrapy.extensions.logstats] INFO: Crawled 2114 pages (at 5 pages/min), scraped 1772 items (at 5 items/min)
2018-11-11 07:46:52 [scrapy.extensions.logstats] INFO: Crawled 2118 pages (at 4 pages/min), scraped 1777 items (at 5 items/min)
2018-11-11 07:47:43 [scrapy.extensions.logstats] INFO: Crawled 2122 pages (at 4 pages/min), scraped 1781 items (at 4 items/min)
2018-11-11 07:49:14 [scrapy.extensions.logstats] INFO: Crawled 2129 pages (at 7 pages/min), scraped 1789 items (at 8 items/min)
2018-11-11 07:49:48 [scrapy.extensions.logstats] INFO: Crawled 2133 pages (at 4 pages/min), scraped 1792 items (at 3 items/min)
2018-11-11 07:51:03 [scrapy.extensions.logstats] INFO: Crawled 2141 pages (at 8 pages/min), scraped 1800 items (at 8 items/min)
       valid
Crawling page: https://www.total.com/en/investors/environment-social-governance       valid
Crawling page: https://www.total.com/en/media/check-out-our-official-channels-social-media       valid
Crawling page: https://www.total.com/en/media/news?thematic=All&type=press       valid
Crawling page: https://www.total.com/en/investors/publications-and-regulated-information/regulated-information       valid
Crawling page: https://www.total.com/en/investors/publications-and-regulated-information/other-information       valid
Crawling page: https://www.total.com/en/investors/individual-shareholders/employee-shareholders       valid
Crawling page: https://www.total.com/en/investors/individual-shareholders/shareholders-club       valid
Crawling page: https://www.total.com/en/investors/publications-and-regulated-information       valid
Crawling page: https://www.total.com/en/investors/publications-and-regulated-information/reports-and-publications       valid
Crawling page: https://www.total.com/en/investors/individual-shareholders/buy-shares       valid
Crawling page: https://www.total.com/en/investors/individual-shareholders/shareholder-publications       valid
Crawling page: https://www.total.com/en/investors/individual-shareholders/dedicated-team       valid
Crawling page: https://www.total.com/en/investors/individual-shareholders/shareholders-events       valid
Crawling page: https://www.total.com/en/investors/shareholders-meetings       valid
Crawling page: https://www.total.com/en/investors/individual-shareholders       valid
Crawling page: https://www.total.com/en/investors/shares-and-dividends/Total-shares       valid
Crawling page: https://www.total.com/en/investors/shares-and-dividends/ownership-structure       valid
Crawling page: https://www.total.com/en/investors/shares-and-dividends       valid
Crawling page: https://www.total.com/en/investors/shares-and-dividends/dividends       valid
Crawling page: https://www.total.com/en/investors/results-investor-presentations/main-indicators       valid
Crawling page: https://www.total.com/en/investors/results-investor-presentations/investor-presentations       valid
Crawling page: https://www.total.com/en/investors/results-investor-presentations       valid
Crawling page: https://www.total.com/en/investors/results-investor-presentations/results       valid
Crawling page: https://www.total.com/en/dossiers/total-and-climate       valid
Crawling page: https://www.total.com/en/investors/why-invest-in-total       valid
Crawling page: https://www.total.com/en/commitment/shared-development/ethics-and-sustainable-development-key-factors-our-supplier-relationships       valid
Crawling page: https://www.total.com/en/commitment/shared-development/access-to-energy       valid
Crawling page: https://www.total.com/en/our-commitment/being-responsible-employer       valid
Crawling page: https://www.total.com/en/our-commitment/infographics/our-commitments-and-improvement-indicators       valid
Crawling page: http://vindicoat.com/joomla1/index.php/terms-of-use       valid
Crawling page: http://vindicoat.com/joomla1/       valid
Crawling page: https://www.total.com/en/commitment/shared-development/social-engineering       valid
Crawling page: https://www.total.com/en/commitment/shared-development/local-economic-development       valid
Crawling page: https://www.total.com/en/commitment/shared-development       valid
Crawling page: https://www.total.com/en/commitment/protecting-people/health/local-communities       valid
Crawling page: http://vindicoat.com/joomla1/index.php/meet-the-team       valid
Crawling page: http://vindicoat.com/joomla1/index.php/newsroom       valid
Crawling page: http://vindicoat.com/joomla1/index.php/privacy       valid
Crawling page: http://vindicoat.com/joomla1/index.php/contact       valid
Crawling page: https://www.total.com/en/commitment/protecting-people/health       valid
Crawling page: https://www.total.com/en/commitment/protecting-people/health/workplace       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/environment-protection/anti-pollution-measures       valid
Crawling page: https://www.total.com/en/commitment/protecting-people/health/products       valid
Crawling page: http://vindicoat.com/joomla1/index.php/faq       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/environment-protection/protecting-biodiversity       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/environment-protection/waste       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/environment-protection/water       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/environment-protection/air       valid
Crawling page: http://www.vindicoat.com/joomla1/index.php/contact/request-samples       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/climate-change/energy-efficiency-carbon-reduction       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/environment-protection       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/environment-protection/environmental-engineering       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/climate-change/renewable-energies       valid
Crawling page: https://www.total.com/en/commitment/protecting-people/industrial-safety       valid
Crawling page: https://www.total.com/en/commitment/protecting-people/industrial-safety/culture       valid
Crawling page: https://www.total.com/en/commitment/protecting-people/industrial-safety/risk-management       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/climate-change/carbon-intensity-energy-mix       valid
Crawling page: https://www.total.com/en/energy-expertise/ship-market/products-services/natural-gas-power       valid
Crawling page: https://www.total.com/en/energy-expertise/ship-market/products-services/sustainable-mobility       valid
Crawling page: https://www.total.com/en/energy-expertise/ship-market/products-services/local-presence       valid
Crawling page: https://www.total.com/en/energy-expertise/ship-market/products-services/our-industrial-solutions       valid
Crawling page: https://www.total.com/en/energy-expertise/ship-market/products-services       valid
Crawling page: https://www.total.com/en/energy-expertise/ship-market/our-trading-and-shipping-operations       valid
Crawling page: https://www.total.com/en/energy-expertise/transformation-development/total-present-across-entire-low-carbon-electricity-value-chain       valid
Crawling page: https://www.total.com/en/energy-expertise/transformation-development/specialty-chemicals/hutchinson-elastomers       valid
Crawling page: https://www.total.com/en/energy-expertise/transformation-development/refining-petrochemical/responsible-industry-player       valid
Crawling page: https://www.total.com/en/energy-expertise/transformation-development/refining-petrochemical/long-term-partnerships       valid
Crawling page: https://www.total.com/en/energy-expertise/transformation-development/polymers       valid
Crawling page: https://www.total.com/en/energy-expertise/transformation-development/refining-petrochemical       valid
Crawling page: https://www.total.com/en/energy-expertise/transformation-development/refining-petrochemical/meet-oil-products-demand-worldwide       valid
Crawling page: https://www.total.com/en/energy-expertise/transformation-development/refining-petrochemical/operational-excellence       valid
Crawling page: https://www.total.com/en/energy-expertise/exploration-production/committed-future-bioenergies       valid
Crawling page: https://www.total.com/en/energy-expertise/exploration-production/oil-gas/innovating-produce-tomorrows-oil-and-gas       valid
Crawling page: https://www.total.com/en/energy-expertise/exploration-production/solar-power/our-expertise-in-solar-energy       valid
Crawling page: https://www.total.com/en/energy-expertise/exploration-production/solar-power/solar-the-focus-of-our-renewable-energy-ambition2018-11-11 07:51:55 [scrapy.extensions.logstats] INFO: Crawled 2147 pages (at 6 pages/min), scraped 1804 items (at 4 items/min)
2018-11-11 07:53:26 [scrapy.extensions.logstats] INFO: Crawled 2155 pages (at 8 pages/min), scraped 1810 items (at 6 items/min)
2018-11-11 07:55:09 [scrapy.extensions.logstats] INFO: Crawled 2159 pages (at 4 pages/min), scraped 1818 items (at 8 items/min)
2018-11-11 07:55:57 [scrapy.extensions.logstats] INFO: Crawled 2166 pages (at 7 pages/min), scraped 1822 items (at 4 items/min)
2018-11-11 07:59:02 [scrapy.extensions.logstats] INFO: Crawled 2171 pages (at 5 pages/min), scraped 1829 items (at 7 items/min)
2018-11-11 07:59:55 [scrapy.extensions.logstats] INFO: Crawled 2171 pages (at 0 pages/min), scraped 1834 items (at 5 items/min)
2018-11-11 08:00:43 [scrapy.extensions.logstats] INFO: Crawled 2181 pages (at 10 pages/min), scraped 1838 items (at 4 items/min)
2018-11-11 08:03:29 [scrapy.extensions.logstats] INFO: Crawled 2185 pages (at 4 pages/min), scraped 1844 items (at 6 items/min)
2018-11-11 08:04:24 [scrapy.extensions.logstats] INFO: Crawled 2187 pages (at 2 pages/min), scraped 1848 items (at 4 items/min)
2018-11-11 08:04:45 [scrapy.extensions.logstats] INFO: Crawled 2187 pages (at 0 pages/min), scraped 1850 items (at 2 items/min)
2018-11-11 08:06:04 [scrapy.extensions.logstats] INFO: Crawled 2209 pages (at 22 pages/min), scraped 1860 items (at 10 items/min)
2018-11-11 08:06:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.total.com/en/investors/share-information/ADR-NYSE-TOT-Information> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 08:07:05 [scrapy.extensions.logstats] INFO: Crawled 2209 pages (at 0 pages/min), scraped 1866 items (at 6 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 08:07:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.total.com/en/investors/share-information/total-share-price-paris> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 08:07:52 [scrapy.extensions.logstats] INFO: Crawled 2210 pages (at 1 pages/min), scraped 1871 items (at 5 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 08:08:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wiki.total/en?show_loader=false> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 08:08:44 [scrapy.extensions.logstats] INFO: Crawled 2224 pages (at 14 pages/min), scraped 1878 items (at 7 items/min)
/bin/sh: 1: kill: Illegal number: 
2018-11-11 08:09:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.voragotech.com/custom-products> (referer: None)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 70, in parse_links
    referring_url = response.request.headers.get('Referer', None).decode('ASCII')
AttributeError: 'NoneType' object has no attribute 'decode'
2018-11-11 08:09:43 [scrapy.extensions.logstats] INFO: Crawled 2236 pages (at 12 pages/min), scraped 1888 items (at 10 items/min)
2018-11-11 08:15:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.admaproducts.com/> (referer: https://www.admaproducts.com/?_escaped_fragment_=)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

       valid
Crawling page: https://www.total.com/en/energy-expertise/exploration-production/solar-power       valid
Crawling page: https://www.total.com/en/energy-expertise/exploration-production/oil-gas/our-ambition-oil-and-gas       valid
Crawling page: https://www.total.com/en/energy-expertise/exploration-production/oil-gas/renowed-expertise-oil-and-gas-production-lng-deep-offshore       valid
Crawling page: https://www.total.com/en/energy-expertise/exploration-production/oil-gas       valid
Crawling page: http://vindicoat.com/joomla1/index.php/process       valid
Crawling page: http://vindicoat.com/joomla1/index.php/solution       valid
Crawling page: http://vindicoat.com/joomla1/index.php/industries       valid
Crawling page: https://www.total.com/en/group/strength/deep-geographic-roots       valid
Crawling page: https://www.total.com/en/group/strength       valid
Crawling page: https://www.total.com/en/group/strength/integrated-business-model       valid
Crawling page: https://www.total.com/en/group/strength/employees       valid
Crawling page: http://vindicoat.com/joomla1/index.php/privacy-mobile       valid
Crawling page: http://vindicoat.com/joomla1/index.php/contact-us       valid
Crawling page: http://vindicoat.com/joomla1/index.php/newsroom-mobile       valid
Crawling page: http://vindicoat.com/joomla1/index.php/terms-of-use-mobile       valid
Crawling page: https://www.total.com/en/group/ambition/commitments/supplying-energy-that-contributes-to-economic-and-social-development       valid
Crawling page: https://www.total.com/en/group/ambition/commitments/continually-reinventing-the-customer-relationship       valid
Crawling page: https://www.total.com/en/commitment/environmental-issues-challenges/climate-change       valid
Crawling page: https://www.total.com/en/group/ambition/commitments       valid
Crawling page: https://www.total.com/en/group/ambition       valid
Crawling page: https://www.total.com/en/group/ambition/challenges       valid
Crawling page: https://www.total.com/en/our-group/ethics/exemplary-behavior       valid
Crawling page: http://vindicoat.com/joomla1/index.php/meet-the-team-mobile       valid
Crawling page: http://vindicoat.com/joomla1/index.php/process-mobile       valid
Crawling page: http://vindicoat.com/joomla1/index.php/faq-mobile       valid
Crawling page: http://vindicoat.com/joomla1/index.php/industries-mobile       valid
Crawling page: https://www.total.com/en/group/identity/history       valid
Crawling page: https://www.total.com/en/group/identity/governance/biographies       valid
Crawling page: https://www.total.com/en/group/identity/governance/general-management       valid
Crawling page: https://www.total.com/en/group/identity/five-strong-values-embedded-our-dna       valid
Crawling page: http://vindicoat.com/joomla1/index.php/solution-mobile       valid
Crawling page: https://www.total.com/en/group/identity/governance/board-of-directors       valid
Crawling page: https://www.total.com/en/group/identity/governance       valid
Crawling page: https://www.total.com/en/group/identity       valid
Crawling page: https://www.total.com/en/our-group/total-a-major-energy-operator       valid
Crawling page: https://www.total.com/en/projects       valid
Crawling page: https://www.total.com/en/node/8236/nojs/1       valid
Crawling page: https://www.total.com/en/infographics/total-98-000-employes-dans-plus-de-130-pays       valid
Crawling page: https://www.total.com/en/media/news?thematic=All&type=dossier       valid
Crawling page: https://www.total.com/en/media/info/calendar       valid
Crawling page: https://www.total.com/en/media/news/press-releases/total-announces-third-2018-interim-dividend-update       valid
Crawling page: https://www.total.com/en/media/news/press-releases/angola-total-inaugurates-kaombo-project-and-reiterates-its-commitment-country-new-investments       valid
Crawling page: https://www.total.com/en/media/news/press-releases/total-and-sempra-energy-sign-memorandum-understanding-development-north-american-lng-export-projects       valid
Crawling page: https://www.total.com/en/media/news/press-releases/australia-ichthys-lng-project-begins-gas-exports       valid
Crawling page: https://www.total.com/en/media/news/press-releases/total-joins-forces-indian-private-adani-group-expand-natural-gas-and-fuel-retail-activities-india       valid
Crawling page: https://www.total.com/en/home-media       valid
Crawling page: https://www.total.com/en/dossiers/total-africa-oil-week-2018       valid
Crawling page: https://www.voragotech.com/news       valid
Crawling page: https://www.total.com/en/commitment       valid
Crawling page: https://www.total.com/en/investors       valid
Crawling page: https://www.total.com/en/jobseekers       valid
Crawling page: https://www.total.com/en/group       valid
Crawling page: https://www.voragotech.com/executive-team       valid
Crawling page: https://www.voragotech.com/distributors       valid
Crawling page: https://www.voragotech.com/company-overview       valid
Crawling page: https://www.total.com/en/energy-expertise       valid
Crawling page: https://www.voragotech.com/licensing       valid
Crawling page: https://www.total.com/en/info/company-websites       valid
Crawling page: https://www.voragotech.com/products/roadmap       valid
Crawling page: https://www.voragotech.com/development-tools       valid
Crawling page: https://www.total.com/en/investors/share-information/ADR-NYSE-TOT-Information       Crawling page: https://www.total.com/fr       valid
Crawling page: https://www.total.com/en/contact-form       valid
Crawling page: http://smebeam.com/index.html       valid
Crawling page: https://www.voragotech.com/vorago-products       valid
Crawling page: https://www.voragotech.com/flight-heritage       valid
Crawling page: https://www.voragotech.com/applications       valid
Crawling page: https://www.voragotech.com/resources       valid
Crawling page: https://www.total.com/en       valid
Crawling page: https://www.total.com/en/investors/share-information/total-share-price-paris       Crawling page: https://www.westec.org/the-bridge.html       valid
Crawling page: https://www.westec.org/       valid
Crawling page: https://www.westec.org/well-control-1.html       valid
Crawling page: https://www.westec.org/jobs.html       valid
Crawling page: https://www.westec.org/train-for-success-1.html       valid
Crawling page: https://www.westec.org/spelling-vocab-assignments.html       valid
Crawling page: https://www.westec.org/safety-1.html       valid
Crawling page: http://wiki.total/en?show_loader=false       Crawling page: https://www.westec.org/audio-practice-files2.html       valid
Crawling page: https://www.westec.org/perfect-copies.html       valid
Crawling page: https://www.voragotech.com/       valid
Crawling page: https://www.westec.org/practice-material---lists.html       valid
Crawling page: https://www.voragotech.com/technology       valid
Crawling page: https://www.voragotech.com/custom-products       Crawling page: https://sumitomorubber-usa.com/legal/certificates/       valid
Crawling page: https://sumitomorubber-usa.com/legal/california-transparency-statement/       valid
Crawling page: https://www.westec.org/court-reporting-information-page.html       valid
Crawling page: https://www.westec.org/-2018-in-service-class-schedule.html       valid
Crawling page: https://www.westec.org/adult-correctional-officer-core.html       valid
Crawling page: https://www.westec.org/pc832-arrest-and-control----pc832-firearms.html       valid
Crawling page: https://sumitomorubber-usa.com/news/article:05-15-2018-12-00am-both-team-falken-motorsports-racecars-complete-the-46th-adac-zurich-24h-race-nurburgring/       valid
Crawling page: https://sumitomorubber-usa.com/legal/terms-of-use/       valid
Crawling page: https://sumitomorubber-usa.com/legal/privacy-policy/       valid
Crawling page: https://sumitomorubber-usa.com/news/article:12-15-2016-12-00am-sri-group-s-usa-technical-center-to-be-fully-operational-from-january-2017/       valid
Crawling page: https://www.admaproducts.com/       Crawling page: https://sumitomorubber-usa.com/news/article:09-18-2018-12-00am-team-falken-s-yoshihide-muroya-places-2nd-in-the-sixth-race-of-red-bull-air-race-world-championship-2018/2018-11-11 08:15:08 [scrapy.extensions.logstats] INFO: Crawled 2239 pages (at 3 pages/min), scraped 1894 items (at 6 items/min)
2018-11-11 08:15:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <406 http://thornbioscience.com/our-research/saber/>: HTTP status code is not handled or not allowed
2018-11-11 08:16:33 [scrapy.extensions.logstats] INFO: Crawled 2259 pages (at 20 pages/min), scraped 1906 items (at 12 items/min)
2018-11-11 08:17:32 [scrapy.extensions.logstats] INFO: Crawled 2259 pages (at 0 pages/min), scraped 1916 items (at 10 items/min)
2018-11-11 08:17:46 [scrapy.extensions.logstats] INFO: Crawled 2269 pages (at 10 pages/min), scraped 1917 items (at 1 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 08:18:41 [scrapy.extensions.logstats] INFO: Crawled 2273 pages (at 4 pages/min), scraped 1922 items (at 5 items/min)
2018-11-11 08:20:28 [scrapy.extensions.logstats] INFO: Crawled 2277 pages (at 4 pages/min), scraped 1930 items (at 8 items/min)
2018-11-11 08:21:21 [scrapy.extensions.logstats] INFO: Crawled 2277 pages (at 0 pages/min), scraped 1934 items (at 4 items/min)
2018-11-11 08:21:46 [scrapy.extensions.logstats] INFO: Crawled 2287 pages (at 10 pages/min), scraped 1936 items (at 2 items/min)
2018-11-11 08:22:43 [scrapy.extensions.logstats] INFO: Crawled 2292 pages (at 5 pages/min), scraped 1940 items (at 4 items/min)
2018-11-11 08:28:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.renovacareinc.com/disclaimer-privacy-policy> (referer: https://www.renovacareinc.com/contact/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-11 08:29:33 [scrapy.extensions.logstats] INFO: Crawled 2295 pages (at 3 pages/min), scraped 1948 items (at 8 items/min)
2018-11-11 08:30:12 [scrapy.extensions.logstats] INFO: Crawled 2295 pages (at 0 pages/min), scraped 1951 items (at 3 items/min)
2018-11-11 08:35:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.renovacareinc.com/media/> (referer: https://www.renovacareinc.com/contact/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-11 08:40:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.renovacareinc.com/press-kit/> (referer: https://www.renovacareinc.com/contact/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-11 08:45:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.renovacareinc.com/videos/> (referer: https://www.renovacareinc.com/contact/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-11 08:45:28 [scrapy.extensions.logstats] INFO: Crawled 2315 pages (at 20 pages/min), scraped 1952 items (at 1 items/min)
2018-11-11 08:52:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.renovacareinc.com/> (referer: https://www.renovacareinc.com/contact/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-11 08:57:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.renovacareinc.com/investors/> (referer: https://www.renovacareinc.com/contact/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-11 08:58:13 [scrapy.extensions.logstats] INFO: Crawled 2315 pages (at 0 pages/min), scraped 1966 items (at 14 items/min)
2018-11-11 08:59:02 [scrapy.extensions.logstats] INFO: Crawled 2327 pages (at 12 pages/min), scraped 1970 items (at 4 items/min)
2018-11-11 08:59:56 [scrapy.extensions.logstats] INFO: Crawled 2331 pages (at 4 pages/min), scraped 1974 items (at 4 items/min)
2018-11-11 09:00:49 [scrapy.extensions.logstats] INFO: Crawled 2331 pages (at 0 pages/min), scraped 1978 items (at 4 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 09:01:50 [scrapy.extensions.logstats] INFO: Crawled 2337 pages (at 6 pages/min), scraped 1983 items (at 5 items/min)
2018-11-11 09:01:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.symbols.com/print.php?id=taurus> (referer: https://www.symbols.com/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 59, in parse_links
    res = response.replace(body=browser.page_source)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: Failed to decode response from marionette

2018-11-11 09:02:50 [scrapy.extensions.logstats] INFO: Crawled 2341 pages (at 4 pages/min), scraped 1987 items (at 4 items/min)
2018-11-11 09:03:48 [scrapy.extensions.logstats] INFO: Crawled 2341 pages (at 0 pages/min), scraped 1991 items (at 4 items/min)
2018-11-11 09:05:15 [scrapy.extensions.logstats] INFO: Crawled 2353 pages (at 12 pages/min), scraped 1999 items (at 8 items/min)
2018-11-11 09:06:08 [scrapy.extensions.logstats] INFO: Crawled 2357 pages (at 4 pages/min), scraped 2003 items (at 4 items/min)
2018-11-11 09:07:08 [scrapy.extensions.logstats] INFO: Crawled 2357 pages (at 0 pages/min), scraped 2007 items (at 4 items/min)
       valid
Crawling page: https://sumitomorubber-usa.com/news/article:09-11-2018-12-00am-falken-ziex-ze001-a-s-selected-as-factory-standard-tires-for-the-new-subaru-forester/       valid
Crawling page: http://thornbioscience.com/qa-qc/       valid
Crawling page: http://thornbioscience.com/about-us/scientific-advisory-board/       valid
Crawling page: http://thornbioscience.com/our-research/       valid
Crawling page: https://www.symbols.com/about.php?slc=Symbols       valid
Crawling page: https://www.symbols.com/symbol/flag-of-morocco       valid
Crawling page: https://www.symbols.com/symbol/flag-of-egypt       valid
Crawling page: https://www.symbols.com/symbol/flag-of-estonia       valid
Crawling page: http://thornbioscience.com/about-us/       valid
Crawling page: http://thornbioscience.com/about-us/laura-thorn/       valid
Crawling page: http://thornbioscience.com/about-us/bibliography/       valid
Crawling page: http://thornbioscience.com/veterinary-products/       valid
Crawling page: http://thornbioscience.com       valid
Crawling page: https://sumitomorubber-usa.com/company/community/       valid
Crawling page: https://sumitomorubber-usa.com/company/leadership/       valid
Crawling page: https://sumitomorubber-usa.com/company/culture/       valid
Crawling page: https://sumitomorubber-usa.com/company/history/       valid
Crawling page: https://www.symbols.com/symbol/flag-of-mongolia       valid
Crawling page: https://www.symbols.com/symbol/flag-of-bulgaria       valid
Crawling page: https://www.symbols.com/symbol/flag-of-benin       valid
Crawling page: https://www.symbols.com/symbol/flag-of-bahrain       valid
Crawling page: http://thornbioscience.com/clean-room-services/       valid
Crawling page: https://www.symbols.com/symbol/flag-of-andorra       valid
Crawling page: https://www.symbols.com/symbol/flag-of-argentina       valid
Crawling page: https://www.symbols.com/symbol/flag-of-indonesia       valid
Crawling page: https://sumitomorubber-usa.com/company/about/       valid
Crawling page: https://www.symbols.com/symbol/flag-of-ivory-coast       valid
Crawling page: https://sumitomorubber-usa.com/       valid
Crawling page: https://www.symbols.com/symbol/flag-of-tuvalu       valid
Crawling page: https://www.symbols.com/symbol/nepal       valid
Crawling page: https://www.symbols.com/symbol/flag-of-ukraine       valid
Crawling page: https://www.symbols.com/symbol/flag-of-brunei       valid
Crawling page: https://www.symbols.com/symbol/suriah       valid
Crawling page: https://www.symbols.com/symbol/flag-of-yemen       valid
Crawling page: https://www.symbols.com/symbol/flag-of-tunisia       valid
Crawling page: https://www.symbols.com/symbol/flag-of-luxembourg       valid
Crawling page: https://www.symbols.com/symbol/flag-of-austria       valid
Crawling page: https://www.symbols.com/symbol/flag-of-armenia       valid
Crawling page: https://www.symbols.com/symbol/flag-of-iraq       valid
Crawling page: https://www.symbols.com/symbol/flag-of-dominica       valid
Crawling page: https://www.symbols.com/advertise.php       valid
Crawling page: https://www.symbols.com/what-is-this-symbol.php       valid
Crawling page: https://www.symbols.com/group/4       valid
Crawling page: https://www.symbols.com/category/39       valid
Crawling page: https://www.symbols.com/symbol/flag-of-denmark       valid
Crawling page: https://www.symbols.com/symbol/flag-of-djibouti       valid
Crawling page: https://www.symbols.com/category/62       valid
Crawling page: https://www.symbols.com/category/37       valid
Crawling page: https://www.symbols.com/category/35       valid
Crawling page: https://www.symbols.com/category/64       valid
Crawling page: https://www.renovacareinc.com/disclaimer-privacy-policy       Crawling page: https://www.symbols.com/category/45       valid
Crawling page: https://www.symbols.com/category/56       valid
Crawling page: https://www.symbols.com/category/5       valid
Crawling page: https://www.symbols.com/category/25       valid
Crawling page: https://www.renovacareinc.com/stock-info/       valid
Crawling page: https://www.symbols.com/category/10       valid
Crawling page: https://www.symbols.com/category/33       valid
Crawling page: https://www.renovacareinc.com/media/       Crawling page: https://www.renovacareinc.com/press-kit/       Crawling page: https://www.renovacareinc.com/press-releases/       valid
Crawling page: https://www.renovacareinc.com/videos/       Crawling page: https://www.symbols.com/category/18       valid
Crawling page: https://www.symbols.com/category/12       valid
Crawling page: https://www.symbols.com/category/16       valid
Crawling page: https://www.symbols.com/category/27       valid
Crawling page: https://www.renovacareinc.com/photos/       valid
Crawling page: https://www.renovacareinc.com/publication/       valid
Crawling page: https://www.renovacareinc.com/team/       valid
Crawling page: https://www.renovacareinc.com/technology/       valid
Crawling page: https://www.symbols.com/category/17       valid
Crawling page: https://www.symbols.com/category/52       valid
Crawling page: https://www.renovacareinc.com/about/       valid
Crawling page: https://www.renovacareinc.com/       Crawling page: https://www.renovacareinc.com/investor-deck       valid
Crawling page: https://www.renovacareinc.com/investors/       Crawling page: https://www.symbols.com/category/15       valid
Crawling page: https://www.symbols.com/category/23       valid
Crawling page: https://www.symbols.com/category/38       valid
Crawling page: https://www.symbols.com/category/61       valid
Crawling page: https://www.symbols.com/category/22       valid
Crawling page: https://www.symbols.com/category/47       valid
Crawling page: https://www.symbols.com/category/41       valid
Crawling page: https://www.symbols.com/category/13       valid
Crawling page: https://www.symbols.com/category/66       valid
Crawling page: https://www.symbols.com/symbol/virgo       valid
Crawling page: https://www.symbols.com/symbol/scorpio       valid
Crawling page: https://www.symbols.com/symbol/sagittarius       valid
Crawling page: https://www.symbols.com/symbol/pisces       valid
Crawling page: https://www.symbols.com/symbol/libra       valid
Crawling page: https://www.symbols.com/symbol/leo       valid
Crawling page: https://www.symbols.com/symbol/gemini       valid
Crawling page: https://www.symbols.com/symbol/capricorn       valid
Crawling page: https://www.symbols.com/symbol/cancer       valid
Crawling page: https://www.renovacareinc.com/contact/       valid
Crawling page: https://www.symbols.com/print.php?id=taurus       Crawling page: https://www.symbols.com/collection.php?add=2       valid
Crawling page: https://www.symbols.com/symbol/aquarius       valid
Crawling page: https://www.symbols.com/group/1       valid
Crawling page: https://www.symbols.com/symbol/aries       valid
Crawling page: https://www.symbols.com/category/1       valid
Crawling page: https://www.symbols.com/category/34       valid
Crawling page: https://www.symbols.com/category/2       valid
Crawling page: https://www.symbols.com/symbol/taurus       valid
Crawling page: https://www.symbols.com/group/12       valid
Crawling page: https://www.symbols.com/category/31       valid
Crawling page: https://www.symbols.com/category/28       valid
Crawling page: https://www.symbols.com/category/46       valid
Crawling page: https://www.symbols.com/all_categories.php       valid
Crawling page: https://www.symbols.com/category/9       valid
Crawling page: https://www.symbols.com/justadded.php       valid
Crawling page: https://www.symbols.com/search/life       valid
Crawling page: https://www.symbols.com/symbols/Z       valid
Crawling page: https://www.symbols.com/symbols/Y       valid
Crawling page: https://www.symbols.com/symbols/X       valid
Crawling page: https://www.symbols.com/symbols/W       valid
Crawling page: https://www.symbols.com/symbols/V       valid
Crawling page: https://www.symbols.com/symbols/U       valid
Crawling page: https://www.symbols.com/symbols/T       valid
Crawling page: https://www.symbols.com/symbols/S       valid
Crawling page: https://www.symbols.com/symbols/O2018-11-11 09:07:46 [scrapy.extensions.logstats] INFO: Crawled 2367 pages (at 10 pages/min), scraped 2010 items (at 3 items/min)
2018-11-11 09:09:27 [scrapy.extensions.logstats] INFO: Crawled 2372 pages (at 5 pages/min), scraped 2018 items (at 8 items/min)
2018-11-11 09:10:19 [scrapy.extensions.logstats] INFO: Crawled 2376 pages (at 4 pages/min), scraped 2022 items (at 4 items/min)
2018-11-11 09:11:17 [scrapy.extensions.logstats] INFO: Crawled 2378 pages (at 2 pages/min), scraped 2026 items (at 4 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 09:11:45 [scrapy.extensions.logstats] INFO: Crawled 2378 pages (at 0 pages/min), scraped 2028 items (at 2 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 09:12:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <406 http://www.solartonic.com/>: HTTP status code is not handled or not allowed
2018-11-11 09:13:00 [scrapy.extensions.logstats] INFO: Crawled 2401 pages (at 23 pages/min), scraped 2044 items (at 16 items/min)
2018-11-11 09:14:10 [scrapy.extensions.logstats] INFO: Crawled 2416 pages (at 15 pages/min), scraped 2062 items (at 18 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 09:14:53 [scrapy.extensions.logstats] INFO: Crawled 2440 pages (at 24 pages/min), scraped 2075 items (at 13 items/min)
2018-11-11 09:15:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.them.net/tel:8003228436>: HTTP status code is not handled or not allowed
2018-11-11 09:16:49 [scrapy.extensions.logstats] INFO: Crawled 2440 pages (at 0 pages/min), scraped 2088 items (at 13 items/min)
2018-11-11 09:22:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.renovacareinc.com/briefcase/> (referer: https://www.renovacareinc.com/contact/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-11 09:22:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <406 http://www.solartonic.com/solartonic-participates-in-next-energy-smart-cities-challenge/>: HTTP status code is not handled or not allowed
2018-11-11 09:22:21 [scrapy.extensions.logstats] INFO: Crawled 2458 pages (at 18 pages/min), scraped 2091 items (at 3 items/min)
2018-11-11 09:23:10 [scrapy.extensions.logstats] INFO: Crawled 2458 pages (at 0 pages/min), scraped 2096 items (at 5 items/min)
2018-11-11 09:28:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.renovacareinc.com/sec-filings/> (referer: https://www.renovacareinc.com/contact/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-11 09:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.renovacareinc.com/faqs/> (referer: https://www.renovacareinc.com/contact/)
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/spiders/crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "/home/ubuntu/EAGER/code/crawler/FirmDB/spiders/HTMLSpider.py", line 58, in parse_links
    browser.get(response.url)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: Timeout loading page after 300000ms

2018-11-11 09:33:54 [scrapy.extensions.logstats] INFO: Crawled 2458 pages (at 0 pages/min), scraped 2102 items (at 6 items/min)
2018-11-11 09:33:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://tpsolar.nl/project-lochem/?lang=en>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://tpsolar.nl/project-lochem/?lang=en took longer than 180.0 seconds..
2018-11-11 09:33:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.voragotech.com/contact-us>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.voragotech.com/contact-us took longer than 180.0 seconds..
2018-11-11 09:35:32 [scrapy.extensions.logstats] INFO: Crawled 2476 pages (at 18 pages/min), scraped 2113 items (at 11 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 09:36:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.symbols.com/category/63>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 09:36:07 [scrapy.extensions.logstats] INFO: Crawled 2477 pages (at 1 pages/min), scraped 2116 items (at 3 items/min)
       valid
Crawling page: https://www.symbols.com/symbols/Q       valid
Crawling page: https://www.symbols.com/symbols/R       valid
Crawling page: https://www.symbols.com/symbols/P       valid
Crawling page: https://www.symbols.com/symbols/N       valid
Crawling page: https://www.symbols.com/symbols/M       valid
Crawling page: https://www.symbols.com/symbols/L       valid
Crawling page: https://www.symbols.com/symbols/K       valid
Crawling page: https://www.symbols.com/symbols/J       valid
Crawling page: https://www.symbols.com/symbols/I       valid
Crawling page: https://www.symbols.com/symbols/H       valid
Crawling page: https://www.symbols.com/symbols/G       valid
Crawling page: https://www.symbols.com/symbols/F       valid
Crawling page: https://www.symbols.com/symbols/E       valid
Crawling page: https://www.symbols.com/symbols/D       valid
Crawling page: https://www.symbols.com/symbols/C       valid
Crawling page: https://www.symbols.com/symbols/B       valid
Crawling page: https://www.symbols.com/symbols/A       valid
Crawling page: https://www.symbols.com/symbol/watford-f.c.-logo       valid
Crawling page: https://www.symbols.com/symbols/0       valid
Crawling page: https://www.symbols.com/       valid
Crawling page: http://oasdesigngroup.com       valid
Crawling page: http://oasdesigngroup.com/about-2/index.html       valid
Crawling page: http://oasdesigngroup.com/services/index.html       valid
Crawling page: http://plasmawhirl.com/contact.php       valid
Crawling page: http://www.oasdesigngroup.com       valid
Crawling page: http://plasmawhirl.com/lighting.php       valid
Crawling page: https://www.panasonic.com/global/sitemap.html       valid
Crawling page: https://www.panasonic.com/global/corporate/profile/group-companies/sanyo.html       valid
Crawling page: http://plasmawhirl.com/links.php       valid
Crawling page: http://plasmawhirl.com/patents.php       valid
Crawling page: http://plasmawhirl.com/bricks.php       valid
Crawling page: https://www.panasonic.com/jp/corporate/profile/group-companies/sanyo.html       valid
Crawling page: https://www.panasonic.com/global/global-network.html       valid
Crawling page: http://www.solartonic.com/solutions/innovations/       valid
Crawling page: http://www.solartonic.com/solutions/solar-lighting/       valid
Crawling page: http://www.solartonic.com/solutions/case-study-imd-houston/       valid
Crawling page: http://plasmawhirl.com/dCurrent.php       valid
Crawling page: https://www.panasonic.com/global/cookie-policy.html       valid
Crawling page: http://plasmawhirl.com/biochar.php       valid
Crawling page: http://plasmawhirl.com/products.php       valid
Crawling page: http://plasmawhirl.com/about.php       valid
Crawling page: http://www.solartonic.com/solutions/       valid
Crawling page: http://www.them.net/contract-packaging/       valid
Crawling page: http://www.them.net/packaging-blog/       valid
Crawling page: http://www.them.net/gallery/photos/       valid
Crawling page: http://www.them.net/gallery/videos/       valid
Crawling page: http://www.them.net/gallery/       valid
Crawling page: http://www.them.net/technologies/zipbox/       valid
Crawling page: http://www.them.net/technologies/stick-pack/       valid
Crawling page: http://www.them.net/technologies/snapsil/       valid
Crawling page: http://www.them.net/technologies/fbr-elpo/       valid
Crawling page: http://www.them.net/technologies/earthinks/       valid
Crawling page: http://www.them.net/technologies/       valid
Crawling page: http://www.them.net/packaging-machinery/stick-packaging-machinery/       valid
Crawling page: http://www.them.net/packaging-machinery/       valid
Crawling page: http://plasmawhirl.com/index.php       valid
Crawling page: http://www.them.net/contract-packaging/pouch-package-contract-packaging/       valid
Crawling page: http://www.them.net/contract-packaging/stick-pack-contract-packaging/       valid
Crawling page: http://www.them.net/contract-packaging/quality/       valid
Crawling page: http://www.them.net/about-us/partners/       valid
Crawling page: http://www.them.net/about-us/markets/       valid
Crawling page: http://www.them.net/about-us/leadership/       valid
Crawling page: http://www.them.net/about-us/history/       valid
Crawling page: http://www.them.net/about-us/them-advantage/       valid
Crawling page: http://www.them.net/about-us/       valid
Crawling page: http://www.them.net/       valid
Crawling page: http://www.them.net/packaging-machinery/liquid-paste-packaging-machinery/       valid
Crawling page: https://www.panasonic.com/global/home.html       valid
Crawling page: https://www.panasonic.com/global/privacy-policy.html       valid
Crawling page: https://www.panasonic.com/global/terms-of-use.html       valid
Crawling page: http://www.solartonic.com/contact/       valid
Crawling page: http://www.solartonic.com/news/       valid
Crawling page: http://www.solartonic.com/solutions/case-study-next-energy/       valid
Crawling page: http://www.them.net/contact-direction/       valid
Crawling page: http://www.them.net/packaging-machinery/       valid
Crawling page: http://www.solartonic.com/blog/blog-grid/       valid
Crawling page: http://www.solartonic.com/?s=       valid
Crawling page: http://www.solartonic.com/solartonic-establishes-middle-east-partnership/       valid
Crawling page: http://www.solartonic.com/category/news/       valid
Crawling page: http://www.them.net/packaging-machinery/powder-granule-packaging-machinery/       valid
Crawling page: http://www.them.net/about-us/       valid
Crawling page: https://www.renovacareinc.com/register/       valid
Crawling page: https://www.renovacareinc.com/briefcase/       Crawling page: https://www.symbols.com/category/68       valid
Crawling page: https://www.symbols.com/category/42       valid
Crawling page: https://www.symbols.com/category/51       valid
Crawling page: https://www.symbols.com/category/3       valid
Crawling page: http://thornbioscience.com/our-research/ovulation-induction/       valid
Crawling page: http://thornbioscience.com/our-research/mucosal-surfaces/       valid
Crawling page: https://www.renovacareinc.com/sec-filings/       Crawling page: https://www.renovacareinc.com/faqs/       Crawling page: https://sumitomorubber-usa.com/careers/       valid
Crawling page: https://sumitomorubber-usa.com/news/article:12-14-2016-12-00am-87-million-investment-will-expand-tonawanda-tire-plant/       valid
Crawling page: https://sumitomorubber-usa.com/contact/       valid
Crawling page: https://sumitomorubber-usa.com/news/       valid
Crawling page: https://www.symbols.com/awards.php       valid
Crawling page: https://www.symbols.com/testimonials.php       valid
Crawling page: https://www.symbols.com/news.php       valid
Crawling page: https://www.symbols.com/press.php       valid
Crawling page: https://www.symbols.com/category/54       valid
Crawling page: https://www.westec.org/home.html       valid
Crawling page: https://www.westec.org/about.html       valid
Crawling page: https://www.westec.org/administration-of-justice.html       valid
Crawling page: https://www.westec.org/map-to-westec.html       valid
Crawling page: http://www.solartonic.com/solartonic-opens-new-london-uk-office/       valid
Crawling page: http://www.solartonic.com/solartonic-presents-at-smart-cities-connect-expo-in-austin/       valid
Crawling page: http://www.solartonic.com/author/hgg10_us2001ahotmail-com/       valid
Crawling page: http://www.solartonic.com/solartonic-completes-projects-in-arizona/       valid
Crawling page: https://www.symbols.com/category/6       valid
Crawling page: https://www.symbols.com/category/48       valid
Crawling page: https://www.thewaltdisneycompany.com/       valid
Crawling page: https://tpsolar.nl/project-uden/?lang=en       valid
Crawling page: https://tpsolar.nl/nieuws/?lang=en       valid
Crawling page: https://www.thewaltdisneycompany.com/mickeys-90th-spectacular-honors-the-mouse-who-started-it-all/       valid
Crawling page: https://www.thewaltdisneycompany.com/the-walt-disney-company-and-make-a-wish-invite-fans-to-share-your-ears-to-help-grant-wishes/       valid
Crawling page: https://www.thewaltdisneycompany.com/environment/2018-11-11 09:37:12 [scrapy.extensions.logstats] INFO: Crawled 2489 pages (at 12 pages/min), scraped 2125 items (at 9 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 09:37:59 [scrapy.extensions.logstats] INFO: Crawled 2492 pages (at 3 pages/min), scraped 2130 items (at 5 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 09:38:41 [scrapy.extensions.logstats] INFO: Crawled 2496 pages (at 4 pages/min), scraped 2137 items (at 7 items/min)
2018-11-11 09:39:42 [scrapy.extensions.logstats] INFO: Crawled 2505 pages (at 9 pages/min), scraped 2146 items (at 9 items/min)
2018-11-11 09:40:46 [scrapy.extensions.logstats] INFO: Crawled 2516 pages (at 11 pages/min), scraped 2157 items (at 11 items/min)
2018-11-11 09:41:46 [scrapy.extensions.logstats] INFO: Crawled 2528 pages (at 12 pages/min), scraped 2168 items (at 11 items/min)
2018-11-11 09:42:43 [scrapy.extensions.logstats] INFO: Crawled 2540 pages (at 12 pages/min), scraped 2179 items (at 11 items/min)
2018-11-11 09:43:41 [scrapy.extensions.logstats] INFO: Crawled 2550 pages (at 10 pages/min), scraped 2189 items (at 10 items/min)
2018-11-11 09:44:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://www.uvic.ca/mypage/api/cookiecheck>: HTTP status code is not handled or not allowed
2018-11-11 09:44:44 [scrapy.extensions.logstats] INFO: Crawled 2563 pages (at 13 pages/min), scraped 2202 items (at 13 items/min)
2018-11-11 09:45:48 [scrapy.extensions.logstats] INFO: Crawled 2575 pages (at 12 pages/min), scraped 2214 items (at 12 items/min)
       valid
Crawling page: https://www.thewaltdisneycompany.com/philanthropy/       valid
Crawling page: https://www.thewaltdisneycompany.com/news/       valid
Crawling page: https://www.thewaltdisneycompany.com/new-star-wars-and-marvel-series-announced-for-disney-streaming-service/       valid
Crawling page: https://www.thewaltdisneycompany.com/investor-relations/       valid
Crawling page: https://tpsolar.nl/project-dordrecht-2/?lang=en       valid
Crawling page: https://tpsolar.nl/       valid
Crawling page: https://tpsolar.nl/       valid
Crawling page: https://tpsolar.nl/?lang=en       valid
Crawling page: https://www.thewaltdisneycompany.com/about/       valid
Crawling page: https://www.uvic.ca/news/media/index.php       valid
Crawling page: https://www.uvic.ca/communicationsmarketing/media/resources/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/index.php       valid
Crawling page: https://www.uvic.ca/home/about/contact-us/       valid
Crawling page: https://www.uvic.ca/current-faculty-staff/home/resources/       valid
Crawling page: https://www.uvic.ca/security/       valid
Crawling page: https://www.uvic.ca/current-students/home/resources/       valid
Crawling page: https://www.uvic.ca/home/about/copyright/index.php       valid
Crawling page: https://www.uvic.ca/home/about/legal-notices/index.php       valid
Crawling page: https://www.uvic.ca/home/about/social-media/index.php       valid
Crawling page: https://www.uvic.ca/news/       valid
Crawling page: https://www.uvic.ca/home/about/accessibility/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/contact/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/researchsnapshots/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/events/index.php       valid
Crawling page: https://www.uvic.ca/news/topics/2018+convocation-fall-sci-saville+news       valid
Crawling page: https://www.uvic.ca/research/partner/home/technologies/portfolio/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/technologies/techtransfer/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/technologies/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/research-opps/agreements/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/services/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/research-opps/grants/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/research-opps/co-op/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/why/curp/index.php       valid
Crawling page: https://www.uvic.ca/research/learnabout/home/researchers/experts/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/why/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/about/index.php       valid
Crawling page: https://www.uvic.ca/search/q/experts.php?searchstring=       valid
Crawling page: https://www.uvic.ca/search/q/department.php?qtype=dept&deptq=       valid
Crawling page: https://www.uvic.ca/search/q/resources.php?resources-q=       valid
Crawling page: https://www.uvic.ca/search/q/directory.php?qtype=pers&persq=       valid
Crawling page: https://www.uvic.ca/search/q/web.php?t=4&p=1&g=true&q=       valid
Crawling page: https://www.uvic.ca/research/search.php?t=4&p=1&g=true&q=       valid
Crawling page: https://www.uvic.ca/home/share/       valid
Crawling page: https://www.uvic.ca/search/q/news.php?q=&t=4&p=1       valid
Crawling page: https://www.uvic.ca/hr/careers/       valid
Crawling page: https://www.uvic.ca/home/tools/index.php       valid
Crawling page: https://www.uvic.ca/systems/status/notices/index.php       valid
Crawling page: https://www.uvic.ca/systems/status/index.php       valid
Crawling page: https://www.uvic.ca/systems/services/internettelephone/index.php       valid
Crawling page: https://www.uvic.ca/systems/services/contact/       valid
Crawling page: https://www.uvic.ca/systems/services/emailcalendar/index.php       valid
Crawling page: https://www.uvic.ca/systems/services/informationsecurity/index.php       valid
Crawling page: https://www.uvic.ca/systems/services/loginspasswords/index.php       valid
Crawling page: https://www.uvic.ca/systems/services/helpsupport/hardwarerepair/index.php       valid
Crawling page: https://www.uvic.ca/systems/support/avmultimedia/index.php       valid
Crawling page: https://www.uvic.ca/systems/about/clientservices/desktopsupport/index.php       valid
Crawling page: https://www.uvic.ca/systems/       valid
Crawling page: https://www.uvic.ca/cas/login?service=https%3A%2F%2Fwww.uvic.ca%2Femail%2F       valid
Crawling page: https://www.uvic.ca/library/index.php       valid
Crawling page: https://www.uvic.ca/hr/       valid
Crawling page: https://www.uvic.ca/cas/login?service=https%3A%2F%2Fwww.uvic.ca%2Frais%2Flogin%2Fcas       valid
Crawling page: https://www.uvic.ca/cas/login?service=https%3A%2F%2Fwww.uvic.ca%2Fbanner%2F       valid
Crawling page: https://www.uvic.ca/security/home/direct/index.php       valid
Crawling page: https://www.uvic.ca/security/safety/security/safewalk/index.php       valid
Crawling page: https://www.uvic.ca/services/health/       valid
Crawling page: https://www.uvic.ca/home/help/       valid
Crawling page: https://www.uvic.ca/coopandcareer/       valid
Crawling page: https://www.uvic.ca/services/counselling/       valid
Crawling page: https://www.uvic.ca/services/cal/       valid
Crawling page: https://www.uvic.ca/equity/       valid
Crawling page: https://www.uvic.ca/current-students/home/student-life/index.php       valid
Crawling page: https://www.uvic.ca/finnerty/index.php       valid
Crawling page: https://www.uvic.ca/communications/speakersbureau/index.php       valid
Crawling page: https://www.uvic.ca/farquhar/       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/maps/maps/mac.php       valid
Crawling page: https://www.uvic.ca/residence/home/home/off-campus/       valid
Crawling page: https://www.uvic.ca/residence/future-residents/       valid
Crawling page: https://www.uvic.ca/residence/       valid
Crawling page: https://www.uvic.ca/services/food/what/index.php       valid
Crawling page: https://www.uvic.ca/services/food/index.php       valid
Crawling page: https://www.uvic.ca/services/food/where/index.php       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/maps/maps/bikemap.php       valid
Crawling page: https://www.uvic.ca/facilities/service/accessibility/index.php       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/maps/maps/busroutes.php       valid
Crawling page: https://www.uvic.ca/systems/services/avmultimedia/classroomav/index.php       valid
Crawling page: https://www.uvic.ca/search/browse/maps.php       valid
Crawling page: https://www.uvic.ca/security/safety/index.php       valid
Crawling page: https://www.uvic.ca/home/on-campus/       valid
Crawling page: https://www.uvic.ca/security/index.php       valid
Crawling page: https://www.uvic.ca/library/about/work/index.php       valid
Crawling page: https://www.uvic.ca/library/about/support/index.php       valid
Crawling page: https://www.uvic.ca/library/about/FAQs/index.php       valid
Crawling page: https://www.uvic.ca/library/about/ul/index.php       valid
Crawling page: https://www.uvic.ca/library/about/index.php       valid
Crawling page: https://www.uvic.ca/library/use/floormaps/index.php       valid
Crawling page: https://www.uvic.ca/library/use/policies/index.php       valid
Crawling page: https://www.uvic.ca/library/use/connect/index.php       valid
Crawling page: https://www.uvic.ca/library/use/computers/index.php       valid
Crawling page: https://www.uvic.ca/library/use/borrow/index.php       valid
Crawling page: https://www.uvic.ca/library/use/info/index.php       valid
Crawling page: https://www.uvic.ca/library/use/studyroom/index.php       valid
Crawling page: https://www.uvic.ca/library/use/index.php       valid
Crawling page: https://www.uvic.ca/library/research/tips/index.php2018-11-11 09:46:48 [scrapy.extensions.logstats] INFO: Crawled 2587 pages (at 12 pages/min), scraped 2226 items (at 12 items/min)
2018-11-11 09:47:41 [scrapy.extensions.logstats] INFO: Crawled 2598 pages (at 11 pages/min), scraped 2236 items (at 10 items/min)
2018-11-11 09:48:47 [scrapy.extensions.logstats] INFO: Crawled 2611 pages (at 13 pages/min), scraped 2250 items (at 14 items/min)
2018-11-11 09:49:52 [scrapy.extensions.logstats] INFO: Crawled 2624 pages (at 13 pages/min), scraped 2262 items (at 12 items/min)
2018-11-11 09:50:43 [scrapy.extensions.logstats] INFO: Crawled 2635 pages (at 11 pages/min), scraped 2275 items (at 13 items/min)
2018-11-11 09:51:52 [scrapy.extensions.logstats] INFO: Crawled 2647 pages (at 12 pages/min), scraped 2287 items (at 12 items/min)
2018-11-11 09:52:40 [scrapy.extensions.logstats] INFO: Crawled 2655 pages (at 8 pages/min), scraped 2295 items (at 8 items/min)
2018-11-11 09:53:43 [scrapy.extensions.logstats] INFO: Crawled 2667 pages (at 12 pages/min), scraped 2306 items (at 11 items/min)
2018-11-11 09:54:44 [scrapy.extensions.logstats] INFO: Crawled 2678 pages (at 11 pages/min), scraped 2318 items (at 12 items/min)
       valid
Crawling page: https://www.uvic.ca/library/locations/index.php       valid
Crawling page: https://www.uvic.ca/library/research/refdesk/index.php       valid
Crawling page: https://www.uvic.ca/library/research/videos/index.php       valid
Crawling page: https://www.uvic.ca/library/research/guides/index.php       valid
Crawling page: https://www.uvic.ca/library/research/workshops/index.php       valid
Crawling page: https://www.uvic.ca/library/research/librarians/index.php       valid
Crawling page: https://www.uvic.ca/library/research/citation/index.php       valid
Crawling page: https://www.uvic.ca/library/research/ask/index.php       valid
Crawling page: https://www.uvic.ca/library/locations/home/spcoll/index.php       valid
Crawling page: https://www.uvic.ca/library/locations/home/media/index.php       valid
Crawling page: https://www.uvic.ca/library/locations/home/learning/index.php       valid
Crawling page: https://www.uvic.ca/library/research/index.php       valid
Crawling page: https://www.uvic.ca/library/locations/home/mearns/index.php       valid
Crawling page: https://www.uvic.ca/library/locations/home/law/index.php       valid
Crawling page: https://www.uvic.ca/library/locations/home/archives/index.php       valid
Crawling page: https://www.uvic.ca/library/featured/events/index.php       valid
Crawling page: https://www.uvic.ca/library/featured/data/index.php       valid
Crawling page: https://www.uvic.ca/library/featured/scholcomm/index.php       valid
Crawling page: https://www.uvic.ca/library/featured/collections/index.php       valid
Crawling page: https://www.uvic.ca/library/find/formats/index.php       valid
Crawling page: https://www.uvic.ca/library/featured/index.php       valid
Crawling page: https://www.uvic.ca/library/find/special/index.php       valid
Crawling page: https://www.uvic.ca/library/find/reserves/index.php       valid
Crawling page: https://www.uvic.ca/library/find/books/index.php       valid
Crawling page: https://www.uvic.ca/library/find/journals/index.php       valid
Crawling page: https://www.uvic.ca/library/find/databases/index.php       valid
Crawling page: https://www.uvic.ca/library/find/articles/index.php       valid
Crawling page: https://www.uvic.ca/library/find/index.php       valid
Crawling page: https://www.uvic.ca/research/conduct/home/news/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/resources/index.php       valid
Crawling page: https://www.uvic.ca/research/conduct/home/forms/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/research-opps/index.php       valid
Crawling page: https://www.uvic.ca/research/partner/home/projects/index.php       valid
Crawling page: https://www.uvic.ca/research/learnabout/home/infofor/postdocs/index.php       valid
Crawling page: http://www.adynxx.com/financial-conflicts-of-interest-policy/       valid
Crawling page: https://www.uvic.ca/research/learnabout/home/awards/index.php       valid
Crawling page: https://www.uvic.ca/research/learnabout/home/centres/index.php       valid
Crawling page: https://www.uvic.ca/library/       valid
Crawling page: http://www.adynxx.com/terms-of-use/       valid
Crawling page: http://www.adynxx.com/news/adynxx-announces-results-of-the-adyx-004-phase-2-study-of-brivoligide-ayx1-for-the-treatment-of-post-surgical-pain/       valid
Crawling page: http://www.adynxx.com/privacy-policy/       valid
Crawling page: https://www.uvic.ca/research/learnabout/home/researchers/index.php       valid
Crawling page: http://www.adynxx.com/news/adynxx-completes-enrollment-in-adyx-004-a-phase-2-study-of-brivoligide-ayx1-lead-compound-for-the-treatment-of-post-surgical-pain/       valid
Crawling page: http://www.adynxx.com/news/alliqua-biomedical-inc-and-adynxx-inc-announce-merger-agreement-to-create-nasdaq-listed-clinical-stage-pharmaceutical-company-with-a-focus-on-pain-and-inflammation/       valid
Crawling page: http://www.adynxx.com/news/adynxx-to-participate-in-symposium-present-posters-at-efic-pain-congress-2017/       valid
Crawling page: http://www.adynxx.com/contact/       valid
Crawling page: http://www.adynxx.com/news/       valid
Crawling page: http://www.adynxx.com/therapeutic-approach/       valid
Crawling page: http://www.adynxx.com/company/       valid
Crawling page: http://www.adynxx.com       valid
Crawling page: https://www.uvic.ca/ideafest/       valid
Crawling page: https://www.uvic.ca/learningandteaching/       valid
Crawling page: https://www.uvic.ca/coopandcareer/career/index.php       valid
Crawling page: https://www.uvic.ca/coopandcareer/co-op/index.php       valid
Crawling page: https://www.uvic.ca/BAN1P/bwckschd.p_disp_dyn_sched       valid
Crawling page: https://www.uvic.ca/socialsciences/       valid
Crawling page: https://www.uvic.ca/research/conduct/home/news/newsletter/index.php       valid
Crawling page: https://www.uvic.ca/research/learnabout/home/publications/index.php       valid
Crawling page: https://www.uvic.ca/knowledge/       valid
Crawling page: https://www.uvic.ca/science/       valid
Crawling page: https://www.uvic.ca/law/       valid
Crawling page: https://www.uvic.ca/medsci/       valid
Crawling page: https://www.uvic.ca/humanities/       valid
Crawling page: https://www.uvic.ca/hsd/       valid
Crawling page: https://www.uvic.ca/graduatestudies/       valid
Crawling page: https://www.uvic.ca/engineering/       valid
Crawling page: https://www.uvic.ca/gustavson/       valid
Crawling page: https://www.uvic.ca/education/       valid
Crawling page: https://www.uvic.ca/future-students/home/programs/index.php       valid
Crawling page: https://www.uvic.ca/future-students/home/apply/index.php       valid
Crawling page: https://www.uvic.ca/home/academics/       valid
Crawling page: https://www.uvic.ca/registrar/safa/index.php       valid
Crawling page: https://www.uvic.ca/gustavson/executive/       valid
Crawling page: https://www.uvic.ca/registrar/       valid
Crawling page: https://www.uvic.ca/law/admissions/index.php       valid
Crawling page: https://www.uvic.ca/graduatestudies/admissions/index.php       valid
Crawling page: https://www.uvic.ca/graduatestudies/admissions/admissions/beforeapplying/requirements/index.php       valid
Crawling page: https://www.uvic.ca/graduatestudies/research/index.php       valid
Crawling page: https://www.uvic.ca/finearts/       valid
Crawling page: https://www.uvic.ca/graduatestudies/admissions/admissions/index.php       valid
Crawling page: https://www.uvic.ca/future-students/undergraduate/apply/index.php       valid
Crawling page: https://www.uvic.ca/future-students/undergraduate/admissions/index.php       valid
Crawling page: https://www.uvic.ca/home/admissions/       valid
Crawling page: https://www.uvic.ca/home/about/contact-us/key-contacts/index.php       valid
Crawling page: https://www.uvic.ca/home/about/contact-us/experts/index.php       valid
Crawling page: https://www.uvic.ca/home/about/contact-us/department-directory/index.php       valid
Crawling page: https://www.uvic.ca/home/about/community/alliances/index.php       valid
Crawling page: https://www.uvic.ca/home/about/community/research/index.php       valid
Crawling page: https://www.uvic.ca/home/about/community/properties/index.php       valid
Crawling page: https://www.uvic.ca/home/about/edge/dynamic-learning/index.php       valid
Crawling page: https://www.uvic.ca/home/about/community/resources/index.php       valid
Crawling page: https://www.uvic.ca/home/about/community/aboriginal/index.php       valid
Crawling page: https://www.uvic.ca/home/about/community/involvement/index.php       valid
Crawling page: https://www.uvic.ca/home/about/community/index.php       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/parking-tpt/index.php       valid
Crawling page: https://www.uvic.ca/home/about/victoria/index.php       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/hours/index.php       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/tours/index.php       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/uvss-info-booth/index.php       valid
Crawling page: https://uvic.mua.hrdepartment.com/hr/ats/JobSearch/viewAll2018-11-11 09:55:12 [root] ERROR: Unable to find match for url: https://uvic.mua.hrdepartment.com/hr/ats/JobSearch/viewAll
2018-11-11 09:55:47 [scrapy.extensions.logstats] INFO: Crawled 2692 pages (at 14 pages/min), scraped 2331 items (at 13 items/min)
2018-11-11 09:56:45 [scrapy.extensions.logstats] INFO: Crawled 2702 pages (at 10 pages/min), scraped 2342 items (at 11 items/min)
2018-11-11 09:57:43 [scrapy.extensions.logstats] INFO: Crawled 2712 pages (at 10 pages/min), scraped 2351 items (at 9 items/min)
2018-11-11 09:58:44 [scrapy.extensions.logstats] INFO: Crawled 2722 pages (at 10 pages/min), scraped 2361 items (at 10 items/min)
2018-11-11 09:59:51 [scrapy.extensions.logstats] INFO: Crawled 2733 pages (at 11 pages/min), scraped 2373 items (at 12 items/min)
2018-11-11 09:59:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/hr/pay-benefits/benefits/index.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 10:00:44 [scrapy.extensions.logstats] INFO: Crawled 2742 pages (at 9 pages/min), scraped 2382 items (at 9 items/min)
2018-11-11 10:01:44 [scrapy.extensions.logstats] INFO: Crawled 2756 pages (at 14 pages/min), scraped 2393 items (at 11 items/min)
2018-11-11 10:02:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/research/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:02:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/cas/login?service=https://www.uvic.ca/mypage/Login%3FrefUrl%3D%2Fmypage%2Fp%2Fmycourses>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:02:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://annambiosciences.com/publications>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:02:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/search/q/directory.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:02:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://annambiosciences.com/our_technologies/our_technology_and_its_application>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:02:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://annambiosciences.com/#yss>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:02:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://annambiosciences.com/news>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:02:46 [scrapy.extensions.logstats] INFO: Crawled 2766 pages (at 10 pages/min), scraped 2404 items (at 11 items/min)
2018-11-11 10:02:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/news/topics/2018+onc-early-earthquake-warning+media-release>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 10:02:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/security/home/lost/index.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 10:03:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/home/about/contact-us/staff-directory/index.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 10:03:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/home/about/about/index.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 10:03:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/partners/business-industry/index.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
/bin/sh: 1: kill: No such process

2018-11-11 10:04:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/president/about/welcome/index.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:04:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/current-students/index.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:04:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.uvic.ca/current-students/home/resources/index.php>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectError: An error occurred while connecting: 104: Connection reset by peer.
2018-11-11 10:04:11 [scrapy.extensions.logstats] INFO: Crawled 2781 pages (at 15 pages/min), scraped 2416 items (at 12 items/min)
2018-11-11 10:04:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coopertechnologies.net/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-11-11 10:04:44 [scrapy.extensions.logstats] INFO: Crawled 2790 pages (at 9 pages/min), scraped 2421 items (at 5 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 10:05:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://www.gracenote.com/feed/>: HTTP status code is not handled or not allowed
       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/welcome-centre/index.php       valid
Crawling page: https://www.uvic.ca/universitysecretary/policies/index.php       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/index.php       valid
Crawling page: https://www.uvic.ca/universitysecretary/governors/index.php       valid
Crawling page: https://www.uvic.ca/universitysecretary/home/office/index.php       valid
Crawling page: https://www.uvic.ca/universitysecretary/home/chancellor/index.php       valid
Crawling page: https://www.uvic.ca/external/home/vicepresident/index.php       valid
Crawling page: https://www.uvic.ca/vpfo/index.php       valid
Crawling page: https://www.uvic.ca/research/learnabout/home/about/vpre/index.php       valid
Crawling page: https://www.uvic.ca/president/index.php       valid
Crawling page: https://www.uvic.ca/BAN1P/bzsklogn.p_display_login       valid
Crawling page: https://www.uvic.ca/vpacademic/index.php       valid
Crawling page: https://www.uvic.ca/home/about/governance-administration/index.php       valid
Crawling page: https://www.uvic.ca/financialplanning/budget/index.php       valid
Crawling page: https://www.uvic.ca/home/about/facts-reports/accountability/index.php       valid
Crawling page: https://www.uvic.ca/home/about/facts-reports/strategic-plan/index.php       valid
Crawling page: https://www.uvic.ca/home/about/facts-reports/index.php       valid
Crawling page: https://www.uvic.ca/home/about/facts-reports/university-reports/index.php       valid
Crawling page: https://www.uvic.ca/home/about/about/       valid
Crawling page: https://www.uvic.ca/partners/community/index.php       valid
Crawling page: https://www.uvic.ca/partners/index.php       valid
Crawling page: https://www.uvic.ca/partners/indigenous/index.php       valid
Crawling page: https://www.uvic.ca/alumni/index.php       valid
Crawling page: https://www.uvic.ca/alumni-donors/index.php       valid
Crawling page: https://www.uvic.ca/hr/careers/index.php       valid
Crawling page: https://www.uvic.ca/hr/careers/join-uvic/index.php       valid
Crawling page: https://www.uvic.ca/future-faculty-staff/index.php       valid
Crawling page: https://www.uvic.ca/current-faculty-staff/index.php       valid
Crawling page: https://www.uvic.ca/future-students/indigenous/index.php       valid
Crawling page: https://www.uvic.ca/hr/pay-benefits/recognition-awards/index.php       valid
Crawling page: https://www.uvic.ca/future-students/continuing-professional/index.php       valid
Crawling page: https://www.uvic.ca/future-students/graduate/index.php       valid
Crawling page: https://www.uvic.ca/hr/learning-development/calendar/index.php       valid
Crawling page: https://www.uvic.ca/future-students/undergraduate/index.php       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/maps/index.php       valid
Crawling page: https://www.uvic.ca/future-students/index.php       valid
Crawling page: https://www.uvic.ca/search/browse/az.php       valid
Crawling page: https://www.uvic.ca/cas/login?service=https%3A%2F%2Fwww.uvic.ca%2Fresearch%2Fpartner%2Findex.php       valid
Crawling page: https://www.uvic.ca/index.php       valid
Crawling page: https://www.uvic.ca/search/q/index.php       valid
Crawling page: https://www.uvic.ca       valid
Crawling page: https://www.uvic.ca/partners/employers/index.php       valid
Crawling page: https://www.uvic.ca/partners/research/index.php       valid
Crawling page: https://www.uvic.ca/home/about/campus-info/directories/index.php       valid
Crawling page: https://www.uvic.ca/current-students/home/new-students/index.php       valid
Crawling page: https://www.uvic.ca/universitysecretary/senate/index.php       valid
Crawling page: https://www.uvic.ca/hr/careers/how-to-apply/index.php       valid
Crawling page: https://www.uvic.ca/home/about/contact-us/index.php       valid
Crawling page: https://www.uvic.ca/news/publications/ring/index.php       valid
Crawling page: https://www.uvic.ca/hr/health-wellness/index.php       valid
Crawling page: https://www.uvic.ca/current-students/home/academics/index.php       valid
Crawling page: https://www.uvic.ca/research/       valid
Crawling page: https://www.uvic.ca/mypage/f/welcome/normal/render.uP       valid
Crawling page: https://www.uvic.ca/search/q/experts.php       valid
Crawling page: https://www.uvic.ca/research/learnabout/home/facts/index.php       valid
Crawling page: https://www.uvic.ca/research/index.php       valid
Crawling page: https://www.uvic.ca/research/conduct/home/regapproval/index.php       valid
Crawling page: https://www.uvic.ca/research/conduct/index.php       valid
Crawling page: https://www.uvic.ca/research/conduct/home/policies/index.php       valid
Crawling page: https://www.uvic.ca/cas/login?service=https://www.uvic.ca/mypage/Login%3FrefUrl%3D%2Fmypage%2Ff%2Fstudent-services%2F       valid
Crawling page: https://www.uvic.ca/research/conduct/home/funding/index.php       valid
Crawling page: https://www.uvic.ca/current-faculty-staff/home/resources/index.php       valid
Crawling page: https://www.thewaltdisneycompany.com/modern-technology-and-traditional-artistry-bring-to-life-the-worlds-of-the-nutcracker-and-the-four-realms/       valid
Crawling page: http://annambiosciences.com/contact_us       valid
Crawling page: https://www.uvic.ca/onecard/       valid
Crawling page: https://www.uvic.ca/systems/about/clientservices/servicecentre/index.php       valid
Crawling page: https://www.uvic.ca/research/contact/index.php       valid
Crawling page: http://annambiosciences.com/careers       valid
Crawling page: http://annambiosciences.com/our_technologies       valid
Crawling page: https://www.uvic.ca/news/topics/2018+knowledge-indigenous-language-mcivor+news       valid
Crawling page: http://annambiosciences.com/about_annam_biosciences/mission       valid
Crawling page: https://www.thewaltdisneycompany.com/disney-donates-1-million-to-feeding-america/       valid
Crawling page: http://annambiosciences.com/home       valid
Crawling page: http://annambiosciences.com/about_annam_biosciences       valid
Crawling page: https://www.thewaltdisneycompany.com/contact-us/       valid
Crawling page: http://annambiosciences.com/about_annam_biosciences/management       valid
Crawling page: https://www.uvic.ca/cas/login?service=http%3A%2F%2Fdev.uvic.ca%2Fcurrent-students%2Findex.php       valid
Crawling page: https://www.uvic.ca/news/topics/2018+fossil-fuel-owners-bill-carroll+media-release       valid
Crawling page: https://www.uvic.ca/home/about/contact-us/key-departments/index.php       valid
Crawling page: https://www.uvic.ca/graduatestudies/index.php       valid
Crawling page: https://www.uvic.ca/home/about/contact-us/emergency/index.php       valid
Crawling page: https://www.uvic.ca/international/       valid
Crawling page: https://www.uvic.ca/research/learnabout/home/strengths/index.php       valid
Crawling page: https://www.uvic.ca/news/topics/2018+ian-manners-materials-science+news       valid
Crawling page: https://atleisure.com/contact       valid
Crawling page: https://atleisure.com/troubleshooting       valid
Crawling page: https://www.uvic.ca/future-students/undergraduate/deadlines/index.php       valid
Crawling page: https://atleisure.com/warranties       valid
Crawling page: https://atleisure.com/maintenance       valid
Crawling page: https://www.brother-usa.com/       valid
Crawling page: https://www.brother-usa.com/business       valid
Crawling page: https://www.brother-usa.com/home       valid
Crawling page: https://atleisure.com/about-us       valid
Crawling page: http://www.atleisure.com       valid
Crawling page: https://www.brother-usa.com/login       valid
Crawling page: http://atleisure.com       valid
Crawling page: https://atleisure.com/faq       valid
Crawling page: https://atleisure.com/our-patents       valid
Crawling page: http://huntenergyenterprises.com/doing-business-with-hunt.aspx       valid
Crawling page: http://graphenetechnologies.com/       valid
Crawling page: http://huntenergyenterprises.com/DITL-video.html       valid
Crawling page: http://huntenergyenterprises.com/contact.aspx       valid
Crawling page:/bin/sh: 1: kill: No such process

2018-11-11 10:05:51 [scrapy.extensions.logstats] INFO: Crawled 2807 pages (at 17 pages/min), scraped 2435 items (at 14 items/min)
2018-11-11 10:06:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.gracenote.com/privacy-statement-gracenote-site/>: HTTP status code is not handled or not allowed
2018-11-11 10:06:41 [scrapy.extensions.logstats] INFO: Crawled 2821 pages (at 14 pages/min), scraped 2440 items (at 5 items/min)
2018-11-11 10:08:10 [scrapy.extensions.logstats] INFO: Crawled 2821 pages (at 0 pages/min), scraped 2450 items (at 10 items/min)
2018-11-11 10:09:06 [scrapy.extensions.logstats] INFO: Crawled 2830 pages (at 9 pages/min), scraped 2454 items (at 4 items/min)
2018-11-11 10:09:49 [scrapy.extensions.logstats] INFO: Crawled 2833 pages (at 3 pages/min), scraped 2459 items (at 5 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 10:10:48 [scrapy.extensions.logstats] INFO: Crawled 2834 pages (at 1 pages/min), scraped 2463 items (at 4 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 10:12:24 [scrapy.extensions.logstats] INFO: Crawled 2842 pages (at 8 pages/min), scraped 2469 items (at 6 items/min)
2018-11-11 10:12:45 [scrapy.extensions.logstats] INFO: Crawled 2846 pages (at 4 pages/min), scraped 2473 items (at 4 items/min)
2018-11-11 10:14:09 [scrapy.extensions.logstats] INFO: Crawled 2852 pages (at 6 pages/min), scraped 2481 items (at 8 items/min)
2018-11-11 10:15:04 [scrapy.extensions.logstats] INFO: Crawled 2868 pages (at 16 pages/min), scraped 2487 items (at 6 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 10:15:41 [scrapy.extensions.logstats] INFO: Crawled 2870 pages (at 2 pages/min), scraped 2492 items (at 5 items/min)
2018-11-11 10:16:50 [scrapy.extensions.logstats] INFO: Crawled 2874 pages (at 4 pages/min), scraped 2502 items (at 10 items/min)
2018-11-11 10:17:45 [scrapy.extensions.logstats] INFO: Crawled 2885 pages (at 11 pages/min), scraped 2509 items (at 7 items/min)
2018-11-11 10:18:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.j-oled.com/j-news/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 10:18:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.j-oled.com/application/>
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-11-11 10:18:52 [scrapy.extensions.logstats] INFO: Crawled 2897 pages (at 12 pages/min), scraped 2518 items (at 9 items/min)
/bin/sh: 1: kill: No such process

2018-11-11 10:20:12 [scrapy.extensions.logstats] INFO: Crawled 2897 pages (at 0 pages/min), scraped 2525 items (at 7 items/min)
2018-11-11 10:21:12 [scrapy.extensions.logstats] INFO: Crawled 2903 pages (at 6 pages/min), scraped 2531 items (at 6 items/min)
 http://huntenergyenterprises.com/leadership.aspx       valid
Crawling page: http://huntenergyenterprises.com/about.aspx       valid
Crawling page: http://huntenergyenterprises.com/careers.aspx       valid
Crawling page: http://www.gracenote.com/       valid
Crawling page: http://jewhites.com.au/advertise-on-this-site/       valid
Crawling page: https://atleisure.com/service-center       valid
Crawling page: https://atleisure.com/heating       valid
Crawling page: https://atleisure.com/covers       valid
Crawling page: https://atleisure.com/alternate-instruction-manuals       valid
Crawling page: http://jewhites.com.au/contact-us/       valid
Crawling page: http://jewhites.com.au/problem-free-renting/       valid
Crawling page: http://jewhites.com.au/rental-properties-adelaide/       valid
Crawling page: http://jewhites.com.au/residential-property-sales/       valid
Crawling page: http://jewhites.com.au/property-manager-expectations/       valid
Crawling page: http://jewhites.com.au/property-management-enquiry/       valid
Crawling page: http://jewhites.com.au/property-management-adelaide/       valid
Crawling page: http://jewhites.com.au/pay-corporation-levy/       valid
Crawling page: http://jewhites.com.au/property-management-essential-questions/       valid
Crawling page: https://atleisure.com/shade       valid
Crawling page: https://atleisure.com/furniture       valid
Crawling page: http://jewhites.com.au/after-hours-emergencies/       valid
Crawling page: http://jewhites.com.au/body-corporate-insurance/       valid
Crawling page: http://jewhites.com.au/self-managing-a-body-corporate/       valid
Crawling page: http://jewhites.com.au/body-corporate-property-development/       valid
Crawling page: https://www.j-oled.com/press/2018-8-23-2/       valid
Crawling page: https://www.j-oled.com/terms-of-use/       valid
Crawling page: https://www.j-oled.com/news/       valid
Crawling page: https://www.j-oled.com/privacy-policy/       valid
Crawling page: http://jewhites.com.au/free-quote-appraisal/       valid
Crawling page: http://jewhites.com.au/client-testimonials/       valid
Crawling page: http://jewhites.com.au/mailing-list/       valid
Crawling page: http://jewhites.com.au/body-corporate-management/       valid
Crawling page: http://jewhites.com.au/our-team/       valid
Crawling page: http://jewhites.com.au/property-management-specialist/       valid
Crawling page: http://jewhites.com.au/je-whites-blog/       valid
Crawling page: http://jewhites.com.au/       valid
Crawling page: http://www.gracenote.com/ja/       valid
Crawling page: http://www.gracenote.com/tech-blog/       valid
Crawling page: https://www.j-oled.com/faq/       valid
Crawling page: https://www.j-oled.com/technology/       valid
Crawling page: https://www.j-oled.com/product/       valid
Crawling page: https://www.j-oled.com/       valid
Crawling page: http://www.gracenote.com/terms-of-use/       valid
Crawling page: http://www.gracenote.com/open-source-software/       valid
Crawling page: http://www.gracenote.com/privacy-statement/       valid
Crawling page: http://www.gracenote.com/gracenote-helps-cable-satellite-operators-turn-tv-music-destination/       valid
Crawling page: http://www.gracenote.com/new-gracenote-mobile-video-analytics-solution-delivers-groundbreaking-view-of-streaming-app-performance/       valid
Crawling page: http://www.gracenote.com/company/our-locations/       valid
Crawling page: http://www.gracenote.com/studio-system/       valid
Crawling page: http://www.gracenote.com/company/support/       valid
Crawling page: http://www.gracenote.com/company/press/       valid
Crawling page: http://www.gracenote.com/company/careers/       valid
Crawling page: http://www.gracenote.com/contact-us-form/       valid
Crawling page: http://www.gracenote.com/connectivity/mobile-video-analytics/       valid
Crawling page: http://www.gracenote.com/company/leadership/       valid
Crawling page: http://www.gracenote.com/sports/sports-services/       valid
Crawling page: http://www.gracenote.com/company/about-us/       valid
Crawling page: http://www.gracenote.com/sports/fifa-world-cup/       valid
Crawling page: http://www.gracenote.com/clients/       valid
Crawling page: http://www.gracenote.com/sports/global-sports-data/       valid
Crawling page: http://www.gracenote.com/auto/music-recognition-auto/       valid
Crawling page: http://www.huntenergyenterprises.com       valid
Crawling page: http://huntenergyenterprises.com/       valid
Crawling page: http://www.gracenote.com/video/media-recognition/       valid
Crawling page: http://www.gracenote.com/studio-system-projects/       valid
Crawling page: http://www.gracenote.com/auto/smart-radio-solutions/       valid
Crawling page: http://huntenergyenterprises.com/selection-criteria.aspx       valid
Crawling page: http://huntenergyenterprises.com/sitemap.aspx       valid
Crawling page: http://huntenergyenterprises.com/terms-and-conditions.aspx       valid
Crawling page: http://huntenergyenterprises.com/social.aspx       valid
Crawling page: http://www.gracenote.com/sports/tv-sports-data/       valid
Crawling page: http://huntenergyenterprises.com/financial-summary.aspx       valid
Crawling page: http://huntenergyenterprises.com/index.aspx       valid
Crawling page: http://www.gracenote.com/video/studio-and-celebrity/       valid
Crawling page: http://www.gracenote.com/video/global-video-data/       valid
Crawling page: http://www.gracenote.com/video/tv-solutions-for-apac/       valid
Crawling page: http://www.gracenote.com/advanced-audio/       valid
Crawling page: http://www.gracenote.com/music/global-music-data/       valid
Crawling page: http://www.gracenote.com/music/music-recognition/       valid
Crawling page: http://www.gracenote.com/music/music-discovery/       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/services/cabling-bracing.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/tree-service-bartlett-il.php       valid
Crawling page: https://www.j-oled.com/contact/       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/services/insect-disease-diagnosis-and-treatment.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/services/tree-risk-assessment-and-removals.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/services/pruning.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/tree-service-wheaton-il.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/about/meet-our-team.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/services/root-collar-excavation.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/services/our-capabilities.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/about/career-opportunities.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/about/credentials.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/about/company-background.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/contact.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/tree-service-naperville-il.php       valid
Crawling page: https://www.j-oled.com/company/       valid
Crawling page: https://www.j-oled.com/lecture/display-innovation-china/       valid
Crawling page: https://www.j-oled.com/press/2018-11-6/       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/tree-service-barrington-il.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/gallery.php       valid
Crawling page: https://www.greenextractiontechnologiesllc.com/services/tree-harvesting.php       valid
Crawling page: https://www.j-oled.com/category/lecture/       valid
Crawling page: https://www.j-oled.com/category/press/       valid
Crawling page: https://www.j-oled.com/lecture/display-innovation-taiwan/       valid
Crawling page: https://www.j-oled.com/feed/       valid
Crawling page: https://www.j-oled.com/eng/2018-11-11 10:21:43 [scrapy.extensions.logstats] INFO: Crawled 2906 pages (at 3 pages/min), scraped 2534 items (at 3 items/min)
2018-11-11 10:21:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-11 10:21:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 525,
 'downloader/exception_type_count/twisted.internet.error.ConnectError': 119,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 35,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 368,
 'downloader/request_bytes': 1920203,
 'downloader/request_count': 3948,
 'downloader/request_method_count/GET': 3948,
 'downloader/response_bytes': 80636624,
 'downloader/response_count': 3423,
 'downloader/response_status_count/200': 2888,
 'downloader/response_status_count/301': 446,
 'downloader/response_status_count/302': 56,
 'downloader/response_status_count/303': 1,
 'downloader/response_status_count/400': 1,
 'downloader/response_status_count/403': 1,
 'downloader/response_status_count/404': 23,
 'downloader/response_status_count/406': 4,
 'downloader/response_status_count/408': 1,
 'downloader/response_status_count/500': 2,
 'dupefilter/filtered': 313,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 11, 10, 21, 43, 163916),
 'httperror/response_ignored_count': 30,
 'httperror/response_ignored_status_count/400': 1,
 'httperror/response_ignored_status_count/403': 1,
 'httperror/response_ignored_status_count/404': 23,
 'httperror/response_ignored_status_count/406': 4,
 'httperror/response_ignored_status_count/500': 1,
 'item_scraped_count': 2534,
 'log_count/ERROR': 320,
 'log_count/INFO': 360,
 'log_count/WARNING': 2,
 'memusage/max': 201486336,
 'memusage/startup': 99491840,
 'offsite/domains': 249,
 'offsite/filtered': 487,
 'request_depth_max': 1,
 'response_received_count': 2906,
 'retry/count': 461,
 'retry/max_reached': 67,
 'retry/reason_count/408 Request Time-out': 1,
 'retry/reason_count/500 Internal Server Error': 1,
 'retry/reason_count/twisted.internet.error.ConnectError': 93,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 2,
 'retry/reason_count/twisted.internet.error.TimeoutError': 33,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 331,
 'scheduler/dequeued': 3948,
 'scheduler/dequeued/memory': 3948,
 'scheduler/enqueued': 3948,
 'scheduler/enqueued/memory': 3948,
 'spider_exceptions/AttributeError': 235,
 'spider_exceptions/TimeoutException': 10,
 'spider_exceptions/UnicodeEncodeError': 1,
 'spider_exceptions/WebDriverException': 5,
 'start_time': datetime.datetime(2018, 11, 11, 4, 2, 40, 685658)}
2018-11-11 10:21:43 [scrapy.core.engine] INFO: Spider closed (finished)
       valid
Crawling page: https://www.j-oled.com/careers/       valid
